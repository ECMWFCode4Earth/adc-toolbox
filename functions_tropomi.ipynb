{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TROPOMI functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def TROPOMI_download(input_type, bbox, period, product_type, processing_mode):\n",
    "\n",
    "   \"\"\" Query and download the TROPOMI dataset from Sentinel API\n",
    "\n",
    "         Args:\n",
    "            input_type (str): Search type (Manual or Query)\n",
    "            bbox (arr): Query bounding box\n",
    "            period (list): Query period of time \n",
    "            product_type (str): Query product type\n",
    "            processing_mode (str): Query processing mode (Offline, Near real time, Reprocessing)\n",
    "\n",
    "        Returns:\n",
    "            file_name (str): File name of TROPOMI product within 5phub\n",
    "            product_name (str): Product name of TROPOMI product within 5phub\n",
    "   \"\"\"\n",
    "\n",
    "   user = 's5pguest' \n",
    "   password = 's5pguest' \n",
    "   api = SentinelAPI(user, password, 'https://s5phub.copernicus.eu/dhus/')\n",
    "\n",
    "   if input_type == 'Manual':\n",
    "\n",
    "      file_name = input('Write file name: ')\n",
    "      product_name = input('Write product name:')\n",
    "\n",
    "   elif input_type == 'Query':\n",
    "      \n",
    "      print('Warning: The maximum number of items that can be shown is 5.')\n",
    "      print('You can see all the results at https://s5phub.copernicus.eu/dhus/.')\n",
    "\n",
    "      poly = geojson.Polygon([[(bbox[0][0], bbox[0][1]), (bbox[0][0], bbox[1][1]), \n",
    "                               (bbox[1][0], bbox[1][1]), (bbox[1][0], bbox[0][1]), \n",
    "                               (bbox[0][0], bbox[0][1])]])\n",
    "\n",
    "      products = api.query(area = geojson_to_wkt(poly),\n",
    "                           area_relation = 'Contains',\n",
    "                           producttype = product_type,\n",
    "                           processinglevel = 'L2',\n",
    "                           platformname = 'Sentinel-5 Precursor',\n",
    "                           instrumentname = 'TROPOspheric Monitoring Instrument',\n",
    "                           processingmode = processing_mode,\n",
    "                           date = period,\n",
    "                           limit = 5)\n",
    "\n",
    "      items = list(products.items())\n",
    "      \n",
    "      if not items: \n",
    "         print('There are no results. The code will be interrupted.')\n",
    "         raise KeyboardInterrupt\n",
    "       \n",
    "      else:\n",
    "         print('RESULTS FOR PERIOD ' + str(period))\n",
    "         for i in range(0, len(items)):\n",
    "            print('Number ', i, ': ', items[i][1]['title'], sep = '')\n",
    "\n",
    "      file_int = input('Select number or press Enter if you want to select the first result: ') or 0\n",
    "      file_name = items[int(file_int)][0]\n",
    "      product_name = items[int(file_int)][1]['title'] + '.nc'\n",
    "\n",
    "   print('SELECTED')\n",
    "   print('File name:', file_name)\n",
    "   print('Product name:', product_name)\n",
    "   \n",
    "   if os.path.isfile(os.path.join(os.path.abspath(''), 'data/' + sensor + '/' + component_nom + '/' + product_name)):\n",
    "      print('The file exists, it will not be downloaded again.')\n",
    "\n",
    "   else:\n",
    "      print('The file does not exist, it will be downloaded.')\n",
    "      api.download(file_name, directory_path = 'data/tropomi/' + component_nom)\n",
    "\n",
    "   return file_name, product_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def TROPOMI_read(product_names, component_nom):\n",
    "\n",
    "    \"\"\" Read TROPOMI dataset as xarray dataset object\n",
    "\n",
    "        Args:\n",
    "            product_name (str): Product name of TROPOMI product within 5phub\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "\n",
    "        Returns:\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "            support_input_ds (xarray): TROPOMI dataset that contains support input data in xarray format\n",
    "            support_details_ds (xarray): TROPOMI dataset that contains support details data in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    TROPOMI_ds_all = []\n",
    "    support_input_ds_all = []\n",
    "    support_details_ds_all = []\n",
    "\n",
    "    for product_name in product_names:\n",
    "\n",
    "        TROPOMI_ds = xr.open_dataset('data/tropomi/' + component_nom + '/' + product_name, group = 'PRODUCT')\n",
    "\n",
    "        support_input_ds = xr.open_dataset('data/tropomi/' + component_nom + '/' + product_name, \n",
    "                                           group = 'PRODUCT/SUPPORT_DATA/INPUT_DATA')\n",
    "\n",
    "        support_input_ds = support_input_ds.assign(ground_pixel = TROPOMI_ds.ground_pixel)\n",
    "        support_input_ds = support_input_ds.assign(scanline = TROPOMI_ds.scanline)\n",
    "        support_input_ds = support_input_ds.assign(time = TROPOMI_ds.time)\n",
    "        support_input_ds = support_input_ds.set_coords(['ground_pixel', 'scanline', 'time'])\n",
    "\n",
    "        support_details_ds = xr.open_dataset('data/tropomi/' + component_nom + '/' + product_name, \n",
    "                                             group = 'PRODUCT/SUPPORT_DATA/DETAILED_RESULTS')\n",
    "\n",
    "        if component_nom == 'CO':\n",
    "            \n",
    "            # Transform heights into levels\n",
    "            data = {'Layer': np.arange(1, 51)[::-1], 'Height': TROPOMI_ds.layer}\n",
    "            dataframe = pd.DataFrame(data)\n",
    "            \n",
    "            for i in range(0, 50):\n",
    "\n",
    "                TROPOMI_ds['layer'] = xr.where(TROPOMI_ds.layer == dataframe['Height'].iloc[i], \n",
    "                                            int(dataframe['Layer'].iloc[i]), TROPOMI_ds['layer'])\n",
    "\n",
    "        TROPOMI_ds_all.append(TROPOMI_ds)\n",
    "        support_input_ds_all.append(support_input_ds)\n",
    "        support_details_ds_all.append(support_details_ds)\n",
    "\n",
    "    # Merge if there is more than one product\n",
    "    if len(product_names) >= 2:\n",
    "\n",
    "        TROPOMI_ds = xr.merge(TROPOMI_ds_all)\n",
    "        support_input_ds = xr.merge(support_input_ds_all)\n",
    "        support_details_ds = xr.merge(support_input_ds_all)\n",
    "\n",
    "    return TROPOMI_ds, support_input_ds, support_details_ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def TROPOMI_pressure(TROPOMI_ds, component_nom, support_input_ds, support_details_ds):\n",
    "\n",
    "    \"\"\" Calculate level pressures for TROPOMI dataset\n",
    "\n",
    "        Args:\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            support_input_ds (xarray): TROPOMI dataset that contains support input data in xarray format\n",
    "            support_details_ds (xarray): TROPOMI dataset that contains support details data in xarray format\n",
    "            \n",
    "        Returns:\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if component_nom == 'NO2':\n",
    "        \n",
    "        print('The layers pressures will be calculated (lower and upper bounds).')\n",
    "\n",
    "        # Calculate pressure as p = ap + b * ps (Units: ap(Pa) + b(none) * ps(Pa) -> To Pa)\n",
    "        pressure = (TROPOMI_ds.tm5_constant_a + TROPOMI_ds.tm5_constant_b * support_input_ds.surface_pressure)\n",
    "        TROPOMI_ds = TROPOMI_ds.assign(pressure = pressure)\n",
    "    \n",
    "    elif component_nom == 'CO':\n",
    "\n",
    "        print('The layers pressures will be retrieved (lower bound).')\n",
    "\n",
    "        # Pressure is at lower bound!\n",
    "        pressure_lower = support_details_ds.pressure_levels\n",
    "        TROPOMI_ds = TROPOMI_ds.assign(pressure = pressure_lower)\n",
    "\n",
    "    elif component_nom == 'SO2':\n",
    "        \n",
    "        print('The layers pressures will be calculated (unknown bound, half?).')\n",
    "        \n",
    "        pressure = (support_input_ds.tm5_constant_a + support_input_ds.tm5_constant_b * support_input_ds.surface_pressure)\n",
    "        TROPOMI_ds = TROPOMI_ds.assign(pressure = pressure)\n",
    "    \n",
    "    elif component_nom == 'O3':\n",
    "\n",
    "        print('The layers pressures will be retrieved (unknown bound, half?).')\n",
    "        pressure = support_details_ds.pressure_grid\n",
    "        TROPOMI_ds = TROPOMI_ds.assign(pressure = pressure)\n",
    "\n",
    "    else:\n",
    "        print('This dataset does not contain data to calculate the layer pressures.')\n",
    "\n",
    "    return TROPOMI_ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def TROPOMI_kernel_column(TROPOMI_ds, support_details_ds):\n",
    "\n",
    "    \"\"\" Calculate column kernels for TROPOMI dataset\n",
    "\n",
    "        Args:\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "            support_details_ds (xarray): TROPOMI dataset that contains support details data in xarray format\n",
    "        \n",
    "        Returns:\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if component_nom == 'NO2':\n",
    "\n",
    "        kernel_column = xr.where(TROPOMI_ds.layer > TROPOMI_ds.tm5_tropopause_layer_index, 0, \n",
    "                                 TROPOMI_ds.averaging_kernel * (TROPOMI_ds.air_mass_factor_total / \n",
    "                                 TROPOMI_ds.air_mass_factor_troposphere))\n",
    "        TROPOMI_ds = TROPOMI_ds.assign(kernel_column = kernel_column)\n",
    "\n",
    "    elif component_nom == 'CO':\n",
    "\n",
    "        kernel_column = support_details_ds.column_averaging_kernel\n",
    "        TROPOMI_ds = TROPOMI_ds.assign(kernel_column = kernel_column)\n",
    "    \n",
    "    elif component_nom == 'SO2':\n",
    "        \n",
    "        height_options = [1, 7, 15]\n",
    "        height = input('Input height (in km) to calculate the column kernels with accuracy: ')\n",
    "\n",
    "        while int(height) not in height_options:\n",
    "            print('ERROR: Enter a valid height number. The options are 1, 7 or 15 km.')\n",
    "            height = input('Input height (in km): ')\n",
    "        \n",
    "        # WRONG: This formula must be corrected. Troposphere AMF do not appear in the dataset.\n",
    "        kernel_column = support_details_ds.averaging_kernel * support_details_ds['sulfurdioxide_total_air_mass_factor_' \n",
    "                                                                                 + height + 'km']\n",
    "        TROPOMI_ds = TROPOMI_ds.assign(kernel_column = kernel_column)\n",
    "    \n",
    "    else:\n",
    "        print('The dataset does not contain information to retrieve or calculate the column averaging kernels.')\n",
    "\n",
    "    return TROPOMI_ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def TROPOMI_profile_apriori(TROPOMI_ds, component, support_details_ds):\n",
    "\n",
    "    \"\"\" Create file with the original corresponding coordinates to each scanline and ground pixel in TROPOMI dataset\n",
    "\n",
    "        Args:\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "            component (str): Component name\n",
    "            support_details_ds (xarray): TROPOMI dataset that contains support details data in xarray format\n",
    "        \n",
    "        Returns:\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    profile_apriori_name = component.replace('_', '') + '_profile_apriori'\n",
    "\n",
    "    if profile_apriori_name in list(support_details_ds.keys()):\n",
    "        profile_apriori = support_details_ds[profile_apriori_name]\n",
    "        TROPOMI_ds = TROPOMI_ds.assign(profile_apriori = profile_apriori)\n",
    "\n",
    "    else:\n",
    "        print('The dataset does not contain any apriori profile.')\n",
    "    \n",
    "    return TROPOMI_ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def TROPOMI_original_coords(TROPOMI_ds, component_nom, time):\n",
    "\n",
    "    \"\"\" Create file with the original corresponding coordinates to each scanline and ground pixel in TROPOMI dataset\n",
    "\n",
    "        Args:\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            time (timestamp): Start datetime for each period\n",
    "    \"\"\"\n",
    "\n",
    "    # Create dataframe with scanlines and ground pixels\n",
    "    TROPOMI_coords_df = []\n",
    "    TROPOMI_coords_df = pd.DataFrame(list(product(TROPOMI_ds.ground_pixel.values, TROPOMI_ds.scanline.values)), \n",
    "                            columns = ['ground_pixel', 'scanline'])\n",
    "\n",
    "    # Find corresponding latitudes and longitudes                          \n",
    "    for index, row in TROPOMI_coords_df.iterrows():\n",
    "        TROPOMI_coords_df.loc[index,'latitude'] = TROPOMI_ds.latitude.sel(\n",
    "                                                scanline = TROPOMI_coords_df['scanline'].loc[index], \n",
    "                                                ground_pixel = TROPOMI_coords_df['ground_pixel'].loc[index],\n",
    "                                                method = None).values\n",
    "                                            \n",
    "        TROPOMI_coords_df.loc[index,'longitude'] = TROPOMI_ds.longitude.sel(\n",
    "                                                scanline = TROPOMI_coords_df['scanline'].loc[index], \n",
    "                                                ground_pixel = TROPOMI_coords_df['ground_pixel'].loc[index],\n",
    "                                                method = None).values\n",
    "\n",
    "    # Save as csv\n",
    "    TROPOMI_coords_df.to_csv('data/tropomi/' +  component_nom + '/' + component_nom + '-coords-' + str(time) + '.csv', index = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def TROPOMI_subset(TROPOMI_ds, product_name, bbox, time):\n",
    "\n",
    "    \"\"\" Read file with the corresponding coordinates to each scanline and ground pixel in TROPOMI dataset.\n",
    "        Subset dataset into desired bounding box.\n",
    "\n",
    "        Args:\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "            product_name (str): Product name of TROPOMI product within 5phub\n",
    "            bbox (arr): Query bounding box\n",
    "            time (timestamp): Start datetime for each period\n",
    "    \n",
    "        Returns:\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.isfile(os.path.join(os.path.abspath(''), 'data/' + sensor + '/' +  component_nom + '/' + component_nom + '-coords-' + str(time) + '.csv')):\n",
    "        pass\n",
    "\n",
    "    else: \n",
    "        TROPOMI_original_coords(TROPOMI_ds, component_nom, time)\n",
    "        \n",
    "    # Read csv\n",
    "    TROPOMI_coords_df = pd.read_csv('data/tropomi/' +  component_nom + '/' + component_nom + '-coords-' + str(time) + '.csv')\n",
    "    \n",
    "    # Set limits\n",
    "    TROPOMI_coords_df = TROPOMI_coords_df[(TROPOMI_coords_df['latitude'] >= bbox[0][1]) & \n",
    "                                          (TROPOMI_coords_df['latitude'] <= bbox[1][1])]\n",
    "    TROPOMI_coords_df = TROPOMI_coords_df[(TROPOMI_coords_df['longitude'] >= bbox[0][0]) & \n",
    "                                          (TROPOMI_coords_df['longitude'] <= bbox[1][0])]\n",
    "    \n",
    "    if TROPOMI_coords_df.empty:\n",
    "        \n",
    "        print('ERROR: The subset could not be made. Try to find a new TROPOMI dataset. The code will be interrupted.')\n",
    "        raise KeyboardInterrupt\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Get scanline and ground pixel coordinates\n",
    "        scanline_coords = np.unique(TROPOMI_coords_df['scanline'].values).tolist()\n",
    "        ground_pixel_coords = np.unique(TROPOMI_coords_df['ground_pixel'].values).tolist()\n",
    "\n",
    "        # Set limits\n",
    "        TROPOMI_ds = TROPOMI_ds.sel(scanline = scanline_coords, ground_pixel = ground_pixel_coords)\n",
    "\n",
    "    return TROPOMI_ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def TROPOMI_subset_coords(TROPOMI_ds):\n",
    "\n",
    "    \"\"\" Create file with the subset corresponding coordinates to each scanline and ground pixel in TROPOMI dataset\n",
    "\n",
    "        Args:\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "        \n",
    "        Returns:\n",
    "            TROPOMI_subset_coords_df (dataframe): Dataframe with subset coordinates\n",
    "    \"\"\"\n",
    "\n",
    "    # Create dataframe with scanlines and ground pixels\n",
    "    TROPOMI_subset_coords_df = []\n",
    "    TROPOMI_subset_coords_df = pd.DataFrame(list(product(TROPOMI_ds.ground_pixel.values, TROPOMI_ds.scanline.values)), \n",
    "                                            columns = ['ground_pixel', 'scanline'])\n",
    "\n",
    "    # Find corresponding latitudes and longitudes                          \n",
    "    for index, row in TROPOMI_subset_coords_df.iterrows():\n",
    "        \n",
    "        TROPOMI_subset_coords_df.loc[index,'latitude'] = TROPOMI_ds.latitude.sel(\n",
    "                                                        scanline = TROPOMI_subset_coords_df['scanline'].loc[index], \n",
    "                                                        ground_pixel = TROPOMI_subset_coords_df['ground_pixel'].loc[index],\n",
    "                                                        method = None).values\n",
    "                                                    \n",
    "        TROPOMI_subset_coords_df.loc[index,'longitude'] = TROPOMI_ds.longitude.sel(\n",
    "                                                        scanline = TROPOMI_subset_coords_df['scanline'].loc[index], \n",
    "                                                        ground_pixel = TROPOMI_subset_coords_df['ground_pixel'].loc[index],\n",
    "                                                        method = None).values\n",
    "\n",
    "    return TROPOMI_subset_coords_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def TROPOMI_convert_units(TROPOMI_ds, sensor_column):\n",
    "\n",
    "    \"\"\" Convert the units of the total column of TROPOMI dataset for any component from mol/m2 to molecules/cm2\n",
    "\n",
    "        Args:\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "            sensor_column (str): Name of sensor column in downloaded dataset\n",
    "        \n",
    "        Returns:\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    TROPOMI_ds[sensor_column] = TROPOMI_ds[sensor_column] * 6.02214*10**19\n",
    "    print('The units of the component columns have been converted to molecules/cm2.')\n",
    "    \n",
    "    if 'profile_apriori' in list(TROPOMI_ds.keys()):\n",
    "        \n",
    "        TROPOMI_ds['profile_apriori'] = TROPOMI_ds['profile_apriori'] * 6.02214*10**19\n",
    "        print('The units of the apriori profiles have been converted to molecules/cm2.')\n",
    "\n",
    "    return TROPOMI_ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def TROPOMI_prepare_df(match_df):\n",
    "\n",
    "    \"\"\" Prepare dataframe for merge\n",
    "\n",
    "        Args:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "        \n",
    "        Returns:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "    \"\"\"\n",
    "\n",
    "    # Pass NaNs to data with qa_value under 0.5\n",
    "    match_df.loc[match_df['qa_value'] < 0.5, [sensor_column, 'kernel_column']] = float('NaN')\n",
    "\n",
    "    # Drop levels\n",
    "    if component_nom == 'CO' or component_nom == 'SO2':\n",
    "        \n",
    "        match_df.index.names = ['corner', 'ground_pixel', 'layer', 'scanline']\n",
    "    \n",
    "    elif component_nom == 'O3':\n",
    "\n",
    "        match_df.index.names = ['corner', 'ground_pixel', 'layer', 'level', 'scanline']\n",
    "        \n",
    "    match_df = match_df.groupby(by = ['layer', 'scanline', 'ground_pixel', 'time', 'delta_time']).mean()\n",
    "    match_df = match_df.reset_index(level = ['layer', 'delta_time'])\n",
    "\n",
    "    return match_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def TROPOMI_apply_avg_kernels(kernels_method, match_df, model_ds, TROPOMI_ds):\n",
    "\n",
    "    \"\"\" Apply averaging kernels by using two methods:\n",
    "        * Nearest neighbours: Find the nearest neighbours in the observation space (in pressures, latitude and longitudes)\n",
    "        * Interpolation: Find the nearest neighbours in the observation space (in latitude and longitudes) and \n",
    "                         interpolate values in pressure\n",
    "\n",
    "        Args:\n",
    "            kernels_method (str): Method to apply averaging kernels to model space (Nearest neighbours or Interpolation)\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "            model_ds (xarray): Model levels dataset in xarray format\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "        \n",
    "        Returns:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "    \"\"\"\n",
    "\n",
    "    if kernels_method == 'Nearest neighbours':\n",
    "        \n",
    "        match_df = avg_kernels_nearest_neighbours(match_df, model_ds)\n",
    "\n",
    "    elif kernels_method == 'Interpolation':\n",
    "        \n",
    "        print('The application of averaging kernels will start now.')\n",
    "        match_df, match_df_visualize = avg_kernels_vertical_interpolation(match_df, model_ds, TROPOMI_ds)\n",
    "        \n",
    "        \"\"\"\n",
    "        answer = input('Do you want to see the vertical interpolation for one location? Yes or No:')\n",
    "        \n",
    "        if answer == 'Yes':\n",
    "            scanline_value = input('Show interpolation for one scanline: ')\n",
    "            ground_pixel_value = input('Show interpolation for one ground_pixel: ')\n",
    "            visualize_interpolation(match_df_visualize, scanline_value, ground_pixel_value)\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "        \"\"\"\n",
    "    \n",
    "    # Calculate values to generate CAMS column to sum in the next step\n",
    "    if 'profile_apriori' in match_df.columns:\n",
    "        match_df['model_column'] = match_df.apply(lambda row: row['profile_apriori'] +\n",
    "                                                              row['kernel_column'] * row['model_component']  -\n",
    "                                                              row['kernel_column'] * row['profile_apriori'], \n",
    "                                                              axis = 1)\n",
    "    \n",
    "    else:\n",
    "        match_df['model_column'] = match_df.apply(lambda row: row['kernel_column'] * row['model_component'], \n",
    "                                                              axis = 1)\n",
    "\n",
    "    return match_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def avg_kernels_nearest_neighbours(match_df, model_ds):\n",
    "\n",
    "    \"\"\" Nearest neighbours method: Find the nearest neighbours in the observation space (in pressures, latitude and longitudes)\n",
    "\n",
    "        Args:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "            model_ds (xarray): Model levels dataset in xarray format\n",
    "        \n",
    "        Returns:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "    \"\"\"\n",
    "    \n",
    "    model_pressures = model_levels['ph [Pa]'].to_numpy()\n",
    "    model_times = model_ds.valid_time.data\n",
    "\n",
    "    match_df['lay_index'] = match_df.apply(lambda row: nearest_neighbour(model_pressures, row['pressure']), axis = 1)\n",
    "    match_df['step_index'] = match_df.apply(lambda row: nearest_neighbour(model_times, row['delta_time']), axis = 1)\n",
    "    match_df['model_time'] = match_df.apply(lambda row: model_ds.valid_time[row['step_index']].values, axis = 1)\n",
    "\n",
    "    match_df['model_component'] = match_df.apply(lambda row: model_ds.component.sel( \n",
    "                                                            latitude = row['latitude'], \n",
    "                                                            longitude = row['longitude'], \n",
    "                                                            method = 'nearest').isel(hybrid = int(row['lay_index']), \n",
    "                                                            step = int(row['step_index'])).values, \n",
    "                                                            axis = 1)\n",
    "    \n",
    "    return match_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def avg_kernels_vertical_interpolation(match_df, model_ds, TROPOMI_ds):\n",
    "\n",
    "    \"\"\" Interpolation: Find the nearest neighbours in the observation space (in latitude and longitudes) and \n",
    "        interpolate values in pressure\n",
    "\n",
    "        Args:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "            model_ds (xarray): Model levels dataset in xarray format\n",
    "            TROPOMI_ds (xarray): TROPOMI dataset in xarray format\n",
    "        \n",
    "        Returns:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "    \"\"\"\n",
    "    \n",
    "    sensor_coords_df = TROPOMI_subset_coords(TROPOMI_ds)\n",
    "\n",
    "    match_df.set_index('pressure', append=True, inplace=True)\n",
    "\n",
    "    # Create index that includes CAMS pressure levels for all the locations in TROPOMI\n",
    "    new_index = pd.MultiIndex.from_product([match_df.index.levels[0], \n",
    "                                            match_df.index.levels[1],\n",
    "                                            match_df.index.levels[2],\n",
    "                                            model_levels['ph [Pa]'].to_numpy()],\n",
    "                                            names = ['scanline', 'ground_pixel', 'time', 'pressure'])\n",
    "    \n",
    "    # Append original and new indexes and reindex dataframe\n",
    "    match_df = match_df.reindex(match_df.index.append(new_index))\n",
    "\n",
    "    # Sort and reset index\n",
    "    match_df = match_df.sort_index()\n",
    "    match_df = match_df.reset_index()\n",
    "\n",
    "    # Find latitudes in CAMS rows with scanlines and ground pixels\n",
    "    match_df['latitude'] = match_df.apply(lambda row: float(sensor_coords_df[\n",
    "                                                            (sensor_coords_df['scanline'] == row['scanline']) & \n",
    "                                                            (sensor_coords_df['ground_pixel'] == row['ground_pixel'])]['latitude'])\n",
    "                                                            if pd.isnull(row['latitude']) else row['latitude'], \n",
    "                                                            axis = 1)\n",
    "                                                            \n",
    "    # Find longitudes in CAMS rows with scanlines and ground pixels\n",
    "    match_df['longitude'] = match_df.apply(lambda row: float(sensor_coords_df[\n",
    "                                                            (sensor_coords_df['scanline'] == row['scanline']) & \n",
    "                                                            (sensor_coords_df['ground_pixel'] == row['ground_pixel'])]['longitude'])\n",
    "                                                            if pd.isnull(row['longitude']) else row['longitude'], \n",
    "                                                            axis = 1)\n",
    "                                                            \n",
    "    # Find hybrids in CAMS rows from 137 models table\n",
    "    match_df['hybrid'] = match_df.apply(lambda row: nearest_neighbour(model_levels['ph [Pa]'].to_numpy(), row['pressure']) + 1\n",
    "                                                    if pd.isnull(row[sensor_column]) else math.nan, \n",
    "                                                    axis = 1)\n",
    "\n",
    "    # Get unique timestep\n",
    "    first_delta_time = sensor_ds['delta_time'].isel(scanline = 0, time = 0).values\n",
    "    unique_step = nearest_neighbour(model_ds.valid_time.data, first_delta_time)\n",
    "    unique_time = model_ds.component.isel(step = unique_step).step.values.astype('timedelta64[h]')\n",
    "\n",
    "    # Get CAMS component data at nearby TROPOMI locations (nearest neighbours)\n",
    "    # Do it only for CAMS rows\n",
    "    match_df['model_component'] = match_df.apply(lambda row: model_ds.component.sel(\n",
    "                                                            hybrid = row['hybrid'], \n",
    "                                                            latitude = row['latitude'], \n",
    "                                                            longitude = row['longitude'], \n",
    "                                                            step = unique_time, method = 'nearest').values \n",
    "                                                            if pd.isnull(row[sensor_column]) else math.nan,\n",
    "                                                            axis = 1)\n",
    "\n",
    "    # Transform 1D-array data to float\n",
    "    match_df['model_component'] = match_df['model_component'].apply(lambda x: float(x))\n",
    "\n",
    "    # Set multiindex again and sort\n",
    "    match_df = match_df.set_index(['time', 'pressure', 'scanline', 'ground_pixel'])\n",
    "    match_df = match_df.sort_values(['time', 'ground_pixel','scanline', 'pressure'], \n",
    "                                    ascending = [True, True, True, False])\n",
    "\n",
    "    # Interpolation\n",
    "    match_df['model_component'] = match_df['model_component'].interpolate()\n",
    "\n",
    "    # Show vertical interpolation for one location\n",
    "    match_df_visualize = match_df\n",
    "\n",
    "    # Drop unnecessary values\n",
    "    match_df = match_df.drop(model_levels['ph [Pa]'].to_numpy(), level = 'pressure')\n",
    "    \n",
    "    model_times = model_ds.valid_time.data\n",
    "    match_df['step_index'] = match_df.apply(lambda row: nearest_neighbour(model_times, row['delta_time']), axis = 1)\n",
    "\n",
    "    # Reset pressure index\n",
    "    match_df = match_df.reset_index('pressure')\n",
    "\n",
    "    return match_df, match_df_visualize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def visualize_interpolation(match_df_visualize, scanline_value, ground_pixel_value):\n",
    "\n",
    "    \"\"\" Visualize interpolated partial columns of the model for a specific location given a scanline and ground pixel\n",
    "\n",
    "        Args:\n",
    "            match_df_visualize (dataframe): Dataframe used to apply averaging kernels with interpolated values\n",
    "            scanline_value (int): Specific location scanline\n",
    "            ground_pixel_value (int): Specific location ground pixel\n",
    "    \"\"\"\n",
    "\n",
    "    # Query to get data for one location\n",
    "    small = match_df.query('scanline == @scanline_value and ground_pixel == @ground_pixel_value')\n",
    "\n",
    "    # Get pressure data\n",
    "    all_pressures = small.index.get_level_values(1).to_numpy()\n",
    "    model_pressures = model_levels['ph [Pa]'].to_numpy()\n",
    "\n",
    "    # Show in black original values and in red the interpolated pressures\n",
    "    diff_colors = np.where(np.isin(all_pressures, model_pressures), 'black', \n",
    "                        np.where(~np.isin(all_pressures, model_pressures), 'red', 'yellow'))\n",
    "\n",
    "    # Show component vs. pressures\n",
    "    plt.scatter(small['model_component'], all_pressures, c = diff_colors, s = 10)\n",
    "\n",
    "    # Revert yaxis to have surface pressure on the bottom\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    ax.set_xlabel(f'{component_nom} (molecules/cm²)', fontsize = 18)\n",
    "    ax.set_ylabel('Pressure (Pa)', fontsize = 18)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}