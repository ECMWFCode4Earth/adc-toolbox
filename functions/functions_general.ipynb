{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_check(sensor, model, component_nom, model_full_name, sensor_type, apply_kernels):\n",
    "\n",
    "    \"\"\" Check if the comparison is possible\n",
    "\n",
    "        Args:\n",
    "            sensor (str): Name of the sensor\n",
    "            model (str): Name of the model\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            model_full_name (str): Full name of the CAMS model among:\n",
    "            - 'cams-global-atmospheric-composition-forecasts' \n",
    "            - 'cams-global-reanalysis-eac4-monthly'\n",
    "            sensor_type (str): Sensor type\n",
    "    \"\"\"\n",
    "\n",
    "    if ((sensor == 'tropomi' and sensor_type == 'L2' and model == 'cams' and model_full_name == 'cams-global-atmospheric-composition-forecasts') or\n",
    "        (sensor == 'tropomi' and sensor_type == 'L3' and model == 'cams' and model_full_name == 'cams-global-reanalysis-eac4-monthly') or \n",
    "        (sensor == 'iasi' and sensor_type == 'L2' and model == 'cams' and model_full_name == 'cams-global-atmospheric-composition-forecasts') or\n",
    "        (sensor == 'iasi' and sensor_type == 'L3' and model == 'cams' and model_full_name == 'cams-global-reanalysis-eac4-monthly') or\n",
    "        (sensor == 'gome' and sensor_type == 'L2' and model == 'cams' and model_full_name == 'cams-global-atmospheric-composition-forecasts') or\n",
    "        (sensor == 'gome' and sensor_type == 'L3' and model == 'cams' and model_full_name == 'cams-global-reanalysis-eac4-monthly')):\n",
    "\n",
    "        if (model_full_name != 'cams-global-atmospheric-composition-forecasts' and\n",
    "            model_full_name != 'cams-global-reanalysis-eac4-monthly'):\n",
    "\n",
    "            print('ERROR: The model is not supported.')\n",
    "            print('The models that are currently supported are:')\n",
    "            print('- cams-global-atmospheric-composition-forecasts')\n",
    "            print('- cams-global-reanalysis-eac4-monthly')\n",
    "            raise KeyboardInterrupt()\n",
    "\n",
    "        else:\n",
    "            \n",
    "            tropomi_L2_kernels_component_nom = ['NO2']\n",
    "            tropomi_L2_component_nom = ['NO2', 'CO', 'O3', 'SO2', 'HCHO']\n",
    "            tropomi_L3_component_nom = ['NO2']\n",
    "            iasi_L2_component_nom = ['CO', 'O3', 'SO2']\n",
    "            iasi_L3_component_nom = ['CO', 'O3']\n",
    "            gome_L2_component_nom = ['NO2', 'O3', 'HCHO', 'SO2']\n",
    "            gome_L3_component_nom = ['NO2']\n",
    "            \n",
    "            if ((sensor == 'tropomi' and sensor_type == 'L2' and component_nom not in tropomi_L2_component_nom) or\n",
    "                (sensor == 'tropomi' and sensor_type == 'L3' and component_nom not in tropomi_L3_component_nom) or\n",
    "                (sensor == 'iasi' and sensor_type == 'L2' and component_nom not in iasi_L2_component_nom) or\n",
    "                (sensor == 'iasi' and sensor_type == 'L3' and component_nom not in iasi_L3_component_nom) or\n",
    "                (sensor == 'gome' and sensor_type == 'L2' and component_nom not in gome_L2_component_nom) or\n",
    "                (sensor == 'gome' and sensor_type == 'L3' and component_nom not in gome_L3_component_nom)):\n",
    "\n",
    "                print(f'ERROR: This specific component cannot be retrieved by the sensor {sensor.upper()} ({sensor_type}).')\n",
    "                raise KeyboardInterrupt()\n",
    "\n",
    "            elif ((apply_kernels == True and sensor == 'tropomi' and component_nom not in tropomi_L2_kernels_component_nom) or\n",
    "                  (apply_kernels == True and sensor != 'tropomi')):\n",
    "\n",
    "                 print('ERROR: It is only possible to apply the averaging kernels from the TROPOMI observations to the CAMS forecasts for NO2 and SO2.')\n",
    "                 print('Please set the variable apply_kernels to False.') \n",
    "                 raise KeyboardInterrupt()\n",
    "\n",
    "            else:\n",
    "\n",
    "                print('The comparison is possible and will start now.')\n",
    "    else:\n",
    "\n",
    "        print('Currently, it is possible to compare:')\n",
    "        print('1 - Forecast data from CAMS model and L2 data from TROPOMI, IASI and GOME-2 sensors.')\n",
    "        print('2 - Reanalysis data from CAMS model and L3 monthly data from TROPOMI, IASI and GOME-2 sensors.')\n",
    "\n",
    "        raise KeyboardInterrupt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def components_table(sensor, component_nom, sensor_type):\n",
    "\n",
    "    \"\"\" Create table with information about the components (molecular weight, full name in different datasets)\n",
    "\n",
    "        Args:\n",
    "            sensor (str): Name of the sensor\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor_type (str): Sensor type\n",
    "\n",
    "        Returns:\n",
    "            component (str): Component name\n",
    "            component_mol_weight (float): Component molecular weight\n",
    "            component_sensor_product (str): Component product name in TROPOMI, IASI or GOME-2 database\n",
    "            sensor_column (str): Component column name in TROPOMI, IASI or GOME-2 database\n",
    "            column_type (str): Tropospheric or total column\n",
    "    \"\"\"\n",
    "\n",
    "    sensor_product_type = None\n",
    "\n",
    "    component_nom_col = ['NO2', 'CO', 'O3', 'SO2', 'CH4', 'HCHO', 'NH3']\n",
    "\n",
    "    component_col = ['nitrogen_dioxide', 'carbon_monoxide', 'ozone', 'sulphur_dioxide', \n",
    "                     'methane', 'formaldehyde', 'ammonia']\n",
    "    component_mol_weight_col = [46.005, 28.01, 48, 64.066, \n",
    "                                16.04, 30.031, 17.031]\n",
    "    component_tropomi_L3_column_col = ['NO2trop', '-', '-', '-', '-', '-', '-']\n",
    "    component_tropomi_L2_column_col = ['nitrogendioxide_tropospheric_column', \n",
    "                                       'carbonmonoxide_total_column', \n",
    "                                       'ozone_total_vertical_column', \n",
    "                                       'sulfurdioxide_total_vertical_column',\n",
    "                                       'methane_tropospheric_column',\n",
    "                                       'formaldehyde_tropospheric_vertical_column',\n",
    "                                       '-'\n",
    "                                       ]\n",
    "    component_tropomi_L2_product_col = ['L2__NO2___', 'L2__CO____', 'L2__O3____', 'L2__SO2___', \n",
    "                                        'L2__CH4___', 'L2__HCHO__', '-']\n",
    "    component_iasi_L3_column_col = ['-', 'COgridDAY', 'O3gridDAY', '-', '-', '-', 'NH3gridDAY']\n",
    "    component_iasi_L2_column_col = ['-', 'CO_total_column', 'O3_total_column', 'SO2_all_altitudes', '-', '-', '']\n",
    "    component_gome_L3_column_col = ['NO2trop', '-', '-', '-', '-', '-', '-']\n",
    "    component_gome_L2_column_col = ['NO2trop', '-', 'O3total', 'SO2total', '-', 'HCHOtotal', '-']\n",
    "\n",
    "    rows = {'Nomenclature': component_nom_col, \n",
    "            'Weight': component_mol_weight_col,\n",
    "            'Component': component_col, \n",
    "            'TROPOMI_L3_column': component_tropomi_L3_column_col,\n",
    "            'TROPOMI_L2_product': component_tropomi_L2_product_col,\n",
    "            'TROPOMI_L2_column': component_tropomi_L2_column_col,\n",
    "            'IASI_L3_column': component_iasi_L3_column_col,\n",
    "            'IASI_L2_column': component_iasi_L2_column_col,\n",
    "            'GOME_L3_column': component_gome_L3_column_col,\n",
    "            'GOME_L2_column': component_gome_L2_column_col}\n",
    "\n",
    "    components_table = pd.DataFrame(rows)\n",
    "\n",
    "    component = components_table['Component'].loc[components_table['Nomenclature'] == component_nom].iloc[0]\n",
    "    component_mol_weight = components_table['Weight'].loc[components_table['Nomenclature'] == component_nom].iloc[0]\n",
    "    \n",
    "    if sensor == 'tropomi' and sensor_type == 'L2':\n",
    "        sensor_product_type = components_table['TROPOMI_L2_product'].loc[components_table['Nomenclature'] == component_nom].iloc[0]\n",
    "\n",
    "    sensor_column = components_table[sensor.upper() + '_' + sensor_type + '_column'].loc[components_table['Nomenclature'] == component_nom].iloc[0]\n",
    "\n",
    "    if 'trop' in sensor_column:\n",
    "        column_type = 'tropospheric'\n",
    "\n",
    "    else:\n",
    "        column_type = 'total'\n",
    "\n",
    "    return component, component_mol_weight, sensor_product_type, sensor_column, column_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_folders(model, sensor, component_nom, sensor_type):\n",
    "\n",
    "    \"\"\" Generate folders to download the datasets if they do not exist \n",
    "\n",
    "        Args:\n",
    "            model (str): Name of the model\n",
    "            sensor (str): Name of the sensor\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor_type (str): Sensor type\n",
    "    \"\"\"\n",
    "\n",
    "    # Model data path\n",
    "    model_path = os.path.join('/', '/'.join(os.getcwd().split('/')[1:3]), 'adc-toolbox', os.path.relpath('data/' + model + '/' + component_nom))\n",
    "\n",
    "    # Sensor data path\n",
    "    if sensor_type == 'L3':\n",
    "        sensor_path = os.path.join('/', '/'.join(os.getcwd().split('/')[1:3]), 'adc-toolbox', os.path.relpath('data/' + sensor + '/' + component_nom + '/L3/'))\n",
    "        \n",
    "    elif sensor_type == 'L2':\n",
    "        sensor_path = os.path.join('/', '/'.join(os.getcwd().split('/')[1:3]), 'adc-toolbox', os.path.relpath('data/' + sensor + '/' + component_nom + '/L2/'))\n",
    "\n",
    "    # Generate paths\n",
    "    paths = [model_path, sensor_path]\n",
    "    for path in paths:\n",
    "        os.makedirs(path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_period(start_date, end_date, sensor, sensor_type):\n",
    "\n",
    "    \"\"\" Give list or tuple with dates that will be used to download the datasets\n",
    "\n",
    "        Args:\n",
    "            start_date (str): Query start date\n",
    "            end_date (str): Query end date\n",
    "            sensor (str): Name of the sensor\n",
    "            sensor_type (str): Sensor type\n",
    "\n",
    "        Returns:\n",
    "            dates (list or tuple): Query dates\n",
    "    \"\"\"\n",
    "\n",
    "    print('SEARCH PERIOD')\n",
    "\n",
    "    range_dt = pd.date_range(np.datetime64(start_date), np.datetime64(end_date))\n",
    "\n",
    "    if (sensor == 'gome' and sensor_type == 'L2') or (sensor == 'iasi' and sensor_type == 'L2'):\n",
    "        dates = tuple(np.unique([date.strftime('%Y-%m-%d') for date in range_dt]))\n",
    "\n",
    "    elif ((sensor == 'gome' and sensor_type == 'L3') or (sensor == 'iasi' and sensor_type == 'L3') or\n",
    "         (sensor == 'tropomi' and sensor_type == 'L3')):\n",
    "        dates = tuple(np.unique([date.strftime('%Y-%m') for date in range_dt]))\n",
    "\n",
    "    elif sensor == 'tropomi' and sensor_type == 'L2':\n",
    "        range_dt_initial = range_dt\n",
    "        range_dt_final = range_dt_initial + dt.timedelta(hours = 23)\n",
    "        dates = list(zip([date.strftime('%Y-%m-%dT%H:%M:%SZ') for date in range_dt_initial], \n",
    "                         [date.strftime('%Y-%m-%dT%H:%M:%SZ') for date in range_dt_final]))\n",
    "\n",
    "    if sensor_type == 'L2':\n",
    "        print(f'- In days: {dates}')\n",
    "\n",
    "    elif sensor_type == 'L3':\n",
    "        print(f'- In months: {dates}')\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_bbox(lon_min, lat_min, lon_max, lat_max):\n",
    "\n",
    "    \"\"\" Generate bounding box from coordinates\n",
    "        \n",
    "        Args:\n",
    "            lon_min (float): Minimum longitude\n",
    "            lat_min (float): Minimum latitude\n",
    "            lon_max (float): Maximum longitude\n",
    "            lat_max (float): Maximum latitude\n",
    "            \n",
    "        Returns:\n",
    "            bbox (arr): Query bounding box\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    bbox = ((lon_min, lat_min), (lon_max, lat_max))\n",
    "\n",
    "    print('SEARCH BOUNDING BOX')\n",
    "    print(f'Latitudes: from {lat_min} to {lat_max}')\n",
    "    print(f'Longitudes: from {lon_min} to {lon_max}')\n",
    "\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_period(sensor, sensor_type, dates, component_nom, *args):\n",
    "\n",
    "    \"\"\" Remove dates if the folders where the dataset had to be downloaded are empty (dataset not available)\n",
    "        \n",
    "        Args:\n",
    "            sensor (str): Name of the sensor\n",
    "            sensor_type (str): Sensor type\n",
    "            dates (list): Query dates\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            *args: satellites\n",
    "            \n",
    "        Returns:\n",
    "            dates (list or tuple): Available dates\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    dates_to_delete = []\n",
    "\n",
    "    for date in dates:\n",
    "        \n",
    "        if sensor_type == 'L3':\n",
    "            output_path = os.path.join('/', '/'.join(os.getcwd().split('/')[1:3]), 'adc-toolbox', \n",
    "                          os.path.relpath('data/' + sensor + '/' + component_nom + '/L3/' + date))\n",
    "\n",
    "        elif sensor_type == 'L2':\n",
    "            output_path = os.path.join('/', '/'.join(os.getcwd().split('/')[1:3]), 'adc-toolbox', \n",
    "                          os.path.relpath('data/' + sensor + '/' + component_nom + '/L2/' + date))\n",
    "\n",
    "        if not os.listdir(output_path):\n",
    "            os.rmdir(output_path)\n",
    "            dates_to_delete.append(date)\n",
    "\n",
    "        if sensor_type == 'L2' and sensor == 'gome':\n",
    "            for satellite in satellites:\n",
    "                if not os.listdir(output_path + '/' + satellite):\n",
    "                    os.rmdir(output_path+ '/' + satellite)\n",
    "\n",
    "    dates_to_keep = np.setdiff1d(dates, np.array(dates_to_delete))\n",
    "    dates = tuple(dates_to_keep)\n",
    "    \n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_download(sensor, sensor_type, component_nom, dates, *args):\n",
    "\n",
    "    \"\"\" Download sensor datasets\n",
    "\n",
    "        Args:\n",
    "            sensor (str): Name of the sensor\n",
    "            sensor_type (str): Sensor type\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            dates (list or tuple): Available dates\n",
    "            *args: bbox, satellites or product_type\n",
    "\n",
    "        Returns:\n",
    "            dates (list): Available dates\n",
    "    \"\"\" \n",
    "\n",
    "    print('RESULTS')\n",
    "    \n",
    "    if sensor == 'tropomi':\n",
    "\n",
    "        for date in dates:\n",
    "\n",
    "            if sensor_type == 'L2':\n",
    "\n",
    "                print(f'For {date}:')\n",
    "                input_type = 'Query'\n",
    "                TROPOMI_L2_download(input_type, bbox, date, product_type, component_nom)\n",
    "\n",
    "            elif sensor_type == 'L3':\n",
    "                TROPOMI_L3_download(date, component_nom)\n",
    "        \n",
    "        if sensor_type == 'L3':\n",
    "            dates = available_period(sensor, sensor_type, dates, component_nom)\n",
    "\n",
    "    elif sensor == 'iasi' or sensor == 'gome':\n",
    "        \n",
    "        for date in dates:\n",
    "            \n",
    "            print(f'For {date}:')\n",
    "\n",
    "            for satellite in satellites:\n",
    "\n",
    "                if sensor == 'iasi' and sensor_type == 'L2':\n",
    "                    IASI_L2_download(component_nom, date, satellite)\n",
    "\n",
    "                elif sensor == 'iasi' and sensor_type == 'L3':\n",
    "                    IASI_L3_download(component_nom, date, satellite)\n",
    "        \n",
    "                elif sensor == 'gome' and sensor_type == 'L2':\n",
    "                    GOME_L2_download(component_nom, date, satellite)\n",
    "\n",
    "                elif sensor == 'gome' and sensor_type == 'L3':\n",
    "                    #GOME_L3_download_AC_SAF(component_nom, date, satellite)\n",
    "                    GOME_L3_download_TEMIS(component_nom, date, satellite)\n",
    "\n",
    "        dates = available_period(sensor, sensor_type, dates, component_nom, satellites)\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_read(sensor, sensor_type, sensor_column, component_nom, dates, *args):\n",
    "\n",
    "    \"\"\" Read sensor datasets as xarray dataset objects\n",
    "\n",
    "        Args:\n",
    "            sensor (str): Name of the sensor\n",
    "            sensor_type (str): Sensor type\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            dates (list or tuple): Available dates\n",
    "            *args: satellites, lat_res, lon_res\n",
    "\n",
    "        Returns:\n",
    "            sensor_ds (xarray): sensor dataset in xarray format\n",
    "            support_input_ds (xarray): TROPOMI dataset that contains support input data in xarray format\n",
    "            support_details_ds (xarray): TROPOMI dataset that contains support details data in xarray format\n",
    "    \"\"\" \n",
    "    \n",
    "    support_input_ds = None\n",
    "    support_details_ds = None\n",
    "\n",
    "    if dates:\n",
    "\n",
    "        if sensor == 'tropomi' and sensor_type == 'L2':\n",
    "            sensor_ds, support_input_ds, support_details_ds = TROPOMI_L2_read(component_nom, sensor_column, dates)\n",
    "        \n",
    "        elif sensor == 'tropomi' and sensor_type == 'L3':\n",
    "            sensor_ds = TROPOMI_L3_read(component_nom, dates, lat_res, lon_res)\n",
    "\n",
    "        elif sensor == 'iasi' and sensor_type == 'L2':\n",
    "            sensor_ds = IASI_L2_read(component_nom, sensor_column, dates, lat_res, lon_res)\n",
    "\n",
    "        elif sensor == 'iasi' and sensor_type == 'L3':\n",
    "            sensor_ds = IASI_L3_read(component_nom, sensor_column, dates, lat_res, lon_res)\n",
    "\n",
    "        elif sensor == 'gome' and sensor_type == 'L2':\n",
    "            sensor_ds = GOME_L2_read(component_nom, dates, lat_res, lon_res)\n",
    "\n",
    "        elif sensor == 'gome' and sensor_type == 'L3':\n",
    "            #sensor_ds = GOME_L3_read_AC_SAF(component_nom, sensor_column, dates, lat_res, lon_res)\n",
    "            sensor_ds = GOME_L3_read_TEMIS(component_nom, dates, lat_res, lon_res)\n",
    "\n",
    "    else:\n",
    "        print('The datasets could not be downloaded for the dates that were queried.')\n",
    "        \n",
    "    return sensor_ds, support_input_ds, support_details_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_convert_units(sensor_ds, sensor, component_nom):\n",
    "\n",
    "    \"\"\" Convert the units of the sensor dataset for any component from mol/m2 to molecules/cm2\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): sensor dataset in xarray format (TROPOMI, IASI or GOME-2)\n",
    "            sensor (str): Name of the sensor\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            \n",
    "        Returns:\n",
    "            sensor_ds (xarray): sensor dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if sensor == 'tropomi':\n",
    "        \n",
    "        if sensor_ds['sensor_column'].units == 'mol m-2':\n",
    "\n",
    "            sensor_ds['sensor_column'] = sensor_ds['sensor_column'] * 6.02214*10**19\n",
    "            sensor_ds['sensor_column'] = sensor_ds['sensor_column'].assign_attrs({'units': 'molec cm-2'})\n",
    "            print('The sensor component units have been converted from mol m-2 to molec cm-2.')\n",
    "            \n",
    "            if 'apriori_profile' in list(sensor_ds.keys()):\n",
    "                sensor_ds['apriori_profile'] = sensor_ds['apriori_profile'] * 6.02214*10**19\n",
    "\n",
    "            if sensor_ds['sensor_column'].units == 'molec cm-2' and component == 'ozone':\n",
    "                sensor_ds['sensor_column'] = sensor_ds['sensor_column'] / (2.69*10**16)\n",
    "                sensor_ds['sensor_column'] = sensor_ds['sensor_column'].assign_attrs({'units': 'DU'})\n",
    "                print('The sensor component units have been converted from molec cm-2 to DU.')\n",
    "\n",
    "                if 'apriori_profile' in list(sensor_ds.keys()):\n",
    "                    sensor_ds['apriori_profile'] = sensor_ds['apriori_profile'] / (2.69*10**16)\n",
    "    \n",
    "    elif sensor == 'iasi':\n",
    "        \n",
    "        if sensor_ds.units == 'mol m-2':\n",
    "\n",
    "            sensor_ds = sensor_ds * 6.02214*10**19\n",
    "            sensor_ds = sensor_ds.assign_attrs({'units': 'molec cm-2'})\n",
    "            print('The sensor component units have been converted from mol m-2 to molec cm-2.')\n",
    "\n",
    "        if sensor_ds.units == 'molec cm-2' and (component_nom == 'O3' or component_nom == 'SO2'):\n",
    "            sensor_ds = sensor_ds / (2.69*10**16)\n",
    "            sensor_ds = sensor_ds.assign_attrs({'units': 'DU'})\n",
    "            print('The sensor component units have been converted from molec cm-2 to DU.')\n",
    "\n",
    "    return sensor_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_convert_units(model, model_ds, sensor, component_mol_weight, model_levels_df, \n",
    "                        start_date, end_date, component_nom, apply_kernels = False, \n",
    "                        CAMS_UID = None, CAMS_key = None):\n",
    "\n",
    "    \"\"\" Convert the units of the model dataset for any component from kg/kg or kg/m2 to molecules/cm2\n",
    "\n",
    "        Args:\n",
    "            model (str): Name of the model\n",
    "            model_ds (xarray): model dataset in xarray format (CAMS)\n",
    "            sensor (str): Name of the sensor\n",
    "            component_mol_weight (float): Component molecular weight\n",
    "            model_levels_df (dataframe): Table with 137 CAMS levels data\n",
    "            start_date (str): Query start date\n",
    "            end_date (str): Query end date\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            apply_kernels (bool): Apply (True) or not (False) the averaging kernels \n",
    "            CAMS_UID (str): ADS user ID\n",
    "            CAMS_key (str): ADS key\n",
    "            \n",
    "        Returns:\n",
    "            model_ds (xarray): model dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if model == 'cams':\n",
    "\n",
    "        if model_ds.component.units == 'kg kg**-1':\n",
    "\n",
    "            model_ds = CAMS_kg_kg_to_kg_m2(model_ds, model_levels_df, sensor, start_date, \n",
    "                                           end_date, component_nom, apply_kernels, CAMS_UID, CAMS_key)\n",
    "            units = 'kg m**-2'\n",
    "            model_ds['component'] = model_ds.component.assign_attrs({'units': units})\n",
    "            print('The model component units have been converted from kg kg**-1 to kg m**-2.')\n",
    "\n",
    "        if model_ds.component.units == 'kg m**-2':\n",
    "\n",
    "            model_ds = CAMS_kg_m2_to_molecules_cm2(model_ds, component_mol_weight)\n",
    "            units = 'molec cm-2'\n",
    "            model_ds['component'] = model_ds.component.assign_attrs({'units': units})\n",
    "            print('The model component units have been converted from kg m**-2 to molec cm-2.')\n",
    "        \n",
    "        if model_ds.component.units == 'molec cm-2' and (component_nom == 'O3' or component_nom == 'SO2'):\n",
    "\n",
    "            model_ds = CAMS_molecules_cm2_to_DU(model_ds)\n",
    "            units = 'DU'\n",
    "            model_ds['component'] = model_ds.component.assign_attrs({'units': units})\n",
    "            print('The model component units have been converted from molec cm-2 to DU.')\n",
    "           \n",
    "        else:\n",
    "            units = 'molec cm-2'\n",
    "\n",
    "    return model_ds, units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbour(array, value):\n",
    "\n",
    "    \"\"\" Find index of the closest value in a 1D-array\n",
    "\n",
    "        Args:\n",
    "            array (arr): Array to find the nearest neighbour\n",
    "            value (float): Search value\n",
    "    \"\"\"\n",
    "\n",
    "    index = np.abs([x - value for x in array]).argmin(0)\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_point(point, array):\n",
    "\n",
    "    \"\"\" Find pair the closest values in a 2D-array\n",
    "\n",
    "        Args:\n",
    "            array (arr): Array to find the nearest neighbour\n",
    "            point (tuple): Search coordinates\n",
    "    \"\"\"\n",
    "\n",
    "    pair = array[cdist([point], array).argmin()]\n",
    "\n",
    "    return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(array):\n",
    "\n",
    "    \"\"\" Split array in pairs\n",
    "\n",
    "        Args:\n",
    "            array (arr): Dates, coordinates list, etc.\n",
    "\n",
    "        Returns:\n",
    "            period (tuple): Divisible dates into pairs\n",
    "    \"\"\"\n",
    "\n",
    "    pair_element = iter(array)\n",
    "    period = list(zip(pair_element, pair_element))\n",
    "\n",
    "    return period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning(ds, lat_res, lon_res):\n",
    "\n",
    "    \"\"\" Regrid onto a custom defined regular grid\n",
    "\n",
    "        Args:\n",
    "            array (xarray): Dataset as xarray \n",
    "            lat_res (float): Spatial resolution for latitude\n",
    "            lon_res (float): Spatial resolution for longitude\n",
    "\n",
    "        Returns:\n",
    "            array (xarray): Dataset as xarray (with regridded coordinates)\n",
    "    \"\"\"\n",
    "\n",
    "    lat_bins = np.arange(-90, 90 + lat_res/2, lat_res)\n",
    "    lon_bins = np.arange(-180, 180 + lon_res/2, lon_res)\n",
    "\n",
    "    lat_center = np.arange(-90 + lat_res/2, 90, lat_res)\n",
    "    lon_center = np.arange(-180 + lon_res/2, 180, lon_res)\n",
    "\n",
    "    ds = ds.groupby_bins('latitude', lat_bins, labels = lat_center).mean()\n",
    "    ds = ds.groupby_bins('longitude', lon_bins, labels = lon_center).mean()\n",
    "    ds = ds.rename({'latitude_bins': 'latitude', 'longitude_bins': 'longitude'})\n",
    "    ds\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset(ds, bbox, sensor, component_nom, sensor_type, subset_type):\n",
    "\n",
    "    \"\"\" Subset any dataset (with latitude and longitude as coordinates) into desired bounding box.\n",
    "\n",
    "        Args:\n",
    "            ds (xarray): Dataset in xarray format\n",
    "            bbox (arr): Query bounding box\n",
    "            sensor (str): Name of the sensor\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor_type (str): Sensor type\n",
    "            subset_type (str):\n",
    "            -  'sensor_subset': Sensor dataset will be subset\n",
    "            -  'model_subset': Model dataset will be subset\n",
    "    \n",
    "        Returns:\n",
    "            ds (xarray): Dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if sensor == 'tropomi' and sensor_type == 'L2' and subset_type == 'sensor_subset':\n",
    "\n",
    "        ds = TROPOMI_subset(ds, bbox, component_nom)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Get nearest longitude and latitude to bbox\n",
    "        lon_min_index = nearest_neighbour(ds.longitude.data, bbox[0][0])\n",
    "        lon_max_index = nearest_neighbour(ds.longitude.data, bbox[1][0])\n",
    "        lat_min_index = nearest_neighbour(ds.latitude.data, bbox[0][1])\n",
    "        lat_max_index = nearest_neighbour(ds.latitude.data, bbox[1][1])\n",
    "\n",
    "        # Define slices\n",
    "        slice_lat = slice(lat_min_index, lat_max_index + 1)\n",
    "        slice_lon = slice(lon_min_index, lon_max_index + 1)\n",
    "\n",
    "        # Set limits\n",
    "        ds = ds.isel(longitude = slice_lon, latitude = slice_lat)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(match_df_time, sensor, component_nom, time, sensor_type):\n",
    "\n",
    "    \"\"\" Prepare dataframe for match\n",
    "\n",
    "        Args:\n",
    "            match_df_time (dataframe): Dataframe used to apply averaging kernels\n",
    "            sensor (str): Name of the sensor\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            time (timestamp): Current time\n",
    "            sensor_type (str): Sensor type\n",
    "        \n",
    "        Returns:\n",
    "            match_df_time (dataframe): Dataframe used to apply averaging kernels\n",
    "    \"\"\"\n",
    "\n",
    "    if sensor == 'tropomi' and sensor_type == 'L2':\n",
    "\n",
    "        # Pass NaNs to data with qa_value under 0.5 (these values will be shown as transparent)\n",
    "        match_df_time.loc[match_df_time['qa_value'] <= 0.5, ['sensor_column', 'column_kernel']] = float('NaN')\n",
    "\n",
    "        # Drop levels\n",
    "        if component_nom == 'CO' or component_nom == 'SO2':\n",
    "            \n",
    "            match_df_time.index.names = ['corner', 'ground_pixel', 'layer', 'scanline']\n",
    "        \n",
    "        elif component_nom == 'O3':\n",
    "\n",
    "            match_df_time.index.names = ['corner', 'ground_pixel', 'layer', 'level', 'scanline']\n",
    "            \n",
    "        match_df_time = match_df_time.groupby(by = ['layer', 'scanline', 'ground_pixel', 'time', 'delta_time']).mean()\n",
    "        match_df_time = match_df_time.reset_index(level = ['layer', 'delta_time'])\n",
    "\n",
    "    elif sensor == 'iasi' or sensor == 'gome' or (sensor == 'tropomi' and sensor_type == 'L3'):\n",
    "\n",
    "        match_df_time = match_df_time.reset_index(level = ['latitude', 'longitude'])\n",
    "        \n",
    "        if (sensor == 'gome' or sensor == 'tropomi') and sensor_type == 'L2':\n",
    "\n",
    "            year = time.astype('datetime64[D]').astype(str).split('-')[0]\n",
    "            month = time.astype('datetime64[D]').astype(str).split('-')[1]\n",
    "            day = time.astype('datetime64[D]').astype(str).split('-')[2]\n",
    "            match_df_time['delta_time'] = match_df_time['delta_time'].fillna(value = dt.datetime(\n",
    "                                                                                     int(year), \n",
    "                                                                                     int(month), \n",
    "                                                                                     int(day), \n",
    "                                                                                     12, 0, 0))\n",
    "        \n",
    "    return match_df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_match_df(sensor_ds, model_ds, bbox, sensor, component_nom, sensor_type, apply_kernels = False):\n",
    "\n",
    "    \"\"\" Intermediate merge table with total column or partial column from both datasets, \n",
    "        the averaging kernels are applied if possible\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): sensor dataset in xarray format (TROPOMI, IASI or GOME-2)\n",
    "            model_ds (xarray): model dataset in xarray format (CAMS)\n",
    "            bbox (arr): Query bounding box\n",
    "            sensor (str): Name of the sensor\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            apply_kernels (bool): Apply (True) or not (False) the averaging kernels \n",
    "\n",
    "        Returns:\n",
    "            match_df (dataframe): Intermediate merge table with total column or partial column from both datasets\n",
    "    \"\"\"\n",
    "    \n",
    "    match_df = pd.DataFrame()\n",
    "\n",
    "    if sensor == 'tropomi' and sensor_type == 'L2' and apply_kernels == True:\n",
    "\n",
    "        print('APPLICATION OF AVERAGING KERNELS')\n",
    "        print('For the application of the averaging kernels, it is necessary to calculate:')\n",
    "        print('1. Level pressures')\n",
    "        print('2. Column kernels')\n",
    "        print('The apriori profiles should be retrieved, but they are not necessary.')\n",
    "\n",
    "        # Calculate TM5 level pressures, column kernels and apriori profiles\n",
    "        print('DATA AVAILABILITY')\n",
    "        sensor_ds = TROPOMI_pressure(sensor_ds, component_nom, support_input_ds, support_details_ds)\n",
    "        sensor_ds = TROPOMI_column_kernel(sensor_ds, component_nom, support_details_ds)\n",
    "        sensor_ds = TROPOMI_apriori_profile(sensor_ds, component_nom, component, support_details_ds)\n",
    "\n",
    "    for time in sensor_ds.time.values:\n",
    "        \n",
    "        # Print estimated time or month\n",
    "        if sensor_type == 'L2':\n",
    "            day = np.datetime64(time).astype('datetime64[D]')\n",
    "            print(f'FOR DATE: {day}')\n",
    "\n",
    "        elif sensor_type == 'L3':\n",
    "            month = np.datetime64(time).astype('datetime64[M]')\n",
    "            print(f'FOR MONTH: {month}')\n",
    "\n",
    "        # Reduce data to only one timestamp\n",
    "        model_ds_time = model_ds.sel(time = time)\n",
    "        sensor_ds_time = sensor_ds.sel(time = time)\n",
    "\n",
    "        # Subset sensor dataset\n",
    "        sensor_ds_time = subset(sensor_ds_time, bbox, sensor, component_nom, \n",
    "                                sensor_type, subset_type = 'sensor_subset')\n",
    "        \n",
    "        # Transform sensor data into dataframe and prepare it for merging it with the model data\n",
    "        match_df_time = sensor_ds_time.to_dataframe()\n",
    "        match_df_time = prepare_df(match_df_time, sensor, component_nom, time, sensor_type)\n",
    "        \n",
    "        if sensor == 'tropomi' and 'column_kernel' in list(sensor_ds.keys()) and apply_kernels == True:\n",
    "            \n",
    "            match_df_time = TROPOMI_apply_kernels(match_df_time, model_ds_time, sensor_ds_time, component_nom)\n",
    "            \n",
    "        else:\n",
    "\n",
    "            if apply_kernels == True:\n",
    "                print('The application of the averaging kernels cannot take place because there is not enough data.')\n",
    "            \n",
    "            # Get model timesteps\n",
    "            model_times = model_ds_time.valid_time.data\n",
    "\n",
    "            if 'hybrid' in list(model_ds.coords):\n",
    "\n",
    "                print('The partial columns will be sumed up.')\n",
    "                print('The sum will be matched to the sensor data by nearest neighbours.')\n",
    "\n",
    "                model_ds_time = model_ds_time.component.sum(dim = 'hybrid', skipna = False)\n",
    "               \n",
    "                match_df_time['step_index'] = match_df_time.apply(lambda row: nearest_neighbour(model_times, row['delta_time']), axis = 1)\n",
    "                match_df_time['model_time'] = match_df_time.apply(lambda row: model_ds_time.valid_time[row['step_index']].values, axis = 1)\n",
    "                match_df_time['model_column'] = match_df_time.apply(lambda row: model_ds_time.sel(\n",
    "                                                                                latitude = row['latitude'], \n",
    "                                                                                longitude = row['longitude'],\n",
    "                                                                                method = 'nearest').isel(step = \n",
    "                                                                                int(row['step_index'])).values, \n",
    "                                                                                axis = 1)\n",
    "   \n",
    "                match_df_time = match_df_time.set_index('layer', append = True)\n",
    "                \n",
    "            else:\n",
    "\n",
    "                print('The model dataset does not contain levels data.')\n",
    "                print('The model dataset will be merged with the sensor dataset by nearest neighbours.')\n",
    "\n",
    "                # Monthly data\n",
    "                if 'step' not in list(model_ds.dims):\n",
    "                    \n",
    "                    match_df_time['model_column'] = match_df_time.apply(lambda row: float(model_ds_time.sel(\n",
    "                                                                                    latitude = row['latitude'], \n",
    "                                                                                    longitude = row['longitude'],\n",
    "                                                                                    method = 'nearest').component.values), \n",
    "                                                                                    axis = 1)\n",
    "                # Hourly / Daily data\n",
    "                else:\n",
    "\n",
    "                    match_df_time['step_index'] = match_df_time.apply(lambda row: nearest_neighbour(model_times, row['delta_time']), axis = 1)\n",
    "                    match_df_time['model_column'] = match_df_time.apply(lambda row: float(model_ds_time.sel(\n",
    "                                                                                    latitude = row['latitude'], \n",
    "                                                                                    longitude = row['longitude'],\n",
    "                                                                                    method = 'nearest').isel(step = \n",
    "                                                                                    int(row['step_index'])).component.values), \n",
    "                                                                                    axis = 1)\n",
    "\n",
    "        match_df_time = match_df_time[~match_df_time.index.duplicated()]\n",
    "        match_df = match_df.append(match_df_time)\n",
    "\n",
    "    return match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_merge_df(match_df, sensor_ds, model_ds, sensor, apply_kernels = False):\n",
    "\n",
    "    \"\"\" Final merge table with total column component data for each dataset, \n",
    "        their difference in each grid point are calculated\n",
    "\n",
    "        Args:\n",
    "            match_df (dataframe): Intermediate merge table with total column or partial column from both datasets\n",
    "            sensor_ds (xarray): sensor dataset in xarray format (TROPOMI, IASI or GOME-2)\n",
    "            model_ds (xarray): model dataset in xarray format (CAMS)\n",
    "            apply_kernels (bool): Apply (True) or not (False) the averaging kernels\n",
    "            sensor (str): Name of the sensor\n",
    "        \n",
    "        Returns:\n",
    "            merge_df (dataframe): Merge table with datasets column data and their difference\n",
    "    \"\"\"\n",
    "\n",
    "    merge_df = []\n",
    "\n",
    "    if 'hybrid' in list(model_ds.coords):\n",
    "\n",
    "        for time in sensor_ds.time.values:\n",
    "\n",
    "            match_ds_time = match_df.query('time == @time').to_xarray()\n",
    "\n",
    "            # Read latitudes and longitudes from data array\n",
    "            latitude = match_ds_time.sel(time = time).latitude.mean(dim = 'layer')\n",
    "            longitude = match_ds_time.sel(time = time).longitude.mean(dim = 'layer')\n",
    "\n",
    "            # Get sum of CAMS data of each layer to get column data\n",
    "            if 'column_kernel' in list(match_ds_time.keys()) and apply_kernels == True:\n",
    "                model_final_ds_time = match_ds_time.sel(time = time).model_column.sum(dim = 'layer', skipna = False).astype(float)\n",
    "\n",
    "            else:\n",
    "                model_final_ds_time = match_ds_time.sel(time = time).model_column.mean(dim = 'layer', skipna = False).astype(float)\n",
    "\n",
    "            model_final_ds_time = model_final_ds_time.assign_coords(latitude = latitude, longitude = longitude)\n",
    "\n",
    "            # Get mean of TROPOMI data of each layer (it must be equal)\n",
    "            sensor_final_ds_time = match_ds_time.sensor_column.sel(time = time).mean(dim = 'layer', skipna = False).astype(float)\n",
    "            sensor_final_ds_time = sensor_final_ds_time.assign_coords(latitude = latitude, longitude = longitude)\n",
    "\n",
    "            merge_ds_time = xr.merge([model_final_ds_time, sensor_final_ds_time])\n",
    "            merge_ds_time['difference'] = merge_ds_time.model_column - merge_ds_time.sensor_column\n",
    "            merge_ds_time['relative_difference'] = (merge_ds_time.model_column - merge_ds_time.sensor_column)/merge_ds_time.sensor_column\n",
    "            merge_df.append(merge_ds_time.to_dataframe())\n",
    "\n",
    "        merge_df = pd.concat(merge_df)\n",
    "\n",
    "    else:\n",
    "\n",
    "        merge_df = match_df\n",
    "        merge_df['difference'] = merge_df['model_column'] - merge_df['sensor_column']\n",
    "        merge_df['relative_difference'] = (merge_df.model_column - merge_df.sensor_column)/merge_df.sensor_column\n",
    "\n",
    "    # Organize dataset for visualization\n",
    "    if sensor == 'tropomi' and sensor_type == 'L2':\n",
    "        merge_df = merge_df.reset_index().set_index(['scanline', 'ground_pixel', 'time'])\n",
    "        merge_df = merge_df[['latitude', 'longitude', 'model_column', 'sensor_column', 'difference', 'relative_difference']]\n",
    "\n",
    "    else:\n",
    "        merge_df = merge_df.reset_index().set_index(['latitude', 'longitude', 'time'])\n",
    "        merge_df = merge_df[['model_column', 'sensor_column', 'difference', 'relative_difference']]\n",
    "    \n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_period(sensor_ds, sensor_type):\n",
    "\n",
    "    \"\"\" Define plot period\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): sensor dataset in xarray format (TROPOMI, IASI or GOME-2)\n",
    "            sensor_type (str): Sensor type\n",
    "\n",
    "        Returns:\n",
    "            plot_dates (arr): Plot dates\n",
    "    \"\"\"\n",
    "\n",
    "    period_answer = input('Do you want to visualize the plots for specific dates? Press Enter for Yes or write No:')\n",
    "    dates = sensor_ds.time.values\n",
    "\n",
    "    if period_answer == 'No' or period_answer == 'no':\n",
    "        plot_dates = dates\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        plot_dates = []\n",
    "\n",
    "        for date in dates:\n",
    "            date_answer = input('Do you want to show the plots for ' + str(date) + '? Press Enter for Yes or write No:')    \n",
    "            if date_answer == 'No' or date_answer == 'no':\n",
    "                pass\n",
    "            else:\n",
    "                plot_dates.append(date)\n",
    "\n",
    "        plot_dates = np.array(plot_dates)\n",
    "\n",
    "    print('The plots will be shown for the following dates:')\n",
    "    if sensor_type == 'L2':\n",
    "        print(plot_dates.astype('datetime64[D]'))\n",
    "    \n",
    "    elif sensor_type == 'L3':\n",
    "        print(plot_dates.astype('datetime64[M]'))\n",
    "\n",
    "    return plot_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_extent(bbox):\n",
    "\n",
    "    \"\"\" Define plot extent\n",
    "\n",
    "        Args:\n",
    "            bbox (arr): Query bounding box\n",
    "\n",
    "        Returns:\n",
    "            plot_bbox (arr): Plot bounding box\n",
    "    \"\"\"\n",
    "\n",
    "    extent_answer = input(f'Do you want to visualize the plots for a specific extent? Press Enter for Yes or write No (default {bbox}):')\n",
    "\n",
    "    if extent_answer == 'No' or extent_answer == 'no':\n",
    "        plot_bbox = ((bbox[0][0], bbox[0][1]), (bbox[1][0], bbox[1][1]))\n",
    "\n",
    "    else:\n",
    "        # Define minimum longitude\n",
    "        plot_lon_min = float(input('Write value of minimum longitude: '))\n",
    "        while (plot_lon_min < bbox[0][0]) or (plot_lon_min > bbox[1][0]):\n",
    "            print(f'ERROR: Longitude must be between {bbox[0][0]} and {bbox[1][0]}.')\n",
    "            plot_lon_min = float(input('Write value of minimum longitude (again): '))\n",
    "\n",
    "        # Define maximum longitude\n",
    "        plot_lon_max = float(input('Write value of maximum longitude: '))\n",
    "        while (plot_lon_max < bbox[0][0]) or (plot_lon_max > bbox[1][0]) or (plot_lon_max <= plot_lon_min):\n",
    "            print(f'ERROR: Longitude must be between {bbox[0][0]} and {bbox[1][0]} and be higher than the minimum {plot_lon_min}.')\n",
    "            plot_lon_max = float(input('Write value of maximum longitude (again): '))\n",
    "\n",
    "        # Define minimum latitude\n",
    "        plot_lat_min = float(input('Write value of minimum latitude: '))\n",
    "        while (plot_lat_min < bbox[0][1]) or (plot_lat_min > bbox[1][1]):\n",
    "            print(f'ERROR: Latitude must be between {bbox[0][1]} and {bbox[1][1]}.')\n",
    "            plot_lat_min = float(input('Write value of minimum latitude (again): '))\n",
    "\n",
    "        # Define maximum latitude\n",
    "        plot_lat_max = float(input('Write value of maximum latitude: '))\n",
    "        while (plot_lat_max < bbox[0][1]) or (plot_lat_max > bbox[1][1]) or (plot_lat_max <= plot_lat_min):\n",
    "            print(f'ERROR: Latitude must be between {bbox[0][1]} and {bbox[1][1]} and be higher than the minimum {plot_lat_min}.')\n",
    "            plot_lat_max = float(input('Write value of maximum latitude (again): '))\n",
    "\n",
    "        # Define plot bbox\n",
    "        plot_bbox = ((plot_lon_min, plot_lat_min), (plot_lon_max, plot_lat_max))\n",
    "\n",
    "    print('The plots will be shown for the following spatial extent: ')\n",
    "    print(plot_bbox)\n",
    "    \n",
    "    return plot_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorbar_range(range_type, array, diff_array, max_all, min_all, max_all_diff, min_all_diff,\n",
    "                   vmin_manual, vmax_manual, vmin_manual_diff, vmax_manual_diff):\n",
    "\n",
    "    \"\"\" Define colorbar range\n",
    "\n",
    "        Args:\n",
    "            range_type (str): Range type for colorbar:\n",
    "            -  'original': Show original values in range\n",
    "            -  'equal': Show same scale in range\n",
    "            -  'manual': Show scale in range given by user\n",
    "            -  'centered': Show scale centered in 0\n",
    "            array (xarray): Component for a specific time and model/sensor\n",
    "            diff_array (xarray): Difference for a specific time\n",
    "            min_all (float): Absolute vmin\n",
    "            max_all (float): Absolute vmax\n",
    "            min_all_diff (float): Absolute vmin for difference values\n",
    "            max_all_diff (float): Absolute vmax for difference values \n",
    "            vmin_manual (float): Input vmin by user\n",
    "            vmax_manual (float): Input vmax by user\n",
    "            vmin_manual_diff (float): Input vmin by user for difference values\n",
    "            vmax_manual_diff (float): Input vmax by user for difference values\n",
    "            \n",
    "        Returns:\n",
    "            vmin, vmax (float): Limits of color bar\n",
    "    \"\"\"\n",
    "    \n",
    "    # The colorbar for the absolute difference will be defined\n",
    "    if np.array_equal(array, diff_array, equal_nan = True) == True:\n",
    "        \n",
    "        if vmin_manual_diff == None and vmax_manual_diff == None:\n",
    "            if np.abs(max_all_diff) >= np.abs(min_all_diff):\n",
    "                \n",
    "                vmin = -np.abs(max_all_diff)\n",
    "                vmax = np.abs(max_all_diff)\n",
    "\n",
    "            elif np.abs(max_all_diff) < np.abs(min_all_diff):\n",
    "                \n",
    "                vmin = -np.abs(min_all_diff)\n",
    "                vmax = np.abs(min_all_diff)\n",
    "        else:\n",
    "            vmin = vmin_manual_diff\n",
    "            vmax = vmax_manual_diff\n",
    "\n",
    "    # The colorbar will show the original range\n",
    "    elif range_type == 'original':\n",
    "      \n",
    "        vmin = np.nanmin(array)\n",
    "        vmax = np.nanmax(array)\n",
    "\n",
    "    # The colorbar will be in the same scale for both datasets\n",
    "    elif range_type == 'equal':\n",
    "       \n",
    "        vmin = min_all\n",
    "        vmax = max_all\n",
    "    \n",
    "    # The colorbar will be in the scale given by the user\n",
    "    elif range_type == 'manual':\n",
    "       \n",
    "        if vmin_manual == None or vmax_manual == None:\n",
    "            print('ERROR: vmin_manual and vmax_manual have to be defined and cannot be None.')\n",
    "            raise KeyboardInterrupt()\n",
    "            \n",
    "        else:\n",
    "            vmin = vmin_manual\n",
    "            vmax = vmax_manual\n",
    "\n",
    "    # The colorbar will be centered at 0\n",
    "    elif range_type == 'centered':\n",
    "        if np.abs(max_all) >= np.abs(min_all):\n",
    "        \n",
    "            vmin = -np.abs(max_all)\n",
    "            vmax = np.abs(max_all)\n",
    "\n",
    "        elif np.abs(max_all) < np.abs(min_all):\n",
    "            \n",
    "            vmin = -np.abs(min_all)\n",
    "            vmax = np.abs(min_all)\n",
    "\n",
    "    return vmin, vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_possible_lengths(loc_min, loc_max):\n",
    "\n",
    "    \"\"\" Get lengths of the frame partitions (white / black) for which the frame \n",
    "        is well adjusted to the minimum and maximum coordinates\n",
    "\n",
    "        Args:\n",
    "            loc_min (float): Minimum latitude or longitude of frame (it should be an integer).\n",
    "            loc_max (float): Maximum latitude or longitude of frame (it should be an integer).\n",
    "\n",
    "        Returns:\n",
    "            options (array): Possible lengths that will be well adjusted to the frame\n",
    "    \"\"\"\n",
    "\n",
    "    number = np.abs(loc_max - loc_min)\n",
    "    options = []\n",
    "\n",
    "    if 0 < number <= 1:\n",
    "        number_loop = int(number * 10)\n",
    "    else:\n",
    "        number_loop = int(number)\n",
    "\n",
    "    for divisor in range(1, number_loop + 1):\n",
    "        if (number_loop % divisor) == 0:\n",
    "            if 0 < number <= 1 or (0 < number < 1 and (number * 10).is_integer() == True):\n",
    "                divisor = divisor / 10\n",
    "            options.append(divisor)\n",
    "\n",
    "    if options:\n",
    "        print(f'Frame length between {loc_min} and {loc_max} should be one of these options: {options}')\n",
    "    else:\n",
    "        print(f'Frame length suggestions could not be computed. Consider changing your bounding box to be at least 1ºx1º or to be composed by integer coordinates.')\n",
    "        print(f'Alternatively, you can inactivate the map frame by removing the following line in the function visualize_pcolormesh:')\n",
    "        print(f'axs = map_frame(axs, lat_min, lat_max, lon_min, lon_max, breaks_lon, breaks_lat, width_lat, width_lon, height_lat, height_lon)')\n",
    "\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_frame(axs, lat_min, lat_max, lon_min, lon_max, breaks_lon, breaks_lat, \n",
    "              width_lat, width_lon, height_lat, height_lon):\n",
    "\n",
    "    for i, x in zip(range(len(breaks_lon)), breaks_lon):\n",
    "        \n",
    "        color = 'white' if i%2 == 0 else 'black'\n",
    "\n",
    "        # Horizontal bottom line\n",
    "        axs.add_patch(mpatches.Rectangle(xy = [x, lat_min - height_lon], width = width_lon, height = height_lon,\n",
    "                                         facecolor = color, clip_on = False, edgecolor = 'black', lw = 1, ls = 'solid'))\n",
    "\n",
    "        # Horizontal top line\n",
    "        axs.add_patch(mpatches.Rectangle(xy = [x, lat_max], width = width_lon, height = height_lon,\n",
    "                                         facecolor = color, clip_on = False, edgecolor = 'black', lw = 1, ls = 'solid'))\n",
    "\n",
    "    for i, y in zip(range(len(breaks_lat)), breaks_lat):\n",
    "\n",
    "        color = 'white' if i%2 == 0 else 'black'\n",
    "\n",
    "        # Vertical left line\n",
    "        axs.add_patch(mpatches.Rectangle(xy = [lon_min - width_lat, y], width = width_lat, height = height_lat,\n",
    "                                         facecolor = color, clip_on = False, edgecolor = 'black', lw = 1, ls = 'solid'))\n",
    "\n",
    "        # Vertical right line\n",
    "        axs.add_patch(mpatches.Rectangle(xy = [lon_max, y], width = width_lat, height = height_lat,\n",
    "                                         facecolor = color, clip_on = False, edgecolor = 'black', lw = 1, ls = 'solid'))\n",
    "\n",
    "    # Squares at the limits\n",
    "    axs.add_patch(mpatches.Rectangle(xy = [lon_max, lat_max], width = width_lat, height = height_lon,\n",
    "                                     facecolor = 'black', clip_on = False, edgecolor = 'black', lw = 1, ls = 'solid'))\n",
    "    axs.add_patch(mpatches.Rectangle(xy = [lon_min - height_lon, lat_min - width_lat], width = width_lat, height = height_lon,\n",
    "                                     facecolor = 'black', clip_on = False, edgecolor = 'black', lw = 1, ls = 'solid'))\n",
    "    axs.add_patch(mpatches.Rectangle(xy = [lon_max, lat_min - width_lat], width = width_lat, height = height_lon,\n",
    "                                     facecolor = 'black', clip_on = False, edgecolor = 'black', lw = 1, ls = 'solid'))\n",
    "    axs.add_patch(mpatches.Rectangle(xy = [lon_min - height_lon, lat_max], width = width_lat, height = height_lon,\n",
    "                                     facecolor = 'black', clip_on = False, edgecolor = 'black', lw = 1, ls = 'solid'))\n",
    "\n",
    "    return axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_markers(axs, bbox_list, coords_list, regions_names, lat_min, lat_max):\n",
    "\n",
    "    \"\"\" Add markers to show regions, locations or texts above them\n",
    "\n",
    "        Args:\n",
    "            axs: Axes of figure\n",
    "            bbox_list (list): List of search bounding boxes (eg. (lat_min, lat_max, lon_min, lon_max, ...)\n",
    "            coords_list (list): List of search coordinates (eg. (lat, lon, lat, lon, ...)\n",
    "            regions_names (list): Region names\n",
    "            lat_min (float): Minimum latitude\n",
    "            lat_max (float): Maximum latitude\n",
    "    \"\"\"\n",
    "\n",
    "    # Transform string to tuple (if there is only one element)\n",
    "    if isinstance(regions_names, str):\n",
    "        regions_names = tuple([regions_names])\n",
    "\n",
    "    # Show rectangles\n",
    "    if bbox_list != None:\n",
    "        \n",
    "        regions_lats = pairwise(bbox_list)[0::2]\n",
    "        regions_lons = pairwise(bbox_list)[1::2]\n",
    "    \n",
    "        for region_lats, region_lons in zip(regions_lats, regions_lons):\n",
    "            \n",
    "            axs.add_patch(mpatches.Rectangle(xy = [region_lons[0], region_lats[0]], \n",
    "                                             width = region_lons[1] - region_lons[0], \n",
    "                                             height = region_lats[1] - region_lats[0],\n",
    "                                             linewidth = 1.5, linestyle = '--',\n",
    "                                             edgecolor = 'black', fill = False))\n",
    "\n",
    "    # Show points\n",
    "    if coords_list != None:    \n",
    "        coords = pairwise(coords_list)\n",
    "        for i in range(0, len(coords)):\n",
    "            axs.scatter(coords[i][1], coords[i][0], c = 'red', s = 12, marker = 'o')\n",
    "    \n",
    "    # Show text\n",
    "    if regions_names != None and coords_list != None:\n",
    "        coords = pairwise(coords_list)\n",
    "        for i, region_name in zip(range(0, len(coords)), regions_names):\n",
    "            axs.annotate(region_name, (coords[i][1], coords[i][0] + np.abs(lat_max - lat_min) / 12), \n",
    "            fontsize = 12, ha = 'center', va = 'center')\n",
    "        \n",
    "    return axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pcolormesh(fig, axs, data_array, longitude, latitude, projection, color_scale, \n",
    "                         pad, long_name, units_name, vmin, vmax, lon_min, lon_max, lat_min, lat_max, \n",
    "                         width_lon, height_lat, bbox_list, coords_list, regions_names):\n",
    "    \n",
    "    \"\"\" Set basic map configuration\n",
    "\n",
    "        Args:\n",
    "            fig: Figure\n",
    "            axs: Axes of figure\n",
    "            data_array (xarray): Variable values to plot - It must be 2-dimensional\n",
    "            longitude (arr): Longitudes within data_array\n",
    "            latitude (arr): Latitudes within data_array\n",
    "            projection: Geographical projection\n",
    "            color_scale (list):Name of color scale (e.g. coolwarm) (in order for: model, sensor, difference)\n",
    "            pad (float): Padding for the subtitles\n",
    "            long_name (str): Plot name\n",
    "            units_name (str): Component name and units\n",
    "            vmin, vmax (float): Limits of color bar\n",
    "            lon_min, lon_max, lat_min, lat_max (float): Limits of longitude and latitude values\n",
    "            width_lon (int): Horizontal width of frame individual sections (black - white lines)\n",
    "            height_lat (int): Vertical height of frame individual sections (black - white lines)\n",
    "            bbox_list (list): List of search bounding boxes (eg. (lat_min, lat_max, lon_min, lon_max, ...)\n",
    "            coords_list (list): List of search coordinates (eg. (lat, lon, lat, lon, ...)\n",
    "            regions_names (list): Region names\n",
    "    \"\"\"\n",
    "\n",
    "    palette = copy(plt.get_cmap(color_scale))\n",
    "    palette.set_bad(alpha = 0)\n",
    "    axs.clear()\n",
    "    im_ind = axs.pcolormesh(longitude, latitude, data_array, \n",
    "                            cmap = palette, \n",
    "                            transform = ccrs.PlateCarree(),\n",
    "                            vmin = vmin,\n",
    "                            vmax = vmax,\n",
    "                            norm = colors.Normalize(vmin = vmin, vmax = vmax),\n",
    "                            shading = 'auto'\n",
    "                            )\n",
    "                        \n",
    "    axs.add_feature(cfeature.BORDERS, edgecolor = 'black', linewidth = 1)\n",
    "    axs.add_feature(cfeature.COASTLINE, edgecolor = 'black', linewidth = 1)\n",
    "\n",
    "    if projection == ccrs.PlateCarree():\n",
    "        \n",
    "        axs.set_extent([lon_min, lon_max, lat_min, lat_max], ccrs.PlateCarree())\n",
    "        diff = (np.abs(lon_max - lon_min))\n",
    "        width_lat, height_lon = diff/100, diff/100\n",
    "        breaks_lon = list(np.arange(lon_min, lon_max, width_lon))\n",
    "        breaks_lat = list(np.arange(lat_min, lat_max, height_lat))\n",
    "\n",
    "        gl = axs.gridlines(draw_labels = True, linestyle = '--')\n",
    "        gl.xlocator = mticker.FixedLocator(breaks_lon[1:])\n",
    "        gl.ylocator = mticker.FixedLocator(breaks_lat)\n",
    "        gl.xformatter = LONGITUDE_FORMATTER\n",
    "        gl.yformatter = LATITUDE_FORMATTER\n",
    "        gl.xlabel_style = {'size': 13.5}\n",
    "        gl.ylabel_style = {'size': 13.5}\n",
    "        gl.xpadding = 10\n",
    "        gl.ypadding = 10\n",
    "        gl.right_labels = False\n",
    "        gl.top_labels = False\n",
    "        axs = map_frame(axs, lat_min, lat_max, lon_min, lon_max, breaks_lon, breaks_lat,\n",
    "                        width_lat, width_lon, height_lat, height_lon)\n",
    "\n",
    "    axs.set_title(long_name, fontsize = 18, pad = pad)\n",
    "    axs.tick_params(labelsize = 14)\n",
    "    \n",
    "    axs = map_markers(axs, bbox_list, coords_list, regions_names, lat_min, lat_max)\n",
    "    \n",
    "    if distribution_type != 'animated':\n",
    "        \n",
    "        cbr = fig.colorbar(im_ind, ax = axs, extend = 'both', orientation = 'horizontal', \n",
    "                           fraction = 0.05, pad = 0.15)   \n",
    "        cbr.set_label(units_name, fontsize = 16)\n",
    "        cbr.ax.tick_params(labelsize = 14)\n",
    "        cbr.ax.xaxis.get_offset_text().set_fontsize(14)\n",
    "      \n",
    "    return im_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_maps(fig, axs, merge_ds_time, range_type, sensor, model, sensor_type, model_type, \n",
    "                    projection, pad, units_name, plot_bbox, color_scale, max_all, min_all, \n",
    "                    min_all_diff, max_all_diff, width_lon, height_lat,\n",
    "                    vmin_manual, vmax_manual, vmin_manual_diff, vmax_manual_diff, \n",
    "                    bbox_list, coords_list, regions_names):\n",
    "\n",
    "    \"\"\" Create 3 plots with:\n",
    "        -   Component concentration for model data\n",
    "        -   Component concentration for sensor data\n",
    "        -   Component concentration for difference data\n",
    "\n",
    "        Args:\n",
    "            fig (figure): Plot figure\n",
    "            axs (axes): Plot axes\n",
    "            merge_ds_time (xarray): Merge xarray with total column data and their difference at specific time \n",
    "            range_type (str): Range type for colorbar:\n",
    "            -  'original': Show original values in range\n",
    "            -  'equal': Show same scale in range\n",
    "            -  'manual': Show scale in range given by user\n",
    "            -  'centered': Show scale centered in 0\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor (str): Name of the sensor\n",
    "            model (str): Name of the model\n",
    "            model_type (str): Model type:\n",
    "            -  'Forecast'\n",
    "            -  'Reanalysis'\n",
    "            sensor_type (str): Sensor type\n",
    "            projection (projection): Geographical projection\n",
    "            pad (float): Padding for the subtitles\n",
    "            units_name (str): Component name and units\n",
    "            plot_bbox (arr): Plot bounding box\n",
    "            color_scale (list):Name of color scale (e.g. coolwarm) (in order for: model, sensor, difference)\n",
    "            min_all (float): Absolute vmin\n",
    "            max_all (float): Absolute vmax\n",
    "            min_all_diff (float): Absolute vmin for difference values\n",
    "            max_all_diff (float): Absolute vmax for difference values \n",
    "            width_lon (int): Horizontal width of frame individual sections (black - white lines)\n",
    "            height_lat (int): Vertical height of frame individual sections (black - white lines)\n",
    "            vmin_manual (float): Input vmin by user\n",
    "            vmax_manual (float): Input vmax by user\n",
    "            vmin_manual_diff (float): Input vmin by user for difference values\n",
    "            vmax_manual_diff (float): Input vmax by user for difference values\n",
    "            bbox_list (list): List of search bounding boxes (eg. (lat_min, lat_max, lon_min, lon_max, ...)\n",
    "            coords_list (list): List of search coordinates (eg. (lat, lon, lat, lon, ...)\n",
    "            regions_names (list): Region names\n",
    "    \"\"\"\n",
    "\n",
    "    # Difference array\n",
    "    diff_array = merge_ds_time.difference\n",
    "\n",
    "    # First plot - CAMS \n",
    "    array = merge_ds_time['model_column']\n",
    "    vmin, vmax = colorbar_range(range_type, array, diff_array, max_all, min_all, \n",
    "                                max_all_diff, min_all_diff, vmin_manual, vmax_manual, \n",
    "                                vmin_manual_diff, vmax_manual_diff)\n",
    "    long_name = model.upper() + ' (' + model_type + ')'\n",
    "    im1 = visualize_pcolormesh(\n",
    "                               fig = fig, axs = axs[0], \n",
    "                               data_array = array,\n",
    "                               longitude = array.longitude,\n",
    "                               latitude = array.latitude,\n",
    "                               projection = projection,\n",
    "                               color_scale = color_scale[0],\n",
    "                               pad = pad,\n",
    "                               long_name = long_name,\n",
    "                               units_name = units_name,\n",
    "                               vmin = vmin, \n",
    "                               vmax = vmax, \n",
    "                               lon_min = plot_bbox[0][0],\n",
    "                               lon_max = plot_bbox[1][0],\n",
    "                               lat_min = plot_bbox[0][1],\n",
    "                               lat_max = plot_bbox[1][1],\n",
    "                               width_lon = width_lon,\n",
    "                               height_lat = height_lat,\n",
    "                               bbox_list = bbox_list, \n",
    "                               coords_list = coords_list,\n",
    "                               regions_names = regions_names\n",
    "                              )\n",
    "\n",
    "    # Second plot - TROPOMI, IASI or GOME-2\n",
    "    array = merge_ds_time['sensor_column']\n",
    "    vmin, vmax = colorbar_range(range_type, array, diff_array, max_all, min_all, \n",
    "                                max_all_diff, min_all_diff, vmin_manual, vmax_manual,\n",
    "                                vmin_manual_diff, vmax_manual_diff)\n",
    "    long_name = 'GOME-2' + ' (' + sensor_type + ')' if sensor == 'gome' else sensor.upper() + ' (' + sensor_type + ')'\n",
    "    im2 = visualize_pcolormesh(\n",
    "                               fig = fig, axs = axs[1],\n",
    "                               data_array = array,\n",
    "                               longitude = array.longitude,\n",
    "                               latitude = array.latitude,\n",
    "                               projection = projection,\n",
    "                               color_scale = color_scale[1],\n",
    "                               pad = pad,\n",
    "                               long_name = long_name,\n",
    "                               units_name = units_name,\n",
    "                               vmin = vmin,  \n",
    "                               vmax = vmax, \n",
    "                               lon_min = plot_bbox[0][0],\n",
    "                               lon_max = plot_bbox[1][0],\n",
    "                               lat_min = plot_bbox[0][1],\n",
    "                               lat_max = plot_bbox[1][1],\n",
    "                               width_lon = width_lon,\n",
    "                               height_lat = height_lat,                     \n",
    "                               bbox_list = bbox_list, \n",
    "                               coords_list = coords_list,\n",
    "                               regions_names = regions_names\n",
    "                              )\n",
    "\n",
    "    # Third plot - Difference\n",
    "    array = diff_array\n",
    "    vmin, vmax = colorbar_range(range_type, array, diff_array, max_all, min_all, \n",
    "                                max_all_diff, min_all_diff, vmin_manual, vmax_manual,\n",
    "                                vmin_manual_diff, vmax_manual_diff)\n",
    "    long_name = 'Difference (' + model.upper() + ' - ' + sensor.upper() + ')'\n",
    "    im3 = visualize_pcolormesh(\n",
    "                              fig = fig, axs = axs[2],\n",
    "                              data_array = array,\n",
    "                              longitude = array.longitude,\n",
    "                              latitude = array.latitude,\n",
    "                              projection = projection,\n",
    "                              color_scale = color_scale[2],\n",
    "                              pad = pad,\n",
    "                              long_name = long_name,\n",
    "                              units_name = units_name,\n",
    "                              vmin = vmin,\n",
    "                              vmax = vmax,\n",
    "                              lon_min = plot_bbox[0][0],\n",
    "                              lon_max = plot_bbox[1][0],\n",
    "                              lat_min = plot_bbox[0][1],\n",
    "                              lat_max = plot_bbox[1][1],\n",
    "                              width_lon = width_lon,\n",
    "                              height_lat = height_lat,\n",
    "                              bbox_list = bbox_list, \n",
    "                              coords_list = coords_list,\n",
    "                              regions_names = regions_names\n",
    "                             )\n",
    "    \n",
    "    im = [im1, im2, im3]\n",
    " \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_absolute_limits(vmin_manual, vmax_manual, model_variable, sensor_variable, diff_variable):\n",
    "\n",
    "    \"\"\" Define absolute minimum and maximum within model and sensor datasets.\n",
    "        Gets manual minimum and maximum or calculates it\n",
    "\n",
    "        Args:\n",
    "            vmin_manual (float): Input vmin by user\n",
    "            vmax_manual (float): Input vmax by user\n",
    "            model_variable (array): Variable to get limits in model data column\n",
    "            sensor_variable (array): Variable to get limits in sensor data column\n",
    "            diff_variable (array): Variable to get limits in difference data column\n",
    "\n",
    "        Returns\n",
    "            min_all (float): Absolute vmin\n",
    "            max_all (float): Absolute vmax\n",
    "            min_all_diff (float): Absolute vmin for difference values\n",
    "            max_all_diff (float): Absolute vmax for difference values     \n",
    "    \"\"\"\n",
    "\n",
    "    # Define absolute minimum and maximum within model and sensor datasets\n",
    "    if vmin_manual == None and vmax_manual == None:\n",
    "        \n",
    "        min_model = np.nanmin(model_variable)\n",
    "        max_model = np.nanmax(model_variable)\n",
    "        min_sensor = np.nanmin(sensor_variable)\n",
    "        max_sensor = np.nanmax(sensor_variable)\n",
    "        max_all = max(max_sensor, max_model)\n",
    "        min_all = min(min_sensor, min_model)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if np.abs(vmax_manual) >= np.abs(vmin_manual):\n",
    "            \n",
    "            min_all = -np.abs(vmax_manual)\n",
    "            max_all = np.abs(vmax_manual)\n",
    "\n",
    "        elif np.abs(vmax_manual) < np.abs(vmin_manual):\n",
    "            \n",
    "            min_all = -np.abs(vmin_manual)\n",
    "            max_all = np.abs(vmin_manual)\n",
    "\n",
    "    # Define absolute minimum and maximum within difference\n",
    "    min_all_diff = np.nanmin(diff_variable)\n",
    "    max_all_diff = np.nanmax(diff_variable)\n",
    "\n",
    "    return min_all, max_all, min_all_diff, max_all_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_vs_sensor(model, sensor, component_nom, units, merge_df, plot_dates, plot_bbox, pad, y, \n",
    "                              model_type, sensor_type, range_type, distribution_type, projection,\n",
    "                              color_scale, width_lon, height_lat, \n",
    "                              vmin_manual = None, vmax_manual = None,\n",
    "                              vmin_manual_diff = None, vmax_manual_diff = None, \n",
    "                              bbox_list = None, coords_list = None, regions_names = None):\n",
    "\n",
    "    \"\"\" Plot model and sensor datasets in the study area for the selected dates, \n",
    "        along with a plot of the differences\n",
    "\n",
    "        Args:\n",
    "            model (str): Name of the model\n",
    "            sensor (str): Name of the sensor\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            units (str): Component units\n",
    "            merge_df (dataframe): Merge table with total column data and their difference\n",
    "            plot_dates (arr): Plot dates\n",
    "            plot_bbox (arr): Plot extent\n",
    "            pad (float): Padding for the subtitles\n",
    "            y (float): y-position of main title\n",
    "            model_type (str): Model type:\n",
    "            -  'Forecast'\n",
    "            -  'Reanalysis'\n",
    "            sensor_type (str): Sensor type\n",
    "            range_type (str): Range type for colorbar:\n",
    "            -  'original': Show original values in range\n",
    "            -  'equal': Show same scale in range\n",
    "            -  'manual': Show scale in range given by user\n",
    "            -  'centered': Show scale centered in 0\n",
    "            distribution_type (str): \n",
    "            -  'aggregated': Aggregate plots by time\n",
    "            -  'individual': Show individual plots\n",
    "            -  'animated: Show animation\n",
    "            projection (projection): Geographical projection\n",
    "            color_scale (list): Name of color scale (e.g. coolwarm) (in order for: model, sensor, difference)\n",
    "            width_lon (int): Horizontal width of frame individual sections (black - white lines)\n",
    "            height_lat (int): Vertical height of frame individual sections (black - white lines)\n",
    "            vmin_manual (float): Input vmin by user\n",
    "            vmax_manual (float): Input vmax by user\n",
    "            vmin_manual_diff (float): Input vmin by user for difference values\n",
    "            vmax_manual_diff (float): Input vmax by user for difference values\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(color_scale) != 3:\n",
    "        print('ERROR: color_scale has to include the scales (e.g. coolwarm) for the three maps (in order for: model, sensor, difference).')\n",
    "        raise KeyboardInterrupt()\n",
    "\n",
    "    # Get min and max \n",
    "    merge_df_bbox = merge_df.query('longitude >= @plot_bbox[0][0] and longitude <= @plot_bbox[1][0] and latitude >= @plot_bbox[0][1] and latitude <= @plot_bbox[1][1]')\n",
    "    model_variable = merge_df_bbox['model_column']\n",
    "    sensor_variable = merge_df_bbox['sensor_column']\n",
    "    diff_variable = merge_df_bbox['difference']\n",
    "    min_all, max_all, min_all_diff, max_all_diff = define_absolute_limits(vmin_manual, vmax_manual, \n",
    "                                                                          model_variable, sensor_variable, \n",
    "                                                                          diff_variable)\n",
    "\n",
    "    units_name = component_nom + ' (' + units + ')'\n",
    "\n",
    "    if distribution_type == 'aggregated':\n",
    "            \n",
    "        merge_ds_time = merge_df.to_xarray().mean(dim = 'time')\n",
    "        latitude = merge_ds_time.latitude\n",
    "        longitude = merge_ds_time.longitude\n",
    "        merge_ds_time = merge_ds_time.assign_coords(latitude = latitude, longitude = longitude)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize = (20, 5), subplot_kw = {'projection': projection})\n",
    "        fig.set_facecolor('w')\n",
    "\n",
    "        im = comparison_maps(fig, axs, merge_ds_time, range_type, sensor, model, sensor_type, model_type, \n",
    "                             projection, pad, units_name, plot_bbox, color_scale, max_all, min_all, \n",
    "                             min_all_diff, max_all_diff, width_lon, height_lat, vmin_manual, vmax_manual,\n",
    "                             vmin_manual_diff, vmax_manual_diff, bbox_list, coords_list, regions_names)\n",
    "\n",
    "        fig.suptitle(f'DISTRIBUTION OF {component_nom} (All times)',\n",
    "                    fontsize = 18, fontweight = 'bold', y = y)\n",
    "\n",
    "    elif distribution_type == 'seasonal':\n",
    "        \n",
    "        merge_df = merge_df.reset_index()\n",
    "        merge_df['season'] = merge_df.apply(lambda row: get_season(row['time']), axis = 1)\n",
    "        available_seasons = np.unique(merge_df['season'])\n",
    "        merge_ds_seasons = merge_df.set_index(['latitude', 'longitude', 'time', 'season'])\n",
    "        merge_ds_seasons = merge_ds_seasons.groupby(level = [0, 1, 3]).mean().to_xarray()\n",
    "        \n",
    "        for season in available_seasons:\n",
    "\n",
    "            merge_ds_season = merge_ds_seasons.sel(season = season)\n",
    "\n",
    "            fig, axs = plt.subplots(1, 3, figsize = (20, 5), subplot_kw = {'projection': projection})\n",
    "            fig.set_facecolor('w')\n",
    "            \n",
    "            im = comparison_maps(fig, axs, merge_ds_season, range_type, sensor, model, sensor_type, model_type, \n",
    "                                 projection, pad, units_name, plot_bbox, color_scale, max_all, min_all, \n",
    "                                 min_all_diff, max_all_diff, width_lon, height_lat, vmin_manual, vmax_manual,\n",
    "                                 vmin_manual_diff, vmax_manual_diff, bbox_list, coords_list, regions_names)\n",
    "            \n",
    "            fig.suptitle(f'DISTRIBUTION OF {component_nom} (Season: {season})',\n",
    "                         fontsize = 18, fontweight = 'bold', y = y)\n",
    "\n",
    "    elif distribution_type == 'individual':\n",
    "        \n",
    "        for time in plot_dates:\n",
    "\n",
    "            merge_ds_time = merge_df.query('time == @time').to_xarray()\n",
    "            latitude = merge_ds_time.sel(time = time).latitude\n",
    "            longitude = merge_ds_time.sel(time = time).longitude\n",
    "            merge_ds_time = merge_ds_time.sel(time = time).assign_coords(latitude = latitude, longitude = longitude)\n",
    "\n",
    "            fig, axs = plt.subplots(1, 3, figsize = (20, 5), subplot_kw = {'projection': projection})\n",
    "            fig.set_facecolor('w')\n",
    "            \n",
    "            im = comparison_maps(fig, axs, merge_ds_time, range_type, sensor, model, sensor_type, model_type, \n",
    "                                 projection, pad, units_name, plot_bbox, color_scale, max_all, min_all, \n",
    "                                 min_all_diff, max_all_diff, width_lon, height_lat, vmin_manual, vmax_manual,\n",
    "                                 vmin_manual_diff, vmax_manual_diff, bbox_list, coords_list, regions_names)\n",
    "            \n",
    "            if (sensor == 'iasi' and sensor_type == 'L3') or (sensor == 'gome' and sensor_type == 'L3'):\n",
    "                month = np.datetime64(time).astype('datetime64[M]')\n",
    "                fig.suptitle(f'DISTRIBUTION OF {component_nom} (Month: {month})',\n",
    "                             fontsize = 18, fontweight = 'bold', y = y)\n",
    "\n",
    "            else:\n",
    "                day = np.datetime64(time).astype('datetime64[D]')\n",
    "                fig.suptitle(f'DISTRIBUTION OF {component_nom} (Date: {day})',\n",
    "                             fontsize = 18, fontweight = 'bold', y = y)\n",
    "                             \n",
    "            plt.show()\n",
    "        \n",
    "    elif distribution_type == 'animated':\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize = (25, 10), subplot_kw = {'projection': projection})\n",
    "        fig.set_facecolor('w')\n",
    "\n",
    "        if (sensor == 'iasi' and sensor_type == 'L3') or (sensor == 'gome' and sensor_type == 'L3'):\n",
    "            month = np.datetime64(plot_dates[0]).astype('datetime64[M]')\n",
    "            fig_title = fig.text(0.5, 0.95, f'DISTRIBUTION OF {component_nom} (Month: {month})', \n",
    "                                 ha = 'center', fontsize = 22, fontweight = 'bold')\n",
    "\n",
    "        else:\n",
    "            day = np.datetime64(plot_dates[0]).astype('datetime64[D]')\n",
    "            fig_title = fig.text(0.5, 0.95, f'DISTRIBUTION OF {component_nom} (Date: {day})', \n",
    "                                 ha = 'center', fontsize = 22, fontweight = 'bold')\n",
    "\n",
    "        time = plot_dates[0]\n",
    "        merge_ds_time = merge_df.query('time == @time').to_xarray()\n",
    "        latitude = merge_ds_time.sel(time = time).latitude\n",
    "        longitude = merge_ds_time.sel(time = time).longitude    \n",
    "        merge_ds_time = merge_ds_time.sel(time= time).assign_coords(latitude = latitude, longitude = longitude)    \n",
    "        im = comparison_maps(fig, axs, merge_ds_time, range_type, sensor, model, sensor_type, model_type,\n",
    "                             projection, pad, units_name, plot_bbox, color_scale, max_all, min_all, \n",
    "                             min_all_diff, max_all_diff, width_lon, height_lat, vmin_manual, vmax_manual,\n",
    "                             vmin_manual_diff, vmax_manual_diff, bbox_list, coords_list, regions_names)\n",
    "\n",
    "        def animate(i):\n",
    "\n",
    "            time = plot_dates[i]\n",
    "            merge_ds_time = merge_df.query('time == @time').to_xarray()\n",
    "            latitude = merge_ds_time.sel(time = time).latitude\n",
    "            longitude = merge_ds_time.sel(time = time).longitude\n",
    "            merge_ds_time = merge_ds_time.sel(time= time).assign_coords(latitude = latitude, longitude = longitude)\n",
    "            im = comparison_maps(fig, axs, merge_ds_time, range_type, sensor, model, sensor_type, model_type, \n",
    "                                 projection, pad, units_name, plot_bbox, color_scale, max_all, min_all, \n",
    "                                 min_all_diff, max_all_diff, width_lon, height_lat, vmin_manual, vmax_manual,\n",
    "                                 vmin_manual_diff, vmax_manual_diff, bbox_list, coords_list, regions_names)     \n",
    "\n",
    "            if (sensor == 'iasi' and sensor_type == 'L3') or (sensor == 'gome' and sensor_type == 'L3'):\n",
    "                month = np.datetime64(plot_dates[i]).astype('datetime64[M]')\n",
    "                fig_title.set_text(f'DISTRIBUTION OF {component_nom} (Month: {month})')\n",
    "\n",
    "            else:\n",
    "                day = np.datetime64(plot_dates[i]).astype('datetime64[D]')\n",
    "                fig_title.set_text(f'DISTRIBUTION OF {component_nom} (Date: {day})')\n",
    "\n",
    "            return im\n",
    "\n",
    "        anim = animation.FuncAnimation(fig, animate, frames = len(plot_dates), blit = True, interval = 1000)\n",
    "\n",
    "        for j in range(0, 3):\n",
    "           \n",
    "            cbr = fig.colorbar(im[j], ax = axs[j], extend = 'both', orientation = 'horizontal', fraction = 0.05, pad = 0.15)\n",
    "            cbr.set_label(units_name, fontsize = 18) \n",
    "            cbr.ax.tick_params(labelsize = 16)\n",
    "            cbr.ax.xaxis.get_offset_text().set_fontsize(16)\n",
    "\n",
    "        display(HTML(anim.to_jshtml()))\n",
    "        anim.save('animation.gif')\n",
    "        plt.close()\n",
    "\n",
    "    else:\n",
    "        print('The distribution type (distribution_type) must be defined as aggregated, individual or animated.')\n",
    "        raise KeyboardInterrupt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_original_vs_calculated(model, component_nom, units, merge_df, \n",
    "                                           model_total_ds, plot_dates, plot_bbox, pad, y, \n",
    "                                           model_type, range_type, projection, color_scale,\n",
    "                                           width_lon, height_lat,\n",
    "                                           vmin_manual = None, vmax_manual = None):\n",
    "\n",
    "    \"\"\" Plot model total columns from the original dataset and the calculated one \n",
    "        in the study area for the selected dates\n",
    "\n",
    "        Args:\n",
    "            model (str): Name of the model\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            units (str): Component units\n",
    "            merge_df (dataframe): Merge result\n",
    "            model_total_ds (xarray): CAMS total columns dataset in xarray format\n",
    "            plot_dates (arr): Plot dates\n",
    "            plot_bbox (arr): Plot extent\n",
    "            pad (float): Padding for the subtitles\n",
    "            y (float): y-position of main title\n",
    "            model_type (str): Model type:\n",
    "            -  'Forecast'\n",
    "            -  'Reanalysis'\n",
    "            range_type (str): Range type for colorbar:\n",
    "            -  'original': Show original values in range\n",
    "            -  'equal': Show same scale in range\n",
    "            -  'manual': Show scale in range given by user\n",
    "            -  'centered': Show scale centered in 0\n",
    "            projection: Geographical projection\n",
    "            color_scale (list): Name of color scale (e.g. coolwarm) (in order for: original, calculated)\n",
    "            width_lon (int): Horizontal width of frame individual sections (black - white lines)\n",
    "            height_lat (int): Vertical height of frame individual sections (black - white lines)\n",
    "            vmin_manual (float): Input vmin by user\n",
    "            vmax_manual (float): Input vmax by user\n",
    "    \"\"\"\n",
    "\n",
    "    units_name = component_nom + ' (' + units + ')'\n",
    "\n",
    "    # Get min and max before splitting the data into timesteps\n",
    "    min_model = np.nanmin(merge_df['model_column'])\n",
    "    max_model = np.nanmax(merge_df['model_column'])\n",
    "    min_sensor = np.nanmin(model_total_ds.component)\n",
    "    max_sensor = np.nanmax(model_total_ds.component)\n",
    "    max_all = max(max_sensor, max_model)\n",
    "    min_all = min(min_sensor, min_model)\n",
    "    min_all_diff, max_all_diff = None, None\n",
    "\n",
    "    if len(color_scale) != 2:\n",
    "        print('ERROR: color_scale has to include the scales (e.g. coolwarm) for the two maps (in order for: original, calculated).')\n",
    "        raise KeyboardInterrupt()\n",
    "    \n",
    "    for time in plot_dates:\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize = (20, 5), subplot_kw = {'projection': projection})\n",
    "        fig.set_facecolor('w')\n",
    "        \n",
    "        merge_ds_time = merge_df.query('time == @time').to_xarray()\n",
    "        latitude = merge_ds_time.sel(time = time).latitude\n",
    "        longitude = merge_ds_time.sel(time = time).longitude\n",
    "        merge_ds_time = merge_ds_time.sel(time= time).assign_coords(latitude = latitude, longitude = longitude)\n",
    "\n",
    "        step = 2\n",
    "\n",
    "        # First plot - CAMS calculated total columns\n",
    "        array = merge_ds_time.model_column\n",
    "        diff_array = None\n",
    "        vmin, vmax = colorbar_range(range_type, array, diff_array, max_all, min_all, \n",
    "                                    max_all_diff, min_all_diff, vmin_manual, vmax_manual, \n",
    "                                    vmin_manual_diff = None, vmax_manual_diff = None)\n",
    "        long_name = 'CALCULATED TOTAL COLUMNS ' + model.upper() + ' (' + model_type + ')'\n",
    "        visualize_pcolormesh(\n",
    "                             fig = fig, axs = axs[0],\n",
    "                             data_array = array,\n",
    "                             longitude = array.longitude,\n",
    "                             latitude = array.latitude,\n",
    "                             projection = projection,\n",
    "                             color_scale = color_scale[0],\n",
    "                             pad = pad,\n",
    "                             long_name = long_name,\n",
    "                             units_name = units_name,\n",
    "                             vmin = vmin, \n",
    "                             vmax = vmax, \n",
    "                             lon_min = plot_bbox[0][0],\n",
    "                             lon_max = plot_bbox[1][0],\n",
    "                             lat_min = plot_bbox[0][1],\n",
    "                             lat_max = plot_bbox[1][1],\n",
    "                             width_lon = width_lon,\n",
    "                             height_lat = height_lat,\n",
    "                             bbox_list = None, \n",
    "                             coords_list = None,\n",
    "                             regions_names = None\n",
    "                            )\n",
    "\n",
    "        # Second plot - CAMS original total columns\n",
    "        array = model_total_ds.component.isel(step = step).sel(time = time)\n",
    "        diff_array = None\n",
    "        vmin, vmax = colorbar_range(range_type, array, diff_array, max_all, min_all, \n",
    "                                    max_all_diff, min_all_diff, vmin_manual, vmax_manual, \n",
    "                                    vmin_manual_diff = None, vmax_manual_diff = None)\n",
    "        long_name = 'ORIGINAL TOTAL COLUMNS ' + model.upper() + ' (' + model_type + ')'\n",
    "        visualize_pcolormesh(\n",
    "                             fig = fig, axs = axs[1],\n",
    "                             data_array = array,\n",
    "                             longitude = array.longitude,\n",
    "                             latitude = array.latitude,\n",
    "                             projection = projection,\n",
    "                             color_scale = color_scale[1],\n",
    "                             pad = pad,\n",
    "                             long_name = long_name,\n",
    "                             units_name = units_name,\n",
    "                             vmin = vmin,\n",
    "                             vmax = vmax, \n",
    "                             lon_min = plot_bbox[0][0],\n",
    "                             lon_max = plot_bbox[1][0],\n",
    "                             lat_min = plot_bbox[0][1],\n",
    "                             lat_max = plot_bbox[1][1],\n",
    "                             width_lon = width_lon,\n",
    "                             height_lat = height_lat,\n",
    "                             bbox_list = None, \n",
    "                             coords_list = None,\n",
    "                             regions_names = None\n",
    "                            )\n",
    "\n",
    "        day = np.datetime64(time).astype('datetime64[D]')\n",
    "        fig.suptitle(f'DISTRIBUTION OF {component_nom} (Date: {day})',\n",
    "                     fontsize = 18, fontweight = 'bold', y = y)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_api():\n",
    "\n",
    "    \"\"\" Get Google API key for reverse geocoding (get country given the coordinates)\n",
    "        \n",
    "        Returns:\n",
    "            environ_keys[1]: Google API key\n",
    "    \"\"\"\n",
    "\n",
    "    # Open txt file with three lines:\n",
    "    # GOOGLE API KEY (first line), GOOGLE CLIENT ID (second line) and GOOGLE CLIENT SECRET (third line)\n",
    "    keys_file = open('data/keys.txt', 'r')\n",
    "    keys = keys_file.readlines()\n",
    "    environ_keys = [key.rstrip() for key in keys]\n",
    "\n",
    "    # Set environment variables in your system\n",
    "    os.environ['GOOGLE_API_KEY'] = environ_keys[1]\n",
    "    os.environ['GOOGLE_CLIENT'] = environ_keys[2]\n",
    "    os.environ['GOOGLE_CLIENT_SECRET'] = environ_keys[3]\n",
    "\n",
    "    return environ_keys[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(day):\n",
    "\n",
    "    \"\"\" Get season given the day\n",
    "\n",
    "        Args:\n",
    "            day (datetime): Date\n",
    "        \n",
    "        Returns:\n",
    "            season (str): Season of the year\n",
    "    \"\"\"\n",
    "\n",
    "    Y = 2000\n",
    "\n",
    "    seasons = [('Winter', (dt.date(Y,  1,  1),  dt.date(Y,  3, 20))),\n",
    "               ('Spring', (dt.date(Y,  3, 21),  dt.date(Y,  6, 20))),\n",
    "               ('Summer', (dt.date(Y,  6, 21),  dt.date(Y,  9, 22))),\n",
    "               ('Autumn', (dt.date(Y,  9, 23),  dt.date(Y, 12, 20))),\n",
    "               ('Winter', (dt.date(Y, 12, 21),  dt.date(Y, 12, 31)))]\n",
    "            \n",
    "    day = day.replace(year = Y)\n",
    "\n",
    "    season = next(season for season, (start, end) in seasons if start <= day <= end)\n",
    "             \n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, Y, component_nom, axs):\n",
    "\n",
    "    \"\"\" Fit a linear equation to scatter plot between X and Y and print results\n",
    "\n",
    "        Args:\n",
    "            X (array): Input sensor component values\n",
    "            Y (array): Input model component values\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "        \n",
    "        Returns:\n",
    "            fit_X (array): X in linear equation fit_Y = A * fit_X + B\n",
    "            fit_Y (array): Y in linear equation fit_Y = A * fit_X + B\n",
    "            R2 (float): slope of determination\n",
    "            slope (float): A in linear equation fit_Y = A * fit_X + B\n",
    "            intercept (float): B in linear equation fit_Y = A * fit_X + B\n",
    "    \"\"\"\n",
    "\n",
    "    R2 = 'Unknown'\n",
    "    slope = 'Unknown'\n",
    "    intercept = 'Unknown'\n",
    "\n",
    "    # Fit regression\n",
    "    reg = LinearRegression().fit(X, Y)\n",
    "    try:\n",
    "        lim_min, lim_max = axs[0].get_xlim()\n",
    "    except:\n",
    "        lim_min, lim_max = axs.get_xlim()\n",
    "    fit_X = np.linspace(lim_min, lim_max, 10) \n",
    "    fit_Y = fit_X * float(reg.coef_) + reg.intercept_\n",
    "    \n",
    "    # Get R2, slope and intercept\n",
    "    R2 = reg.score(X, Y)\n",
    "    slope = reg.coef_[0][0]\n",
    "    intercept = reg.intercept_[0]\n",
    "\n",
    "    # Calculate MSE and RMSE\n",
    "    Y_pred = intercept + slope * X\n",
    "    MSE = mean_squared_error(y_true = Y, y_pred = Y_pred, squared = True)\n",
    "    RMSE = mean_squared_error(y_true = Y, y_pred = Y_pred, squared = False)\n",
    "\n",
    "    return fit_X, fit_Y, slope, intercept, R2, RMSE, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_plots_general_settings(component_nom, axs, units, lim_min, lim_max):\n",
    "\n",
    "    \"\"\" Set common settings for scatter plots\n",
    "\n",
    "        Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            plt (plot): Scatterplot\n",
    "            units (str): Component units\n",
    "            lim_min (float): Minimum value of component in scale\n",
    "            lim_max (float): Maximum value of component in scale\n",
    "    \"\"\"\n",
    "\n",
    "    # Scatter plot\n",
    "    axs[0].set_xlabel(f'Sensor {component_nom} ({units})', fontsize = 20)\n",
    "    axs[0].set_ylabel(f'Model {component_nom} ({units})', fontsize = 20)\n",
    "    axs[0].set_ylim([lim_min, lim_max])\n",
    "\n",
    "    # Histograms\n",
    "    axs[1].set_xlabel(f'Sensor {component_nom} ({units})', fontsize = 20)\n",
    "    axs[2].set_xlabel(f'Model {component_nom} ({units})', fontsize = 20)\n",
    "    for i in range(1, 3):\n",
    "        axs[i].set_ylabel(f'Count', fontsize = 20)\n",
    "    \n",
    "    # All\n",
    "    for i in range(0, 3):\n",
    "        axs[i].tick_params(labelsize = 18)\n",
    "        axs[i].set_xlim([lim_min, lim_max])\n",
    "        axs[i].locator_params(axis = 'both', nbins = 8)\n",
    "        axs[i].xaxis.get_offset_text().set_fontsize(16)\n",
    "        axs[i].yaxis.get_offset_text().set_fontsize(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(merge_df, component_nom, units, sensor, plot_dates, y, extent_definition, \n",
    "                 show_seasons, scatter_plot_type, lim_min = None, lim_max = None, *args):\n",
    "\n",
    "    \"\"\" Scatter plot between the model and sensor datasets in the study area for the selected dates (bbox or countries)\n",
    "\n",
    "        Args:\n",
    "            merge_df (dataframe): Merge result\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            units (str): Component units\n",
    "            sensor (str): Name of the sensor\n",
    "            plot_dates (arr): Plot dates\n",
    "            plot_bbox (arr): Plot extent\n",
    "            y (float): y-position of main title\n",
    "            extent_definition (str):\n",
    "            * 'country': Scatter plots for countries list\n",
    "            * 'bbox': Scatter plots for bbox coordinates\n",
    "            scatter_plot_type (str):\n",
    "            * 'aggregated': Aggregate plots by time, country or season\n",
    "            * 'individual': Individual plots per time, country or season\n",
    "            *args: plot_countries, plot_bbox, lim_min, lim_max\n",
    "    \"\"\"\n",
    "\n",
    "    summary = []\n",
    "\n",
    "    # Set colors for scatter points\n",
    "    sns.color_palette('colorblind', 10)\n",
    "\n",
    "    # Drop NaN values\n",
    "    merge_df = merge_df.dropna()\n",
    "\n",
    "    # Prepare df\n",
    "    if lim_min == None:\n",
    "        lim_min = min(np.nanmin(merge_df['sensor_column']), np.nanmin(merge_df['model_column']))\n",
    "    else:\n",
    "        merge_df = merge_df[(merge_df['sensor_column'] >= lim_min) & (merge_df['model_column'] >= lim_min)]         \n",
    "\n",
    "    if lim_max == None:\n",
    "        lim_max = max(np.nanmax(merge_df['sensor_column']), np.nanmax(merge_df['model_column']))\n",
    "    else:\n",
    "        merge_df = merge_df[(merge_df['sensor_column'] <= lim_max) & (merge_df['model_column'] <= lim_max)]\n",
    "\n",
    "    merge_df = merge_df.query('longitude >= @plot_bbox[0][0] and longitude <= @plot_bbox[1][0] and latitude >= @plot_bbox[0][1] and latitude <= @plot_bbox[1][1]')         \n",
    "    merge_df = merge_df.reset_index()\n",
    "    merge_df = merge_df[merge_df['time'].isin(plot_dates)]\n",
    "\n",
    "    if show_seasons == False:\n",
    "\n",
    "        if extent_definition == 'bbox':\n",
    "\n",
    "            if scatter_plot_type == 'aggregated':\n",
    "\n",
    "                if not merge_df.empty:\n",
    "                    \n",
    "                    fig, axs = plt.subplots(1, 3, figsize = (28, 7))\n",
    "                    fig.set_facecolor('w')\n",
    "            \n",
    "                    # Scatter plot and histograms\n",
    "                    sp = sns.scatterplot(data = merge_df, x = 'sensor_column', y = 'model_column', \n",
    "                                         hue = 'time', ax = axs[0])\n",
    "                    sns.histplot(data = merge_df, x = 'sensor_column', kde = True,  ax = axs[1])\n",
    "                    sns.histplot(data = merge_df, x = 'model_column', kde = True,  ax = axs[2])\n",
    "\n",
    "                    stats_plots_general_settings(component_nom, axs, units, lim_min, lim_max)\n",
    "                    fig.suptitle(f'{component_nom} (All times)', fontsize = 25, fontweight = 'bold', y = y)\n",
    "\n",
    "                    # Line 1:1\n",
    "                    line = mlines.Line2D([0, 1], [0, 1], color = 'grey', linestyle = '--', label = '1:1')\n",
    "                    line.set_transform(axs[0].transAxes)\n",
    "                    axs[0].add_line(line)\n",
    "\n",
    "                    # Linear regression\n",
    "                    X = merge_df['sensor_column'].values.reshape(-1, 1) \n",
    "                    Y = merge_df['model_column'].values.reshape(-1, 1) \n",
    "                    fit_X, fit_Y, slope, intercept, R2, RMSE, MSE = linear_regression(X, Y, component_nom, axs)\n",
    "                    axs[0].plot(fit_X, fit_Y, color = 'black', label = 'A + B*X')\n",
    "\n",
    "                    # Legend settings\n",
    "                    if sensor_type == 'L3':\n",
    "\n",
    "                        leg = sp.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.2),\n",
    "                                        fancybox = True, ncol = 2, fontsize = 18)\n",
    "                        leg.set_title('Legend', prop = {'size': 18, 'weight': 'bold'})\n",
    "\n",
    "                    else:\n",
    "                                        \n",
    "                        leg = sp.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.2),\n",
    "                                        fancybox = True, ncol = 2, fontsize = 18)\n",
    "                        leg.set_title('Legend', prop = {'size': 18, 'weight': 'bold'})\n",
    "\n",
    "                    plt.show()\n",
    "\n",
    "                    # Update summary\n",
    "                    summary.append({'Period': plot_dates, 'Location': plot_bbox, \n",
    "                                    'A': slope, 'B': intercept, \n",
    "                                    'R2': R2, 'RMSE': RMSE, 'MSE': MSE})\n",
    "\n",
    "            elif scatter_plot_type == 'individual':\n",
    "                \n",
    "                for time in plot_dates:\n",
    "                    \n",
    "                    # Select dataframe for a time\n",
    "                    merge_df_time = merge_df.query('time == @time')\n",
    "                    \n",
    "                    if not merge_df_time.empty:\n",
    "                        \n",
    "                        fig, axs = plt.subplots(1, 3, figsize = (28, 7))\n",
    "                        fig.set_facecolor('w')\n",
    "\n",
    "                        # Scatter plot and histograms\n",
    "                        sp = sns.scatterplot(data = merge_df_time, x = 'sensor_column', y = 'model_column', ax = axs[0])\n",
    "                        sns.histplot(data = merge_df_time, x = 'sensor_column', kde = True,  ax = axs[1])\n",
    "                        sns.histplot(data = merge_df_time, x = 'model_column', kde = True,  ax = axs[2])\n",
    "\n",
    "                        stats_plots_general_settings(component_nom, axs, units, lim_min, lim_max)\n",
    "                        \n",
    "                        if sensor == 'tropomi' or (sensor == 'gome' and sensor_type == 'L2'):\n",
    "                            day = np.datetime64(time).astype('datetime64[D]')\n",
    "                            fig.suptitle(f'{component_nom} (Date: {day})', \n",
    "                                         fontsize = 25, fontweight = 'bold', y = y)\n",
    "                            \n",
    "                        else:\n",
    "                            month = np.datetime64(time).astype('datetime64[M]')\n",
    "                            fig.suptitle(f'{component_nom} (Month: {month})', \n",
    "                                         fontsize = 25, fontweight = 'bold', y = y)\n",
    "\n",
    "                        # Line 1:1\n",
    "                        line = mlines.Line2D([0, 1], [0, 1], color = 'grey', linestyle = '--', label = '1:1')\n",
    "                        line.set_transform(axs[0].transAxes)\n",
    "                        axs[0].add_line(line)\n",
    "\n",
    "                        # Linear regression\n",
    "                        X = merge_df_time['sensor_column'].values.reshape(-1, 1) \n",
    "                        Y = merge_df_time['model_column'].values.reshape(-1, 1) \n",
    "                        fit_X, fit_Y, slope, intercept, R2, RMSE, MSE = linear_regression(X, Y, component_nom, axs)\n",
    "                        axs[0].plot(fit_X, fit_Y, color = 'black', label = 'A + B*X')\n",
    "\n",
    "                        # Legend settings\n",
    "                        leg = sp.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.2),\n",
    "                                        fancybox = True, ncol = 2, fontsize = 18)\n",
    "                        leg.set_title('Legend', prop = {'size': 18, 'weight': 'bold'})\n",
    "                        \n",
    "                        plt.show()\n",
    "\n",
    "                        # Update summary\n",
    "                        summary.append({'Period': time, 'Location': plot_bbox, \n",
    "                                        'A': slope, 'B': intercept, \n",
    "                                        'R2': R2, 'RMSE': RMSE, 'MSE': MSE})\n",
    "\n",
    "        elif extent_definition == 'country':\n",
    "\n",
    "            # Read Google API key for reverse geocoding (get country by coordinates)\n",
    "            google_api_key = get_google_api()\n",
    "\n",
    "            # Reverse geocoding\n",
    "            merge_df['country'] = merge_df.apply(lambda row: geocoder.google([row['latitude'], row['longitude']], \n",
    "                                                 method='reverse', key = google_api_key).country_long, axis = 1)\n",
    "\n",
    "            # Find data for the countries in search list\n",
    "            merge_df = merge_df[merge_df['country'].isin(plot_countries)]\n",
    "            available_countries = np.unique(merge_df['country'])\n",
    "\n",
    "            if scatter_plot_type == 'aggregated':\n",
    "\n",
    "                if not merge_df.empty:\n",
    "                    \n",
    "                    fig, axs = plt.subplots(1, 3, figsize = (28, 7))\n",
    "                    fig.set_facecolor('w')\n",
    "\n",
    "                    # Scatter plot and histograms\n",
    "                    sp = sns.scatterplot(data = merge_df, x = 'sensor_column', y = 'model_column', \n",
    "                                         hue = 'country', ax = axs[0])\n",
    "                    sns.histplot(data = merge_df, x = 'sensor_column', kde = True,  ax = axs[1])\n",
    "                    sns.histplot(data = merge_df, x = 'model_column', kde = True,  ax = axs[2])\n",
    "\n",
    "                    stats_plots_general_settings(component_nom, axs, units, lim_min, lim_max)\n",
    "                    fig.suptitle(f'{component_nom} (All countries)', fontsize = 25, fontweight = 'bold', y = y)\n",
    "                    \n",
    "                    # Linear regression\n",
    "                    X = merge_df['sensor_column'].values.reshape(-1, 1) \n",
    "                    Y = merge_df['model_column'].values.reshape(-1, 1) \n",
    "                    fit_X, fit_Y, slope, intercept, R2, RMSE, MSE = linear_regression(X, Y, component_nom, axs)\n",
    "                    axs[0].plot(fit_X, fit_Y, color = 'black', label = 'A + B*X')\n",
    "\n",
    "                    # Line 1:1\n",
    "                    line = mlines.Line2D([0, 1], [0, 1], color = 'grey', linestyle = '--', label = '1:1')\n",
    "                    line.set_transform(axs[0].transAxes)\n",
    "                    axs[0].add_line(line)\n",
    "\n",
    "                    # Legend settings\n",
    "                    leg = sp.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.2),\n",
    "                                    fancybox = True, ncol = 2, fontsize = 18)\n",
    "                    leg.set_title('Legend', prop = {'size': 18, 'weight': 'bold'})\n",
    "\n",
    "                    plt.show()\n",
    "\n",
    "                    # Update summary\n",
    "                    summary.append({'Period': plot_dates, 'Location': available_countries, \n",
    "                                    'A': slope, 'B': intercept, \n",
    "                                    'R2': R2, 'RMSE': RMSE, 'MSE': MSE})\n",
    "\n",
    "            elif scatter_plot_type == 'individual':\n",
    "\n",
    "                for plot_country in plot_countries:\n",
    "\n",
    "                    merge_df_country = merge_df[merge_df['country'] == plot_country]\n",
    "\n",
    "                    if not merge_df_country.empty:\n",
    "                        \n",
    "                        fig, axs = plt.subplots(1, 3, figsize = (28, 7))\n",
    "                        fig.set_facecolor('w')\n",
    "\n",
    "                        # Scatter plot and histograms\n",
    "                        sp = sns.scatterplot(data = merge_df_country, x = 'sensor_column', y = 'model_column', ax = axs[0])\n",
    "                        sns.histplot(data = merge_df_country, x = 'sensor_column', kde = True,  ax = axs[1])\n",
    "                        sns.histplot(data = merge_df_country, x = 'model_column', kde = True,  ax = axs[2])\n",
    "\n",
    "                        stats_plots_general_settings(component_nom, axs, units, lim_min, lim_max)\n",
    "                        fig.suptitle(f'{component_nom} ({plot_country})', fontsize = 25, fontweight = 'bold', y = y)\n",
    "\n",
    "                        # Line 1:1\n",
    "                        line = mlines.Line2D([0, 1], [0, 1], color = 'grey', linestyle = '--', label = '1:1')\n",
    "                        line.set_transform(axs[0].transAxes)\n",
    "                        axs[0].add_line(line)\n",
    "\n",
    "                        # Linear regression\n",
    "                        X = merge_df_country['sensor_column'].values.reshape(-1, 1) \n",
    "                        Y = merge_df_country['model_column'].values.reshape(-1, 1) \n",
    "                        fit_X, fit_Y, slope, intercept, R2, RMSE, MSE = linear_regression(X, Y, component_nom, axs)\n",
    "                        axs[0].plot(fit_X, fit_Y, color = 'black', label = 'A + B*X')\n",
    "\n",
    "                        # Legend settings\n",
    "                        leg = sp.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.2),\n",
    "                                        fancybox = True, ncol = 2, fontsize = 18)\n",
    "                        leg.set_title('Legend', prop = {'size': 18, 'weight': 'bold'})\n",
    "                        \n",
    "                        plt.show()\n",
    "\n",
    "                        # Update summary\n",
    "                        summary.append({'Period': plot_dates, 'Location': plot_country, \n",
    "                                        'A': slope, 'B': intercept, \n",
    "                                        'R2': R2, 'RMSE': RMSE, 'MSE': MSE})\n",
    "\n",
    "            else:\n",
    "                print('ERROR: scatter_plot_type is wrongly defined. The options are ''aggregated'' and ''individual''.')\n",
    "                raise KeyboardInterrupt()\n",
    "\n",
    "        else:\n",
    "            print('ERROR: extent_definition is wrongly defined. The options are ''bbox'' and ''country''.')\n",
    "            raise KeyboardInterrupt()\n",
    "                \n",
    "    elif show_seasons == True:\n",
    "        \n",
    "        if show_seasons == True and extent_definition == 'country':\n",
    "            print('ERROR: Set up show_seasons to False in order to show the scatter plots by countries.')\n",
    "            raise KeyboardInterrupt()\n",
    "\n",
    "        plot_seasons = ['Winter', 'Spring', 'Summer', 'Autumn']\n",
    "\n",
    "        # Find data for the seasons in list\n",
    "        merge_df['season'] = merge_df.apply(lambda row: get_season(row['time']), axis = 1)\n",
    "        available_seasons = np.unique(merge_df['season'])\n",
    "\n",
    "        if scatter_plot_type == 'aggregated':\n",
    "\n",
    "            if not merge_df.empty:\n",
    "                \n",
    "                fig, axs = plt.subplots(1, 3, figsize = (28, 7))\n",
    "                fig.set_facecolor('w')\n",
    "\n",
    "                # Scatter plot and histograms\n",
    "                sp = sns.scatterplot(data = merge_df, x = 'sensor_column', y = 'model_column', \n",
    "                                     hue = 'season', ax = axs[0])\n",
    "                sns.histplot(data = merge_df, x = 'sensor_column', kde = True, ax = axs[1])\n",
    "                sns.histplot(data = merge_df, x = 'model_column', kde = True, ax = axs[2])\n",
    "\n",
    "                stats_plots_general_settings(component_nom, axs, units, lim_min, lim_max)\n",
    "                fig.suptitle(f'{component_nom} (All seasons)', fontsize = 25, fontweight = 'bold', y = y)\n",
    " \n",
    "                # Line 1:1\n",
    "                line = mlines.Line2D([0, 1], [0, 1], color = 'grey', linestyle = '--', label = '1:1')\n",
    "                line.set_transform(axs[0].transAxes)\n",
    "                axs[0].add_line(line)\n",
    "\n",
    "                # Linear regression\n",
    "                X = merge_df['sensor_column'].values.reshape(-1, 1) \n",
    "                Y = merge_df['model_column'].values.reshape(-1, 1) \n",
    "                fit_X, fit_Y, slope, intercept, R2, RMSE, MSE = linear_regression(X, Y, component_nom, axs)\n",
    "                axs[0].plot(fit_X, fit_Y, color = 'black', label = 'A + B*X')\n",
    "\n",
    "                # Legend settings\n",
    "                leg = sp.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.2),\n",
    "                                fancybox = True, ncol = 2, fontsize = 18)\n",
    "                leg.set_title('Legend', prop = {'size': 18, 'weight': 'bold'})\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                # Update summary\n",
    "                summary.append({'Period': available_seasons, 'Location': plot_bbox, \n",
    "                                'A': slope, 'B': intercept, \n",
    "                                'R2': R2, 'RMSE': RMSE, 'MSE': MSE})\n",
    "                                \n",
    "        elif scatter_plot_type == 'individual':\n",
    "\n",
    "            for plot_season in plot_seasons:\n",
    "                \n",
    "                # Prepare df\n",
    "                merge_df_season = merge_df[merge_df['season'] == plot_season]\n",
    "                \n",
    "                if not merge_df_season.empty:\n",
    "                    \n",
    "                    fig, axs = plt.subplots(1, 3, figsize = (28, 7))\n",
    "                    fig.set_facecolor('w')\n",
    "\n",
    "                    # Scatter plot and histograms\n",
    "                    sp = sns.scatterplot(data = merge_df_season, x = 'sensor_column', y = 'model_column', ax = axs[0])\n",
    "                    sns.histplot(data = merge_df_season, x = 'sensor_column', kde = True, ax = axs[1])\n",
    "                    sns.histplot(data = merge_df_season, x = 'model_column', kde = True, ax = axs[2])\n",
    "\n",
    "                    fig.suptitle(f'{component_nom} ({plot_season})', fontsize = 25, fontweight = 'bold', y = y)\n",
    "                    stats_plots_general_settings(component_nom, axs, units, lim_min, lim_max)\n",
    "\n",
    "                    # Line 1:1\n",
    "                    line = mlines.Line2D([0, 1], [0, 1], color = 'grey', linestyle = '--', label = '1:1')\n",
    "                    line.set_transform(axs[0].transAxes)\n",
    "                    axs[0].add_line(line)\n",
    "\n",
    "                    # Linear regression\n",
    "                    X = merge_df_season['sensor_column'].values.reshape(-1, 1) \n",
    "                    Y = merge_df_season['model_column'].values.reshape(-1, 1) \n",
    "                    fit_X, fit_Y, slope, intercept, R2, RMSE, MSE = linear_regression(X, Y, component_nom, axs)\n",
    "                    axs[0].plot(fit_X, fit_Y, color = 'black', label = 'A + B*X')\n",
    "\n",
    "                    # Legend settings\n",
    "                    leg = sp.legend(loc = 'upper center', bbox_to_anchor = (0.5, -0.2),\n",
    "                                    fancybox = True, ncol = 2, fontsize = 18)\n",
    "                    leg.set_title('Legend', prop = {'size': 18, 'weight': 'bold'})\n",
    "\n",
    "                    plt.show()\n",
    "\n",
    "                    # Update summary\n",
    "                    summary.append({'Period': plot_season, 'Location':  plot_bbox, \n",
    "                                    'A': slope, 'B': intercept, \n",
    "                                    'R2': R2, 'RMSE': RMSE, 'MSE': MSE})\n",
    "        else:\n",
    "            print('ERROR: scatter_plot_type is wrongly defined. The options are ''aggregated'' and ''individual''.')\n",
    "            raise KeyboardInterrupt()\n",
    "\n",
    "    else:\n",
    "        print('ERROR: show_seasons is wrongly defined. The options are True and False.')\n",
    "        raise KeyboardInterrupt()\n",
    "    \n",
    "    summary = pd.DataFrame(summary)\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries(merge_df, component_nom, sensor, sensor_type, model, plot_dates, units, \n",
    "               ymin, ymax, xticks, regions_names, coords_list):\n",
    "\n",
    "    \"\"\" Get component data for the closest coordinates to the list of search coordinates and plot them along time\n",
    "\n",
    "        Args:\n",
    "            merge_df (dataframe): Merge result\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor (str): Name of the sensor\n",
    "            model (str): Name of the model\n",
    "            plot_dates (arr): Plot dates\n",
    "            units (str): Component units\n",
    "            ymin (float): Minimum y-axis value\n",
    "            ymax (float): Maximum y-axis value\n",
    "            regions_names (list): Region names \n",
    "            coords_list (list): List of search coordinates (eg. (lat, lon, lat, lon, ...)\n",
    "\n",
    "        Returns:\n",
    "            timeseries_table (dataframe): Dataframe with results from search\n",
    "    \"\"\"\n",
    "    \n",
    "    timeseries_table = pd.DataFrame()\n",
    "\n",
    "    # Drop NaN values\n",
    "    merge_df = merge_df.dropna()\n",
    "\n",
    "    # Drop the dates that have NaN values\n",
    "    plot_dates = np.intersect1d(plot_dates, np.unique(merge_df.index.get_level_values(2)))\n",
    "\n",
    "    # Get coordinates pairs\n",
    "    coords_search = pairwise(coords_list)\n",
    "\n",
    "    for i, region_name in zip(range(0, len(coords_search)), regions_names):\n",
    "       \n",
    "        for time in plot_dates:\n",
    "            \n",
    "            # List of available points per time\n",
    "            timeseries_table_time = merge_df.query('time == @time').reset_index()\n",
    "            available_points = list([(x, y) for x, y in zip(timeseries_table_time['latitude'], \n",
    "                                                            timeseries_table_time['longitude'])])\n",
    "            \n",
    "            # Get closest pair to coordinates in search list\n",
    "            lat_found = closest_point(coords_search[i], available_points)[0]\n",
    "            lon_found = closest_point(coords_search[i], available_points)[1]\n",
    "            timeseries_table_time = merge_df.query('latitude == @lat_found and longitude == @lon_found and time == @time')\n",
    "\n",
    "            timeseries_table_time = timeseries_table_time.reset_index()\n",
    "            timeseries_table_time['lat_search'] = coords_search[i][0]\n",
    "            timeseries_table_time['lon_search'] = coords_search[i][1]\n",
    "            timeseries_table_time['region'] = region_name\n",
    "\n",
    "            # Append retrieval table to previous coordinates\n",
    "            timeseries_table = timeseries_table.append(timeseries_table_time)\n",
    "        \n",
    "        table_length = len(timeseries_table[(timeseries_table['lat_search'] == coords_search[i][0]) &\n",
    "                                            (timeseries_table['lon_search'] == coords_search[i][1])])\n",
    "\n",
    "        # Plot variations in time\n",
    "        if table_length > 1:\n",
    "        \n",
    "            fig, ax = plt.subplots(figsize = (30, 7))\n",
    "            fig.set_facecolor('w')\n",
    "\n",
    "            timeseries_table_time = timeseries_table[(timeseries_table['lat_search'] == coords_search[i][0]) & \n",
    "                                                     (timeseries_table['lon_search'] == coords_search[i][1])]\n",
    "            ax.plot(timeseries_table_time['time'], timeseries_table_time['model_column'], \n",
    "                    label = model.upper(), linestyle = '--', marker = 'o', \n",
    "                    linewidth = 2, markersize = 10, color = 'blue')\n",
    "            ax.plot(timeseries_table_time['time'], timeseries_table_time['sensor_column'], \n",
    "                    label = 'GOME-2' if sensor == 'gome' else sensor.upper(),\n",
    "                    linestyle = '--', marker = 'o', linewidth = 2, markersize = 10, color = 'red')\n",
    "            \n",
    "            ax.legend(loc = 'center left', bbox_to_anchor = (1, 0.5), prop = {'size': 25})\n",
    "\n",
    "            if sensor_type == 'L2':\n",
    "                ax.set_xlabel('Estimated time', fontsize = 25)\n",
    "                \n",
    "            elif sensor_type == 'L3':\n",
    "                ax.set_xlabel('Month', fontsize = 25)\n",
    "\n",
    "            ax.tick_params(labelsize = 22)\n",
    "            ax.yaxis.get_offset_text().set_size(18) \n",
    "            ax.set_ylim([ymin, ymax])\n",
    "            ax.set_xticks(xticks)\n",
    "            ax.set_ylabel(f'{component_nom} ({units})', fontsize = 25)\n",
    "            ax.set_title(f'{component_nom} concentration in {region_name} ({coords_search[i][0]}, {coords_search[i][1]})', \n",
    "                         fontsize = 25, fontweight = 'bold', y = 1.05)\n",
    "        \n",
    "    timeseries_table = timeseries_table.set_index(['region', 'lat_search', 'lon_search', \n",
    "                                                   'latitude', 'longitude', 'time'])\n",
    "\n",
    "    return timeseries_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_annual_cycle(merge_df, component_nom, sensor, model, units, \n",
    "                         ymin, ymax, regions_names, bbox_list):\n",
    "\n",
    "    \"\"\" Get monthly annual cycle by region, defined by coordinates\n",
    "\n",
    "        Args:\n",
    "            merge_df (dataframe): Merge result\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor (str): Name of the sensor\n",
    "            model (str): Name of the model\n",
    "            units (str): Component units\n",
    "            ymin (float): Minimum y-axis value\n",
    "            ymax (float): Maximum y-axis value\n",
    "            regions_names (list): Region names\n",
    "            bbox_list (list): List of search bounding boxes (eg. (lat_min, lat_max, lon_min, lon_max, ...)\n",
    "\n",
    "        Returns:\n",
    "            monthly_annual_cycle_table (dataframe): Dataframe with monthly annual cycle for all regions given\n",
    "    \"\"\"\n",
    "\n",
    "    # Drop NaN values\n",
    "    merge_df = merge_df.dropna()\n",
    "\n",
    "    # Transform string to tuple (if there is only one element)\n",
    "    if isinstance(regions_names, str):\n",
    "        regions_names = tuple([regions_names])\n",
    "\n",
    "    merge_df = merge_df.reset_index()\n",
    "    merge_df['month'] = merge_df.apply(lambda row: row['time'].month, axis = 1)\n",
    "    available_months = np.unique(merge_df['month'])\n",
    "\n",
    "    regions_lats = pairwise(bbox_list)[0::2]\n",
    "    regions_lons = pairwise(bbox_list)[1::2]\n",
    "\n",
    "    monthly_annual_cycle_table = []\n",
    "\n",
    "    for region_lats, region_lons, region_name in zip(regions_lats, regions_lons, regions_names):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize = (30, 7))\n",
    "        fig.set_facecolor('w')\n",
    "\n",
    "        summary_region = []\n",
    "        \n",
    "        # Define and apply bounding box\n",
    "        region_bbox = ((region_lons[0], region_lats[0]), (region_lons[1], region_lats[1]))\n",
    "        merge_df_region = merge_df.query('longitude >= @region_bbox[0][0] and longitude <= @region_bbox[1][0] and latitude >= @region_bbox[0][1] and latitude <= @region_bbox[1][1]')\n",
    "\n",
    "        for month in available_months:\n",
    "\n",
    "            # Retrieve mean and standard deviation by month\n",
    "            merge_df_region_month = merge_df_region.query('month == @month')\n",
    "            descr_stats_table = merge_df_region_month.describe()\n",
    "            model_column_mean = descr_stats_table['model_column']['mean']\n",
    "            model_column_std = descr_stats_table['model_column']['std']\n",
    "            sensor_column_mean = descr_stats_table['sensor_column']['mean']\n",
    "            sensor_column_std = descr_stats_table['sensor_column']['std']\n",
    "\n",
    "            # Update summary\n",
    "            summary_region.append({'location': region_name, \n",
    "                                   'month': month,\n",
    "                                   'model mean': model_column_mean,\n",
    "                                   'model std': model_column_std,\n",
    "                                   'sensor mean': sensor_column_mean,\n",
    "                                   'sensor std': sensor_column_std\n",
    "                                  })\n",
    "\n",
    "        summary_region = pd.DataFrame(summary_region)\n",
    "        \n",
    "        # Create error bars\n",
    "        xval = available_months\n",
    "        model_yval = summary_region[summary_region['location'] == region_name]['model mean']\n",
    "        model_yerr = summary_region[summary_region['location'] == region_name]['model std']\n",
    "        sensor_yval = summary_region[summary_region['location'] == region_name]['sensor mean']\n",
    "        sensor_yerr = summary_region[summary_region['location'] == region_name]['sensor std']\n",
    "\n",
    "        plt.errorbar(xval, model_yval, yerr = model_yerr, label = model.upper(),\n",
    "                     linestyle = '--', marker = 'o', linewidth = 2, markersize = 10, color = 'blue')\n",
    "        plt.errorbar(xval, sensor_yval, yerr = sensor_yerr, label = 'GOME-2' if sensor == 'gome' else sensor.upper(),\n",
    "                     linestyle = '--', marker = 'o', linewidth = 2, markersize = 10, color = 'red')\n",
    "\n",
    "        ax.legend(loc = 'center left', bbox_to_anchor = (1, 0.5), prop = {'size': 25})\n",
    "        \n",
    "        # Format axes\n",
    "        ax.tick_params(labelsize = 22)\n",
    "        ax.yaxis.get_offset_text().set_size(18)\n",
    "        ax.set_xticks(np.arange(1, 13))\n",
    "        ax.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep','Oct', 'Nov', 'Dec'])\n",
    "        ax.set_ylim([ymin, ymax])\n",
    "        ax.set_ylabel(f'{component_nom} ({units})', fontsize = 25)\n",
    "        ax.set_title(f'{component_nom} mean concentration around {region_name} {region_bbox}', \n",
    "                     fontsize = 25, fontweight = 'bold', y = 1.05)\n",
    "        plt.show()\n",
    "\n",
    "        monthly_annual_cycle_table.append(summary_region)\n",
    "\n",
    "    monthly_annual_cycle_table = pd.concat(monthly_annual_cycle_table)\n",
    "    \n",
    "    return monthly_annual_cycle_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trends(merge_df, component_nom, sensor, model, units, ymin, ymax, \n",
    "           plot_dates, regions_names, bbox_list, sensor_break_date, model_break_date):\n",
    "\n",
    "    \"\"\" Get trends by region, defined by coordinates. These trends are generated following linear and sinusoidal models.\n",
    "\n",
    "        Args:\n",
    "            merge_df (dataframe): Merge table with total column data and their difference\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor (str): Name of the sensor\n",
    "            model (str): Name of the model\n",
    "            units (str): Component units\n",
    "            ymin (float): Minimum y-axis value\n",
    "            ymax (float): Maximum y-axis value\n",
    "            plot_dates (arr): Plot dates\n",
    "            regions_names (list): Region names\n",
    "            bbox_list (list): List of search bounding boxes (eg. (lat_min, lat_max, lon_min, lon_max, ...)\n",
    "            sensor_break_date (str): Break date (e.g. '2013-01-01) or None for sensor data\n",
    "            model_break_date (str): Break date (e.g. '2013-01-01) or None for model data\n",
    "\n",
    "        Returns:\n",
    "            trends_table (dataframe): Dataframe with trends for all regions given\n",
    "    \"\"\"\n",
    "\n",
    "    if len(np.unique(merge_df.reset_index()['time'])) >= 12:\n",
    "    \n",
    "        # Sinusoidal model\n",
    "        def objective_function_sin(X, C, D, E, N):\n",
    "            return C * np.sin(D * X + E) + N\n",
    "\n",
    "        # Transform string to tuple (if there is only one element)\n",
    "        if isinstance(regions_names, str):\n",
    "            regions_names = tuple([regions_names])\n",
    "\n",
    "        regions_lats = pairwise(bbox_list)[0::2]\n",
    "        regions_lons = pairwise(bbox_list)[1::2]\n",
    "\n",
    "        trends_table = []\n",
    "\n",
    "        # Drop NaN values\n",
    "        merge_df = merge_df.dropna()\n",
    "\n",
    "        for region_lats, region_lons, region_name in zip(regions_lats, regions_lons, regions_names):\n",
    "\n",
    "            summary_region = []\n",
    "            summary_region_trend = []\n",
    "\n",
    "            # Get data for each bounding box\n",
    "            region_bbox = ((region_lons[0], region_lats[0]), (region_lons[1], region_lats[1]))\n",
    "            merge_df_region = merge_df.query('longitude >= @region_bbox[0][0] and longitude <= @region_bbox[1][0] and latitude >= @region_bbox[0][1] and latitude <= @region_bbox[1][1]')\n",
    "\n",
    "            # Drop the dates that have NaN values\n",
    "            plot_dates = np.intersect1d(plot_dates, np.unique(merge_df.index.get_level_values(2)))\n",
    "            start_date = pd.to_datetime(plot_dates[0])\n",
    "\n",
    "            for time in plot_dates:\n",
    "                \n",
    "                # Get data for each time\n",
    "                merge_df_region_time = merge_df_region.query('time == @time').reset_index()\n",
    "\n",
    "                # Retrieve mean by date\n",
    "                if not merge_df_region_time.empty:\n",
    "\n",
    "                    # Calculate number of months since start date\n",
    "                    merge_df_region_time['month'] = merge_df_region_time.apply(lambda row: (row['time'].year - start_date.year) * 12 + \n",
    "                                                                                           (row['time'].month - start_date.month),\n",
    "                                                                                           axis = 1)\n",
    "                    merge_df_region_time = merge_df_region_time.reset_index()\n",
    "\n",
    "                    month = int(np.unique(merge_df_region_time['month']))\n",
    "                    descr_stats_table = merge_df_region_time.describe()\n",
    "                    model_column_mean = descr_stats_table['model_column']['mean']\n",
    "                    sensor_column_mean = descr_stats_table['sensor_column']['mean']  \n",
    "                    \n",
    "                    # Update summary\n",
    "                    summary_region.append({'location': region_name, \n",
    "                                           'time': time,\n",
    "                                           'month': month,\n",
    "                                           'model mean': model_column_mean,\n",
    "                                           'sensor mean': sensor_column_mean,\n",
    "                                          })\n",
    "\n",
    "            summary_region = pd.DataFrame(summary_region)\n",
    "\n",
    "            # Plot trends\n",
    "            fig, ax = plt.subplots(figsize = (30, 7))\n",
    "            fig.set_facecolor('w')\n",
    "\n",
    "            if sensor_break_date == None and model_break_date == None:\n",
    "                sources = ['sensor', 'model']\n",
    "                colors = ['blue', 'red']\n",
    "\n",
    "            elif sensor_break_date != None and model_break_date == None:\n",
    "                sources = ['sensor-1', 'sensor-2', 'model']\n",
    "                colors = ['blue', 'black', 'red']\n",
    "\n",
    "            elif sensor_break_date == None and model_break_date != None:\n",
    "                sources = ['sensor', 'model-1', 'model-2']\n",
    "                colors = ['blue', 'red', 'green']\n",
    "\n",
    "            elif sensor_break_date != None and model_break_date != None:\n",
    "                sources = ['sensor-1', 'sensor-2', 'model-1', 'model-2']\n",
    "                colors = ['blue', 'black', 'red', 'green']\n",
    "\n",
    "            for source, color in zip(sources, colors):\n",
    "                \n",
    "                # Get data to generate the trend fits\n",
    "                if sensor_break_date == None and model_break_date == None:\n",
    "                    X = summary_region['month'].values\n",
    "                    Y = summary_region[source + ' mean'].values\n",
    "\n",
    "                elif sensor_break_date != None and model_break_date == None:\n",
    "                    if source == 'model':\n",
    "                        X = summary_region['month'].values\n",
    "                        Y = summary_region[source + ' mean'].values\n",
    "                    \n",
    "                    elif source == 'sensor-1':\n",
    "                        X = summary_region[summary_region['time'] <= sensor_break_date]['month'].values\n",
    "                        Y = summary_region[summary_region['time'] <= sensor_break_date]['sensor mean'].values\n",
    "\n",
    "                    elif source == 'sensor-2':\n",
    "                        X = summary_region[summary_region['time'] > sensor_break_date]['month'].values\n",
    "                        Y = summary_region[summary_region['time'] > sensor_break_date]['sensor mean'].values\n",
    "\n",
    "                elif sensor_break_date == None and model_break_date != None:\n",
    "                    if source == 'sensor':\n",
    "                        X = summary_region['month'].values\n",
    "                        Y = summary_region[source + ' mean'].values\n",
    "\n",
    "                    if source == 'model-1':\n",
    "                        X = summary_region[summary_region['time'] <= model_break_date]['month'].values\n",
    "                        Y = summary_region[summary_region['time'] <= model_break_date]['model mean'].values\n",
    "\n",
    "                    elif source == 'model-2':\n",
    "                        X = summary_region[summary_region['time'] > model_break_date]['month'].values\n",
    "                        Y = summary_region[summary_region['time'] > model_break_date]['model mean'].values\n",
    "\n",
    "                elif sensor_break_date != None and model_break_date != None:\n",
    "                    if source == 'model-1':\n",
    "                        X = summary_region[summary_region['time'] <= model_break_date]['month'].values\n",
    "                        Y = summary_region[summary_region['time'] <= model_break_date]['model mean'].values\n",
    "\n",
    "                    elif source == 'model-2':\n",
    "                        X = summary_region[summary_region['time'] > model_break_date]['month'].values\n",
    "                        Y = summary_region[summary_region['time'] > model_break_date]['model mean'].values\n",
    "\n",
    "                    elif source == 'sensor-1':\n",
    "                        X = summary_region[summary_region['time'] <= sensor_break_date]['month'].values\n",
    "                        Y = summary_region[summary_region['time'] <= sensor_break_date]['sensor mean'].values\n",
    "\n",
    "                    elif source == 'sensor-2':\n",
    "                        X = summary_region[summary_region['time'] > sensor_break_date]['month'].values\n",
    "                        Y = summary_region[summary_region['time'] > sensor_break_date]['sensor mean'].values\n",
    "\n",
    "                # Plot lines and scatter\n",
    "                ax.scatter(X, Y, color = color, s = 100)\n",
    "\n",
    "                # Linear model\n",
    "                linear_fit_X, linear_fit_Y, B, A, linear_R2, linear_RMSE, linear_MSE = linear_regression(X.reshape(-1, 1), Y.reshape(-1, 1), component_nom, ax)\n",
    "                ax.plot(X, A + B * X, '--', color = color, linewidth = 3, \n",
    "                        label = model.upper() + ' (A + B*X' if (source == 'model' or source == 'model-1' or source == 'model-2')\n",
    "                                else 'GOME-2 (A + B*X)' if (source == 'sensor' or source == 'sensor-1' or source == 'sensor-2') and sensor == 'gome' \n",
    "                                else sensor.upper() + ' (A + B*X')\n",
    "\n",
    "                try:\n",
    "                    \n",
    "                    # Set initial conditions\n",
    "                    C0 = max(Y) - min(Y) # Initial amplitude\n",
    "                    D0 = np.pi/6 # Initial frequency\n",
    "                    E0 = 0 # Initial phase shift\n",
    "                    N0 = np.mean(Y) # Initial offset\n",
    "                    p0 = [C0, D0, E0, N0]\n",
    "\n",
    "                    # Fit curve\n",
    "                    sin_fit = curve_fit(objective_function_sin, X, Y, p0 = p0)\n",
    "                    C, D, E, N = sin_fit[0][0], sin_fit[0][1], sin_fit[0][2], sin_fit[0][3]\n",
    "                    sin_fit_Y = C * np.sin(D * X + E) + N\n",
    "\n",
    "                    # Calculate R2, RMSE and MSE\n",
    "                    sin_R2 = r2_score(y_true = Y, y_pred = sin_fit_Y)\n",
    "                    sin_MSE = mean_squared_error(y_true = Y, y_pred = sin_fit_Y, squared = True)\n",
    "                    sin_RMSE = mean_squared_error(y_true = Y, y_pred = sin_fit_Y, squared = False)\n",
    "\n",
    "                    ax.plot(X, C * np.sin(D * X + E) + N, color = color, linewidth = 3, \n",
    "                            label = model.upper() + ' (C*np.sin(D*X + E) + N)' if (source == 'model' or source == 'model-1' or source == 'model-2')\n",
    "                                    else 'GOME-2 (C*np.sin(D*X + E) + N)' if (source == 'sensor' or source == 'sensor-1' or source == 'sensor-2') and sensor == 'gome' \n",
    "                                    else sensor.upper() + ' (C*np.sin(D*X + E) + N)')\n",
    "\n",
    "                except:\n",
    "                    \n",
    "                    print(f'{source} data at {region_name} cannot be fitted with a sinusoidal model to account for the seasonality, consider working with a larger dataset.')\n",
    "                    sin_R2, sin_MSE, sin_RMSE = np.nan, np.nan, np.nan\n",
    "                    C, D, E, N = np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "                # Calculate number of months in study period\n",
    "                start_period = X[0]\n",
    "                end_period = X[-1]\n",
    "                period = start_period - end_period\n",
    "\n",
    "                # Calculate concentration difference in study period\n",
    "                start_conc = A + B*start_period\n",
    "                end_conc = A + B*end_period\n",
    "                diff_conc = start_conc - end_conc\n",
    "\n",
    "                # Calculate change rate\n",
    "                change_rate_units = (diff_conc * 12) / period\n",
    "                change_rate_100 = (diff_conc * 12) * 100 / (start_conc * period)\n",
    "\n",
    "                # Update summary\n",
    "                summary_region_trend.append({'Location': region_name, \n",
    "                                             'Source': source.capitalize(),\n",
    "                                             'Rate ('+ units +' y-1)': change_rate_units,\n",
    "                                             'Rate (% y-1)': change_rate_100,\n",
    "                                             'A': A, 'B': B,\n",
    "                                             'C': C, 'D': D,\n",
    "                                             'E': E, 'N': N,\n",
    "                                             'Linear R2': linear_R2, \n",
    "                                             'Linear RMSE': linear_RMSE,\n",
    "                                             'Linear MSE': linear_MSE,\n",
    "                                             'Sinusoidal R2': sin_R2, \n",
    "                                             'Sinusoidal RMSE': sin_RMSE,\n",
    "                                             'Sinusoidal MSE': sin_MSE,\n",
    "                                             })\n",
    "\n",
    "                # Format axes\n",
    "                ax.legend(loc='center left', bbox_to_anchor = (1, 0.5), prop = {'size': 27})\n",
    "                ax.tick_params(labelsize = 26)\n",
    "                ax.yaxis.get_offset_text().set_size(20)\n",
    "                months_num = summary_region['month'].values\n",
    "                ax.set_xticks(np.arange(months_num[0], months_num[-1] + 2, 6))\n",
    "                ax.set_xticklabels(np.arange(months_num[0], months_num[-1] + 2, 6))\n",
    "                ax.set_ylim([ymin, ymax])\n",
    "                ax.set_xlabel(f'Number of months', fontsize = 30)\n",
    "                ax.set_ylabel(f'{component_nom} ({units})', fontsize = 30)\n",
    "                ax.set_title(f'{component_nom} mean concentration around {region_name} {region_bbox}', \n",
    "                             fontsize = 30, fontweight = 'bold', y = 1.05)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            summary_region_trend = pd.DataFrame(summary_region_trend)\n",
    "            trends_table.append(summary_region_trend)\n",
    "\n",
    "        trends_table = pd.concat(trends_table)\n",
    "\n",
    "    else:\n",
    "        print('The trends can only be derived if there are data for more than a year.')\n",
    "\n",
    "    return trends_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_maps(trends_table, component_nom, sensor, model, sensor_type, model_type, \n",
    "               units, plot_dates, pad, y, source_1, source_2, start_period, end_period, \n",
    "               vmin_manual_rate_units, vmax_manual_rate_units, \n",
    "               vmin_manual_rate_100, vmax_manual_rate_100,\n",
    "               vmin_manual_diff_units, vmax_manual_diff_units, \n",
    "               vmin_manual_diff_100, vmax_manual_diff_100, width_lon, height_lat,\n",
    "               bbox_list, coords_list, regions_names):\n",
    "\n",
    "    \"\"\" Create 6 plots with:\n",
    "        -   Rate (units/year) for model data\n",
    "        -   Rate (%/year) for model data\n",
    "        -   Rate (units/year) for sensor data\n",
    "        -   Rate (%/year) for sensor data\n",
    "        -   Rate (units/year) for difference data\n",
    "        -   Rate (%/year) for difference data\n",
    "\n",
    "        Args:\n",
    "            trends_table (dataframe): Dataframe with trends for whole plot bounding box\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor (str): Name of the sensor\n",
    "            model (str): Name of the model\n",
    "            model_type (str): Model type:\n",
    "            -  'Forecast'\n",
    "            -  'Reanalysis'\n",
    "            sensor_type (str): Sensor type\n",
    "            units (str): Component units\n",
    "            plot_dates (arr): Plot dates\n",
    "            pad (float): Padding for the subtitles\n",
    "            y (float): y-position of main title\n",
    "            start_period (int): Number of months that have passed at start date\n",
    "            end_period (int): Number of months that have passed at end date\n",
    "            source_1 (str): This can be sensor, sensor-1 or sensor-2\n",
    "            source_2 (str): This can be model, model-1 or model-2\n",
    "            sensor_break_date (str): Break date (e.g. '2013-01-01) or None for sensor data\n",
    "            model_break_date (str): Break date (e.g. '2013-01-01) or None for model data\n",
    "            vmin_manual_rate_units (float): Input vmin by user for rate in units/year\n",
    "            vmax_manual_rate_units (float): Input vmax by user for rate in units/year\n",
    "            vmin_manual_rate_100 (float): Input vmin by user for rate in %/year\n",
    "            vmax_manual_rate_100 (float): Input vmax by user for rate in %/year\n",
    "            vmin_manual_diff_units (float): Input vmin by user rate difference in units/year\n",
    "            vmax_manual_diff_units (float): Input vmax by user rate difference in units/year\n",
    "            vmin_manual_diff_100 (float): Input vmin by user for rate difference in %/year\n",
    "            vmax_manual_diff_100 (float): Input vmax by user for rate difference in %/year\n",
    "            width_lon (int): Horizontal width of frame individual sections (black - white lines)\n",
    "            height_lat (int): Vertical height of frame individual sections (black - white lines)\n",
    "            bbox_list (list): List of search bounding boxes (eg. (lat_min, lat_max, lon_min, lon_max, ...)\n",
    "            coords_list (list): List of search coordinates (eg. (lat, lon, lat, lon, ...)\n",
    "            regions_names (list): Region names\n",
    "    \"\"\"\n",
    "\n",
    "    for rate_type, units_name, vmin, vmax, vmin_diff, vmax_diff in zip(['rate (' + units + ' y-1)', 'rate (% y-1)'],\n",
    "                                                                       ['Trend (' + units + ' y-1)', 'Trend (% y-1)'],\n",
    "                                                                       [vmin_manual_rate_units, vmin_manual_rate_100],\n",
    "                                                                       [vmax_manual_rate_units, vmax_manual_rate_100],\n",
    "                                                                       [vmin_manual_diff_units, vmin_manual_diff_100],\n",
    "                                                                       [vmax_manual_diff_units, vmax_manual_diff_100]):\n",
    "\n",
    "        trends_ds = trends_table.set_index(['source', 'latitude', 'longitude']).to_xarray()\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize = (20, 5), subplot_kw = {'projection': projection})\n",
    "        fig.set_facecolor('w')\n",
    "\n",
    "        # Difference array\n",
    "        diff_array = trends_ds.sel(source = source_2)[rate_type] - trends_ds.sel(source = source_1)[rate_type]\n",
    "\n",
    "        # First plot - Model rates\n",
    "        array = trends_ds.sel(source = source_2)[rate_type]\n",
    "        long_name = model.upper() + ' (' + model_type + ')'\n",
    "        visualize_pcolormesh(\n",
    "                            fig = fig, axs = axs[0],\n",
    "                            data_array = array,\n",
    "                            longitude = array.longitude,\n",
    "                            latitude = array.latitude,\n",
    "                            projection = projection,\n",
    "                            color_scale = color_scale[0],\n",
    "                            pad = pad,\n",
    "                            long_name = long_name,\n",
    "                            units_name = units_name,\n",
    "                            vmin = vmin, \n",
    "                            vmax = vmax, \n",
    "                            lon_min = plot_bbox[0][0],\n",
    "                            lon_max = plot_bbox[1][0],\n",
    "                            lat_min = plot_bbox[0][1],\n",
    "                            lat_max = plot_bbox[1][1],\n",
    "                            width_lon = width_lon,\n",
    "                            height_lat = height_lat,\n",
    "                            bbox_list = bbox_list, \n",
    "                            coords_list = coords_list,\n",
    "                            regions_names = regions_names\n",
    "                           )\n",
    "\n",
    "        # Second plot - Sensor rates\n",
    "        array = trends_ds.sel(source = source_1)[rate_type]\n",
    "        long_name = 'GOME-2' + ' (' + sensor_type + ')' if sensor == 'gome' else sensor.upper() + ' (' + sensor_type + ')'\n",
    "        visualize_pcolormesh(\n",
    "                            fig = fig, axs = axs[1],\n",
    "                            data_array = array,\n",
    "                            longitude = array.longitude,\n",
    "                            latitude = array.latitude,\n",
    "                            projection = projection,\n",
    "                            color_scale = color_scale[1],\n",
    "                            pad = pad,\n",
    "                            long_name = long_name,\n",
    "                            units_name = units_name,\n",
    "                            vmin = vmin,\n",
    "                            vmax = vmax, \n",
    "                            lon_min = plot_bbox[0][0],\n",
    "                            lon_max = plot_bbox[1][0],\n",
    "                            lat_min = plot_bbox[0][1],\n",
    "                            lat_max = plot_bbox[1][1],\n",
    "                            width_lon = width_lon,\n",
    "                            height_lat = height_lat,\n",
    "                            bbox_list = bbox_list, \n",
    "                            coords_list = coords_list,\n",
    "                            regions_names = regions_names\n",
    "                           )\n",
    "\n",
    "        # Second plot - Rate difference\n",
    "        array = diff_array\n",
    "        long_name = 'Difference (' + model.upper() + ' - ' + sensor.upper() + ')'  \n",
    "        visualize_pcolormesh(\n",
    "                            fig = fig, axs = axs[2],\n",
    "                            data_array = array,\n",
    "                            longitude = array.longitude,\n",
    "                            latitude = array.latitude,\n",
    "                            projection = projection,\n",
    "                            color_scale = color_scale[2],\n",
    "                            pad = pad,\n",
    "                            long_name = long_name,\n",
    "                            units_name = units_name,\n",
    "                            vmin = vmin_diff,\n",
    "                            vmax = vmax_diff, \n",
    "                            lon_min = plot_bbox[0][0],\n",
    "                            lon_max = plot_bbox[1][0],\n",
    "                            lat_min = plot_bbox[0][1],\n",
    "                            lat_max = plot_bbox[1][1],\n",
    "                            width_lon = width_lon,\n",
    "                            height_lat = height_lat,\n",
    "                            bbox_list = bbox_list, \n",
    "                            coords_list = coords_list,\n",
    "                            regions_names = regions_names\n",
    "                           )\n",
    "\n",
    "        fig.suptitle(f'TRENDS OF {component_nom} (Months {str(start_period)} - {str(end_period)})', \n",
    "                    fontsize = 18, fontweight = 'bold', y = y)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bbox_trends(merge_df, component_nom, sensor, model, units, plot_dates, \n",
    "                          sensor_break_date, model_break_date, pad, y,\n",
    "                          vmin_manual_rate_units, vmax_manual_rate_units, \n",
    "                          vmin_manual_rate_100, vmax_manual_rate_100,\n",
    "                          vmin_manual_diff_units, vmax_manual_diff_units, \n",
    "                          vmin_manual_diff_100, vmax_manual_diff_100,\n",
    "                          width_lon, height_lat, \n",
    "                          bbox_list = None, coords_list = None, regions_names = None):\n",
    "\n",
    "    \"\"\" Get trends at whole plot bounding box. These trends are generated following a linear model.\n",
    "        This function is only available for trends without breaks or with a common break \n",
    "        at the same day for both the model and sensor datasets.\n",
    "\n",
    "        Args:\n",
    "            merge_df (dataframe): Merge table with total column data and their difference\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor (str): Name of the sensor\n",
    "            model (str): Name of the model\n",
    "            model_type (str): Model type:\n",
    "            -  'Forecast'\n",
    "            -  'Reanalysis'\n",
    "            sensor_type (str): Sensor type\n",
    "            units (str): Component units\n",
    "            plot_dates (arr): Plot dates\n",
    "            sensor_break_date (str): Break date (e.g. '2013-01-01) or None for sensor data\n",
    "            model_break_date (str): Break date (e.g. '2013-01-01) or None for model data\n",
    "            pad (float): Padding for the subtitles\n",
    "            y (float): y-position of main title\n",
    "            vmin_manual_rate_units (float): Input vmin by user for rate in units/year\n",
    "            vmax_manual_rate_units (float): Input vmax by user for rate in units/year\n",
    "            vmin_manual_rate_100 (float): Input vmin by user for rate in %/year\n",
    "            vmax_manual_rate_100 (float): Input vmax by user for rate in %/year\n",
    "            vmin_manual_diff_units (float): Input vmin by user rate difference in units/year\n",
    "            vmax_manual_diff_units (float): Input vmax by user rate difference in units/year\n",
    "            vmin_manual_diff_100 (float): Input vmin by user for rate difference in %/year\n",
    "            vmax_manual_diff_100 (float): Input vmax by user for rate difference in %/year\n",
    "            width_lon (int): Horizontal width of frame individual sections (black - white lines)\n",
    "            height_lat (int): Vertical height of frame individual sections (black - white lines)\n",
    "            bbox_list (list): List of search bounding boxes (eg. (lat_min, lat_max, lon_min, lon_max, ...)\n",
    "            coords_list (list): List of search coordinates (eg. (lat, lon, lat, lon, ...)\n",
    "            regions_names (list): Region names\n",
    "    \"\"\"\n",
    "    \n",
    "    if ((sensor_break_date != None and model_break_date != None and sensor_break_date != model_break_date) or\n",
    "        (sensor_break_date != None and model_break_date == None) or\n",
    "        (sensor_break_date == None and model_break_date != None)):\n",
    "            print('Trend maps can only be generated when the break date is the same for both datasets or when there are no break dates.')\n",
    "            raise KeyboardInterrupt()\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('WARNING: Computing the trends for each coordinate will take some time.')\n",
    "        trends_table = []\n",
    "\n",
    "        # Drop NaN values\n",
    "        merge_df = merge_df.dropna()\n",
    "        \n",
    "        # Drop the dates that have NaN values\n",
    "        plot_dates = np.intersect1d(plot_dates, np.unique(merge_df.index.get_level_values(2)))\n",
    "        start_date = pd.to_datetime(plot_dates[0])\n",
    "\n",
    "        for latitude in np.unique(merge_df.index.get_level_values(0)):\n",
    "            for longitude in np.unique(merge_df.index.get_level_values(1)):\n",
    "            \n",
    "                # Get data for each set of coordinates\n",
    "                merge_df_region = merge_df.query('longitude == @longitude and latitude == @latitude')\n",
    "\n",
    "                #if len(np.unique(merge_df_region.index.get_level_values(2))) == len(plot_dates):\n",
    "                    \n",
    "                summary_region = []\n",
    "                summary_region_trend = []\n",
    "\n",
    "                for time in plot_dates:\n",
    "                \n",
    "                    # Get data for each time\n",
    "                    merge_df_region_time = merge_df_region.query('time == @time').reset_index()\n",
    "\n",
    "                    # Retrieve total columns by pixel and date\n",
    "                    if not merge_df_region_time.empty:\n",
    "\n",
    "                        # Calculate number of months since start date\n",
    "                        merge_df_region_time['month'] = merge_df_region_time.apply(lambda row: ((row['time'].year - start_date.year) * 12 + \n",
    "                                                                                                (row['time'].month - start_date.month)), axis = 1)\n",
    "                        merge_df_region_time = merge_df_region_time.reset_index()\n",
    "\n",
    "                        month = int(np.unique(merge_df_region_time['month']))\n",
    "\n",
    "                        # Update summary\n",
    "                        summary_region.append({'latitude': latitude, \n",
    "                                               'longitude': longitude,\n",
    "                                               'time': time,\n",
    "                                               'month': month,\n",
    "                                               'model column': merge_df_region_time['model_column'].iloc[0],\n",
    "                                               'sensor column': merge_df_region_time['sensor_column'].iloc[0]\n",
    "                                              })\n",
    "\n",
    "                summary_region = pd.DataFrame(summary_region)\n",
    "\n",
    "                # Create axes to get the limits for the linear regression\n",
    "                fig, ax = plt.subplots(figsize = (30, 7))\n",
    "                fig.set_facecolor('w')\n",
    "\n",
    "                if sensor_break_date == None and model_break_date == None:\n",
    "                    sources = ['sensor', 'model']\n",
    "\n",
    "                elif sensor_break_date != None and model_break_date != None:\n",
    "                    sources = ['sensor-1', 'sensor-2', 'model-1', 'model-2']\n",
    "\n",
    "                for source in sources:\n",
    "                    \n",
    "                    # Get data to generate the trend fits\n",
    "                    if sensor_break_date == None and model_break_date == None:\n",
    "                        X = summary_region['month'].values\n",
    "                        Y = summary_region[source + ' column'].values\n",
    "\n",
    "                    elif sensor_break_date != None and model_break_date != None and sensor_break_date == model_break_date:\n",
    "                        if source == 'model-1':\n",
    "                            X = summary_region[summary_region['time'] <= model_break_date]['month'].values\n",
    "                            Y = summary_region[summary_region['time'] <= model_break_date]['model column'].values\n",
    "\n",
    "                        elif source == 'model-2':\n",
    "                            X = summary_region[summary_region['time'] > model_break_date]['month'].values\n",
    "                            Y = summary_region[summary_region['time'] > model_break_date]['model column'].values\n",
    "\n",
    "                        elif source == 'sensor-1':\n",
    "                            X = summary_region[summary_region['time'] <= sensor_break_date]['month'].values\n",
    "                            Y = summary_region[summary_region['time'] <= sensor_break_date]['sensor column'].values\n",
    "\n",
    "                        elif source == 'sensor-2':\n",
    "                            X = summary_region[summary_region['time'] > sensor_break_date]['month'].values\n",
    "                            Y = summary_region[summary_region['time'] > sensor_break_date]['sensor column'].values\n",
    "\n",
    "                    # Plot lines and scatter\n",
    "                    ax.scatter(X, Y, s = 100)\n",
    "                    plt.close(fig)\n",
    "\n",
    "                    # Linear model\n",
    "                    linear_fit_X, linear_fit_Y, B, A, linear_R2, linear_RMSE, linear_MSE = linear_regression(X.reshape(-1, 1), Y.reshape(-1, 1), component_nom, ax)\n",
    "\n",
    "                    # Calculate number of months in study period\n",
    "                    start_period = X[0]\n",
    "                    end_period = X[-1]\n",
    "                    period = start_period - end_period\n",
    "\n",
    "                    # Calculate concentration difference in study period\n",
    "                    start_conc = A + B*start_period\n",
    "                    end_conc = A + B*end_period\n",
    "                    diff_conc = start_conc - end_conc\n",
    "\n",
    "                    # Calculate change rate\n",
    "                    change_rate_units = (diff_conc * 12) / period\n",
    "                    change_rate_100 = (diff_conc * 12) * 100 / (start_conc * period)\n",
    "\n",
    "                    # Update summary\n",
    "                    summary_region_trend.append({'latitude': latitude, \n",
    "                                                 'longitude': longitude,\n",
    "                                                 'source': source,\n",
    "                                                 'rate (' + units + ' y-1)': change_rate_units,\n",
    "                                                 'rate (% y-1)': change_rate_100,\n",
    "                                                 'A': A, 'B': B\n",
    "                                                })\n",
    "\n",
    "                summary_region_trend = pd.DataFrame(summary_region_trend)\n",
    "                trends_table.append(summary_region_trend)\n",
    "\n",
    "        trends_table = pd.concat(trends_table)       \n",
    "        \n",
    "        if sensor_break_date == None and model_break_date == None:\n",
    "\n",
    "            # Get sources (sensor and model)\n",
    "            source_1 = sources[0]\n",
    "            source_2 = sources[1]\n",
    "\n",
    "            # Get number of months at start and end\n",
    "            start_period = summary_region['month'].values[0]\n",
    "            end_period = summary_region['month'].values[-1]\n",
    "            \n",
    "            # Generate maps\n",
    "            trend_maps(trends_table, component_nom, sensor, model, sensor_type, model_type, \n",
    "                        units, plot_dates, pad, y, source_1, source_2, start_period, end_period, \n",
    "                        vmin_manual_rate_units, vmax_manual_rate_units, \n",
    "                        vmin_manual_rate_100, vmax_manual_rate_100,\n",
    "                        vmin_manual_diff_units, vmax_manual_diff_units, \n",
    "                        vmin_manual_diff_100, vmax_manual_diff_100, width_lon, height_lat,\n",
    "                        bbox_list, coords_list, regions_names)\n",
    "\n",
    "        elif sensor_break_date != None and model_break_date != None and sensor_break_date == model_break_date:\n",
    "            \n",
    "            # Swap source names\n",
    "            sources[1], sources[2] = sources[2], sources[1]\n",
    "            j = 0\n",
    "\n",
    "            for i in range(2):\n",
    "\n",
    "                # Get sources in pairs (sensor-1 and model-1, sensor-2 and model-2)\n",
    "                source_1 = sources[j]\n",
    "                source_2 = sources[j + 1]\n",
    "                \n",
    "                # Get number of months at start and end\n",
    "                if i == 0:\n",
    "                    start_period = summary_region[summary_region['time'] <= model_break_date]['month'].values[0]\n",
    "                    end_period = summary_region[summary_region['time'] <= model_break_date]['month'].values[-1]\n",
    "                elif i == 1:\n",
    "                    start_period = summary_region[summary_region['time'] > model_break_date]['month'].values[0]\n",
    "                    end_period = summary_region[summary_region['time'] > model_break_date]['month'].values[-1]\n",
    "                \n",
    "                # Generate maps\n",
    "                trend_maps(trends_table, component_nom, sensor, model, sensor_type, model_type, \n",
    "                           units, plot_dates, pad, y, source_1, source_2, start_period, end_period, \n",
    "                           vmin_manual_rate_units, vmax_manual_rate_units, \n",
    "                           vmin_manual_rate_100, vmax_manual_rate_100,\n",
    "                           vmin_manual_diff_units, vmax_manual_diff_units, \n",
    "                           vmin_manual_diff_100, vmax_manual_diff_100, width_lon, height_lat,\n",
    "                           bbox_list, coords_list, regions_names)\n",
    "                j += 2   \n",
    "\n",
    "    return trends_table"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc2967d46b8688a8c6de8a18a3daae8ebe0b7dc5d18d27687b3fe01b2a6426f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env-new': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
