{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# General functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def comparison_check(sensor, model, component_nom, model_full_name):\n",
    "\n",
    "    \"\"\" Check if the comparison is possible\n",
    "\n",
    "        Args:\n",
    "            sensor (str): Name of the sensor\n",
    "            model (str): Name of the model\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            model_full_name (str): Full name of the CAMS model among:\n",
    "            - 'cams-global-atmospheric-composition-forecasts' \n",
    "            - 'cams-global-reanalysis-eac4-monthly'\n",
    "    \"\"\"\n",
    "\n",
    "    if ((sensor == 'tropomi' and model == 'cams') or \n",
    "        (sensor == 'iasi' and model == 'cams') or\n",
    "        (sensor == 'gome' and model == 'cams')):\n",
    "\n",
    "        if (model_full_name != 'cams-global-atmospheric-composition-forecasts' and\n",
    "            model_full_name != 'cams-global-reanalysis-eac4-monthly'):\n",
    "\n",
    "            print('ERROR: The model is not supported.')\n",
    "            print('The models that are currently supported are:')\n",
    "            print('- cams-global-atmospheric-composition-forecasts')\n",
    "            print('- cams-global-reanalysis-eac4-monthly')\n",
    "            raise KeyboardInterrupt\n",
    "\n",
    "        else:\n",
    "            \n",
    "            tropomi_component_nom = ['NO2', 'CO', 'O3', 'SO2']\n",
    "            iasi_component_nom = ['CO', 'O3']\n",
    "            gome_component_nom = ['NO2', 'O3']\n",
    "\n",
    "            if ((sensor == 'tropomi' and component_nom not in tropomi_component_nom) or\n",
    "                (sensor == 'iasi' and component_nom not in iasi_component_nom) or\n",
    "                (sensor == 'gome' and component_nom not in gome_component_nom)):\n",
    "\n",
    "                print(f'ERROR: This specific component cannot be retrieved by the sensor {sensor.upper()}.')\n",
    "                raise KeyboardInterrupt\n",
    "\n",
    "            else:\n",
    "\n",
    "                print('The comparison is possible and will start now.')\n",
    "    else:\n",
    "\n",
    "        print('The comparison is only possible for:')\n",
    "        print('1. cams (CAMS model) vs. tropomi (TROPOMI sensor)')\n",
    "        print('2. cams (CAMS model) vs. iasi (IASI sensor)')\n",
    "        print('2. cams (CAMS model) vs. gome (GOME-2 sensor)')\n",
    "\n",
    "        raise KeyboardInterrupt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def components_table(sensor, component_nom):\n",
    "\n",
    "    \"\"\" Create table with information about the components (molecular weight, full name in different datasets)\n",
    "\n",
    "        Args:\n",
    "            sensor (str): Name of the sensor\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "\n",
    "        Returns:\n",
    "            component (str): Component name\n",
    "            component_mol_weight (float): Component molecular weight\n",
    "            component_sensor_product (str): Component product name in TROPOMI, IASI or GOME-2 database\n",
    "            sensor_column (str): Component column name in TROPOMI, IASI or GOME-2 database\n",
    "    \"\"\"\n",
    "\n",
    "    component_nom_col = ['NO2', 'CO', 'O3', 'SO2', 'CH4']\n",
    "\n",
    "    component_col = ['nitrogen_dioxide', 'carbon_monoxide', 'ozone', 'sulfur_dioxide', 'methane']\n",
    "    component_mol_weight_col = [46.005, 28.01, 48, 64.066, 16.04]\n",
    "    component_tropomi_product_col = ['L2__NO2___', 'L2__CO____', 'L2__O3____', 'L2__SO2___', 'L2__CH4___']\n",
    "    component_tropomi_column_col = ['nitrogendioxide_tropospheric_column', \n",
    "                                    'carbonmonoxide_total_column', \n",
    "                                    'ozone_total_vertical_column', \n",
    "                                    'sulfurdioxide_total_vertical_column',\n",
    "                                    'methane_tropospheric_column',\n",
    "                                    ]\n",
    "    component_iasi_column_col = ['-', 'COgridDAY', 'O3gridDAY', '-', '-']\n",
    "    component_gome_column_col = ['NO2total', '-', 'tropospheric_O3', '-', '-']\n",
    "\n",
    "    rows = {'Nomenclature': component_nom_col, \n",
    "            'Weight': component_mol_weight_col,\n",
    "            'Component': component_col, \n",
    "            'TROPOMI_product': component_tropomi_product_col,\n",
    "            'TROPOMI_column': component_tropomi_column_col,\n",
    "            'IASI_column': component_iasi_column_col,\n",
    "            'GOME_column': component_gome_column_col}\n",
    "\n",
    "    components_table = pd.DataFrame(rows)\n",
    "\n",
    "    component = components_table['Component'].loc[components_table['Nomenclature'] == component_nom].iloc[0]\n",
    "    component_mol_weight = components_table['Weight'].loc[components_table['Nomenclature'] == component_nom].iloc[0]\n",
    "    \n",
    "    if sensor == 'tropomi':\n",
    "        component_sensor_product = components_table['TROPOMI_product'].loc[components_table['Nomenclature'] == component_nom].iloc[0]\n",
    "\n",
    "    elif sensor == 'iasi' or sensor == 'gome':\n",
    "        component_sensor_product = None\n",
    "    \n",
    "    sensor_column = components_table[sensor.upper() +'_column'].loc[components_table['Nomenclature'] == component_nom].iloc[0]\n",
    "\n",
    "    return component, component_mol_weight, component_sensor_product, sensor_column"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def generate_folders(model, sensor, component_nom):\n",
    "\n",
    "    \"\"\" Generate folders to download the datasets if they do not exist \n",
    "\n",
    "        Args:\n",
    "            model (str): Name of the model\n",
    "            sensor (str): Name of the sensor\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "    \"\"\"\n",
    "\n",
    "    model_path = os.path.join(os.path.abspath(''), 'data/' + model + '/' + component_nom)\n",
    "    sensor_path = os.path.join(os.path.abspath(''), 'data/' + sensor + '/' + component_nom)\n",
    "\n",
    "    paths = [model_path, sensor_path]\n",
    "\n",
    "    for path in paths:\n",
    "        os.makedirs(path, exist_ok = True) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def sensor_convert_units(sensor_ds, sensor_column, sensor, component):\n",
    "\n",
    "    \"\"\" Convert the units of the sensor dataset for any component from mol/m2 to molecules/cm2\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): sensor dataset in xarray format (TROPOMI, IASI or GOME-2)\n",
    "            sensor_column (str): Component column name in TROPOMI, IASI or GOME-2 database\n",
    "            sensor (str): Name of the sensor\n",
    "            component (str): Component name\n",
    "            \n",
    "        Returns:\n",
    "            sensor_ds (xarray): sensor dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if sensor == 'tropomi':\n",
    "        \n",
    "        if sensor_ds[sensor_column].units == 'mol m-2':\n",
    "\n",
    "            sensor_ds[sensor_column] = sensor_ds[sensor_column] * 6.02214*10**19\n",
    "            sensor_ds[sensor_column] = sensor_ds[sensor_column].assign_attrs({'units': 'molec cm-2'})\n",
    "            print('The sensor component units have been converted from mol cm-2 to molec cm-2.')\n",
    "            \n",
    "            if 'apriori_profile' in list(sensor_ds.keys()):\n",
    "                sensor_ds['apriori_profile'] = sensor_ds['apriori_profile'] * 6.02214*10**19\n",
    "\n",
    "            if sensor_ds[sensor_column].units == 'molec cm-2' and component == 'ozone':\n",
    "                sensor_ds[sensor_column] = sensor_ds[sensor_column] / (2.69*10**16)\n",
    "                sensor_ds[sensor_column] = sensor_ds[sensor_column].assign_attrs({'units': 'DU'})\n",
    "                print('The sensor component units have been converted from molec cm-2 to DU.')\n",
    "\n",
    "                if 'apriori_profile' in list(sensor_ds.keys()):\n",
    "                    sensor_ds['apriori_profile'] = sensor_ds['apriori_profile'] / (2.69*10**16)\n",
    "\n",
    "    elif sensor == 'iasi' or sensor == 'gome':\n",
    "        \n",
    "        if sensor_ds[sensor_column].units == 'mol m-2':\n",
    "\n",
    "            sensor_ds = sensor_ds * 6.02214*10**19\n",
    "            sensor_ds[sensor_column] = sensor_ds[sensor_column].assign_attrs({'units': 'molec cm-2'})\n",
    "            print('The sensor component units have been converted from mol cm-2 to molec cm-2.')\n",
    "\n",
    "        if sensor_ds[sensor_column].units == 'molec cm-2' and component == 'ozone':\n",
    "            sensor_ds = sensor_ds / (2.69*10**16)\n",
    "            sensor_ds[sensor_column] = sensor_ds[sensor_column].assign_attrs({'units': 'DU'})\n",
    "            print('The sensor component units have been converted from molec cm-2 to DU.')\n",
    "\n",
    "    return sensor_ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def model_convert_units(model_ds, model, component_mol_weight, component, conversion_method):\n",
    "\n",
    "    \"\"\" Convert the units of the model dataset for any component from kg/kg or kg/m2 to molecules/cm2\n",
    "\n",
    "        Args:\n",
    "            model_ds (xarray): model dataset in xarray format (CAMS)\n",
    "            model (str): Name of the model\n",
    "            component_mol_weight (float): Component molecular weight\n",
    "            component (str): Component name\n",
    "            conversion_method (str): Type of conversion. It can be:\n",
    "            * Simple: Multiply the partial columns by the layer depth and density\n",
    "            * Complex: Calculate the partial column above each CAMS half level\n",
    "                        \n",
    "        Returns:\n",
    "            model_ds (xarray): model dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if model == 'cams':\n",
    "\n",
    "        if model_ds.component.units == 'kg kg**-1':\n",
    "\n",
    "            model_ds = CAMS_kg_kg_to_kg_m2(model_ds, model_levels_df, conversion_method)\n",
    "            model_ds['component'] = model_ds.component.assign_attrs({'units': 'kg m**-2'})\n",
    "            print('The model component units have been converted from kg kg**-1 to kg m**-2.')\n",
    "            units = 'kg m**-2'\n",
    "            \n",
    "        if model_ds.component.units == 'kg m**-2':\n",
    "\n",
    "            model_ds = CAMS_kg_m2_to_molecules_cm2(model_ds, component_mol_weight)\n",
    "            model_ds['component'] = model_ds.component.assign_attrs({'units': 'molec cm-2'})\n",
    "            print('The model component units have been converted from kg m**-2 to molec cm-2.')\n",
    "            units = 'molec cm-2'\n",
    "\n",
    "        if model_ds.component.units == 'molec cm-2' and component == 'ozone':\n",
    "\n",
    "            model_ds = CAMS_molecules_cm2_to_DU(model_ds, component_mol_weight)\n",
    "            model_ds['component'] = model_ds.component.assign_attrs({'units': 'DU'})\n",
    "            print('The model component units have been converted from molec cm-2 to DU.')\n",
    "            units = 'DU'\n",
    "\n",
    "    return model_ds, units"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def nearest_neighbour(array, value):\n",
    "\n",
    "    \"\"\" Find index of the closest value in a 1D-array\n",
    "\n",
    "        Args:\n",
    "            array (arr): Array to find the nearest neighbour\n",
    "            value (float): Search value\n",
    "    \"\"\"\n",
    "\n",
    "    index = np.abs([x - value for x in array]).argmin(0)\n",
    "    \n",
    "    return index"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def closest_point(point, array):\n",
    "\n",
    "    \"\"\" Find pair the closest values in a 2D-array\n",
    "\n",
    "        Args:\n",
    "            array (arr): Array to find the nearest neighbour\n",
    "            point (tuple): Search coordinates\n",
    "    \"\"\"\n",
    "\n",
    "    pair = array[cdist([point], array).argmin()]\n",
    "\n",
    "    return pair"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def pairwise(dates):\n",
    "\n",
    "    \"\"\" Split dates array in pairs\n",
    "\n",
    "        Args:\n",
    "            dates (arr): All dates\n",
    "\n",
    "        Returns:\n",
    "            period (tuple): Divisible dates into pairs\n",
    "    \"\"\"\n",
    "\n",
    "    pair_element = iter(dates)\n",
    "    period = list(zip(pair_element, pair_element))\n",
    "\n",
    "    return period"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def subset(ds, bbox):\n",
    "\n",
    "    \"\"\" Subset any dataset (with latitude and longitude as coordinates) into desired bounding box.\n",
    "\n",
    "        Args:\n",
    "            ds (xarray): Dataset in xarray format\n",
    "            bbox (arr): Query bounding box\n",
    "    \n",
    "        Returns:\n",
    "            ds (xarray): Dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    # Get nearest longitude and latitude to bbox\n",
    "    lon_min_index = nearest_neighbour(ds.longitude.data, bbox[0][0])\n",
    "    lon_max_index = nearest_neighbour(ds.longitude.data, bbox[1][0])\n",
    "    lat_min_index = nearest_neighbour(ds.latitude.data, bbox[0][1])\n",
    "    lat_max_index = nearest_neighbour(ds.latitude.data, bbox[1][1])\n",
    "\n",
    "    # Define slices\n",
    "    slice_lat = slice(lat_min_index, lat_max_index + 1)\n",
    "    slice_lon = slice(lon_min_index, lon_max_index + 1)\n",
    "\n",
    "    # Set limits\n",
    "    ds = ds.isel(longitude = slice_lon, latitude = slice_lat)\n",
    "\n",
    "    return ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def prepare_df(match_df, sensor, sensor_column, component_nom):\n",
    "\n",
    "    \"\"\" Prepare dataframe for match\n",
    "\n",
    "        Args:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "            sensor (str): Name of the sensor\n",
    "            sensor_column (str): Component column name in TROPOMI, IASI or GOME-2 database\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "        \n",
    "        Returns:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "    \"\"\"\n",
    "\n",
    "    if sensor == 'tropomi':\n",
    "\n",
    "        # Pass NaNs to data with qa_value under 0.5\n",
    "        match_df.loc[match_df['qa_value'] < 0.5, [sensor_column, 'column_kernel']] = float('NaN')\n",
    "\n",
    "        # Drop levels\n",
    "        if component_nom == 'CO' or component_nom == 'SO2':\n",
    "            \n",
    "            match_df.index.names = ['corner', 'ground_pixel', 'layer', 'scanline']\n",
    "        \n",
    "        elif component_nom == 'O3':\n",
    "\n",
    "            match_df.index.names = ['corner', 'ground_pixel', 'layer', 'level', 'scanline']\n",
    "            \n",
    "        match_df = match_df.groupby(by = ['layer', 'scanline', 'ground_pixel', 'time', 'delta_time']).mean()\n",
    "        match_df = match_df.reset_index(level = ['layer', 'delta_time'])\n",
    "\n",
    "    elif sensor == 'iasi' or sensor == 'gome':\n",
    "\n",
    "        match_df = match_df.reset_index(level = ['latitude', 'longitude'])\n",
    "\n",
    "    return match_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def generate_match_table(sensor_ds, model_ds, bbox, kernels_method, \n",
    "                         sensor, component_nom, sensor_column, *args):\n",
    "\n",
    "    \"\"\" Intermediate merge table with total column or partial column from both datasets, \n",
    "        the averaging kernels are applied if possible\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): sensor dataset in xarray format (TROPOMI, IASI or GOME-2)\n",
    "            model_ds (xarray): model dataset in xarray format (CAMS)\n",
    "            bbox (arr): Query bounding box\n",
    "            kernels_method (str): Method to apply averaging kernels to model space:\n",
    "            * Nearest neighbours: Find nearest neighbours horizontally and vertically\n",
    "            * Interpolation: Find nearest neighbours horizontally and interpolate vertically\n",
    "            sensor (str): Name of the sensor\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor_column (str): Component column name in TROPOMI, IASI or GOME-2 database\n",
    "            *args: Include 'model_levels_df' if interpolation is wanted\n",
    "\n",
    "        Returns:\n",
    "            match_table (dataframe): Intermediate merge table with total column or partial column from both datasets\n",
    "    \"\"\"\n",
    "\n",
    "    match_table = pd.DataFrame()\n",
    "\n",
    "    for time in sensor_ds.time.values:\n",
    "        \n",
    "        # Print estimated time or month\n",
    "        if sensor == 'tropomi':\n",
    "            print(f'FOR EST. TIME: {time}')\n",
    "\n",
    "        elif sensor == 'iasi' or sensor == 'gome':\n",
    "            month = np.datetime64(time).astype('datetime64[M]')\n",
    "            print(f'FOR MONTH: {month}')\n",
    "        \n",
    "        # Reduce data to only one timestamp\n",
    "        model_ds_time = model_ds.sel(time = time)\n",
    "        sensor_ds_time = sensor_ds.sel(time = time)\n",
    "\n",
    "        # Subset sensor data xarray\n",
    "        if sensor == 'tropomi':\n",
    "\n",
    "            sensor_ds_time = TROPOMI_subset(sensor_ds_time, bbox, time, sensor, component_nom)\n",
    "\n",
    "        elif sensor == 'iasi' or sensor == 'gome':\n",
    "            sensor_ds_time = subset(sensor_ds_time, bbox)\n",
    "        \n",
    "        # Transform into dataframe\n",
    "        match_df = sensor_ds_time.to_dataframe()\n",
    "        \n",
    "        # Prepare dataframe for following functions\n",
    "        match_df = prepare_df(match_df, sensor, sensor_column, component_nom)\n",
    "        \n",
    "        if 'column_kernel' in list(sensor_ds.keys()) and kernels_method != None:\n",
    "                \n",
    "            print('This dataset contains data to apply the averaging kernels.')\n",
    "            match_df = TROPOMI_apply_avg_kernels(kernels_method, match_df, model_ds_time, \n",
    "                                                 sensor_ds_time, sensor_column, model_levels_df)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print('The dataset does not contain data to apply the averaging kernels.')\n",
    "\n",
    "            if 'hybrid' in list(model_ds.coords):\n",
    "\n",
    "                print('The partial columns will be sumed up.')\n",
    "                print('The sum will be matched to the sensor data by nearest neighbours.')\n",
    "\n",
    "                model_ds_time = model_ds_time.component.sum(dim = 'hybrid', skipna = False)\n",
    "                model_times = model_ds_time.valid_time.data\n",
    "                \n",
    "                match_df['step_index'] = match_df.apply(lambda row: nearest_neighbour(model_times, row['delta_time']), axis = 1)\n",
    "                match_df['model_time'] = match_df.apply(lambda row: model_ds_time.valid_time[row['step_index']].values, axis = 1)\n",
    "                match_df['model_column'] = match_df.apply(lambda row: model_ds_time.sel(latitude = row['latitude'], \n",
    "                                                                                longitude = row['longitude'],\n",
    "                                                                                method = 'nearest').isel(step = \n",
    "                                                                                int(row['step_index'])).values, \n",
    "                                                                                axis = 1)\n",
    "\n",
    "            else:\n",
    "\n",
    "                print('The model does not contain levels data.')\n",
    "                print('The columns model data will be matched to the sensor data by nearest neighbours.')\n",
    "\n",
    "                model_times = model_ds_time.valid_time.data\n",
    "                \n",
    "                match_df['model_column'] = match_df.apply(lambda row: float(model_ds_time.sel(latitude = row['latitude'], \n",
    "                                                                            longitude = row['longitude'],\n",
    "                                                                            method = 'nearest').component.values), \n",
    "                                                                            axis = 1)\n",
    "            \n",
    "        if 'hybrid' in list(model_ds.coords):\n",
    "            match_df = match_df.set_index('layer', append = True)\n",
    "\n",
    "        match_df = match_df[~match_df.index.duplicated()]\n",
    "        match_table = match_table.append(match_df)\n",
    "\n",
    "    return match_table"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def generate_merge_table(match_table, sensor_ds, model_ds, kernels_method, sensor_column, sensor):\n",
    "\n",
    "    \"\"\" Final merge table with total column component data for each dataset, \n",
    "        their difference in each grid point are calculated\n",
    "\n",
    "        Args:\n",
    "            match_table (dataframe): Intermediate merge table with total column or partial column from both datasets\n",
    "            sensor_ds (xarray): sensor dataset in xarray format (TROPOMI, IASI or GOME-2)\n",
    "            model_ds (xarray): model dataset in xarray format (CAMS)\n",
    "            kernels_method (str): Method to apply averaging kernels to model space:\n",
    "            * Nearest neighbours: Find nearest neighbours horizontally and vertically\n",
    "            * Interpolation: Find nearest neighbours horizontally and interpolate vertically\n",
    "            sensor_column (str): Component column name in TROPOMI, IASI or GOME-2 database\n",
    "            sensor (str): Name of the sensor\n",
    "        \n",
    "        Returns:\n",
    "            merge_table (dataframe): Merge table with datasets column data and their difference\n",
    "    \"\"\"\n",
    "\n",
    "    merge_table = []\n",
    "        \n",
    "    if 'hybrid' in list(model_ds.coords):\n",
    "\n",
    "        for time in sensor_ds.time.values:\n",
    "\n",
    "            match_ds = match_table.query('time == @time').to_xarray()\n",
    "\n",
    "            # Read latitudes and longitudes from data array\n",
    "            latitude = match_ds.sel(time = time).latitude.mean(dim = 'layer')\n",
    "            longitude = match_ds.sel(time = time).longitude.mean(dim = 'layer')\n",
    "\n",
    "            # Get sum of CAMS data of each layer to get column data\n",
    "            if 'column_kernel' in list(sensor_ds.keys()) and kernels_method != None:\n",
    "                model_final_ds_time = match_ds.sel(time = time).model_column.sum(dim = 'layer', skipna = False).astype(float)\n",
    "\n",
    "            else:\n",
    "                model_final_ds_time = match_ds.sel(time = time).model_column.mean(dim = 'layer', skipna = False).astype(float)\n",
    "\n",
    "            model_final_ds_time = model_final_ds_time.assign_coords(latitude = latitude, longitude = longitude)\n",
    "\n",
    "            # Get mean of TROPOMI data of each layer (it must be equal)\n",
    "            sensor_final_ds_time = match_ds[sensor_column].sel(time = time).mean(dim = 'layer', skipna = False).astype(float)\n",
    "            sensor_final_ds_time = sensor_final_ds_time.assign_coords(latitude = latitude, longitude = longitude)\n",
    "\n",
    "            merged_ds_time = xr.merge([model_final_ds_time, sensor_final_ds_time])\n",
    "            merged_ds_time['difference'] = merged_ds_time[sensor_column] - merged_ds_time['model_column']\n",
    "            merge_table.append(merged_ds_time.to_dataframe())\n",
    "\n",
    "        merge_table = pd.concat(merge_table)\n",
    "\n",
    "    else:\n",
    "\n",
    "        merge_table = match_table\n",
    "        merge_table['difference'] = merge_table[sensor_column] - merge_table['model_column']\n",
    "\n",
    "    # Organize dataset for visualization\n",
    "    if sensor == 'tropomi':\n",
    "        merge_table = merge_table.groupby(by = ['scanline', 'ground_pixel', 'time']).mean()\n",
    "\n",
    "    elif sensor == 'iasi' or sensor == 'gome':\n",
    "        merge_table = merge_table.groupby(by = ['latitude', 'longitude', 'time']).mean()\n",
    "    \n",
    "    return merge_table"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def plot_period(sensor_ds, sensor):\n",
    "\n",
    "    \"\"\" Define plot period\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): sensor dataset in xarray format (TROPOMI, IASI or GOME-2)\n",
    "\n",
    "        Returns:\n",
    "            plot_dates (arr): Plot dates\n",
    "    \"\"\"\n",
    "\n",
    "    period_answer = input('Do you want to visualize the plots for specific dates? Press Enter for Yes or write No:')\n",
    "    plot_dates = []\n",
    "\n",
    "    if period_answer == 'No' or period_answer == 'no':\n",
    "        plot_dates = sensor_ds.time.values\n",
    "    \n",
    "    else:\n",
    "        if sensor == 'tropomi':\n",
    "            options_df = pd.DataFrame({'Date': sensor_ds.time.values})\n",
    "        \n",
    "        elif sensor == 'iasi' or sensor == 'gome':\n",
    "            options_df = pd.DataFrame({'Date': sensor_ds.time.values.astype('datetime64[M]')})\n",
    "\n",
    "        for index, row in options_df.iterrows():\n",
    "            date_answer = input('Do you want to show the plots for ' + str(row['Date']) + '? Press Enter for Yes or write No:') \n",
    "            if date_answer == 'No' or date_answer == 'no':\n",
    "                pass\n",
    "            else:\n",
    "                plot_dates = np.append(plot_dates, row['Date'])\n",
    "\n",
    "    print('The plots will be shown for the following dates:')\n",
    "    if sensor == 'tropomi':\n",
    "        print(plot_dates)\n",
    "    \n",
    "    elif sensor == 'iasi' or sensor == 'gome':\n",
    "        print(plot_dates.astype('datetime64[M]'))\n",
    "\n",
    "    return plot_dates"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def plot_extent(bbox):\n",
    "\n",
    "    \"\"\" Define plot extent\n",
    "\n",
    "        Args:\n",
    "            bbox (arr): Query bounding box\n",
    "\n",
    "        Returns:\n",
    "            plot_bbox (arr): Plot bounding box\n",
    "    \"\"\"\n",
    "\n",
    "    extent_answer = input(f'Do you want to visualize the plots for a specific extent? Press Enter for Yes or write No (default {bbox}):')\n",
    "\n",
    "    if extent_answer == 'No' or extent_answer == 'no':\n",
    "        plot_bbox = ((bbox[0][0], bbox[0][1]), (bbox[1][0], bbox[1][1]))\n",
    "\n",
    "    else:\n",
    "        # Define minimum longitude\n",
    "        plot_lon_min = float(input('Write value of minimum longitude: '))\n",
    "        while (plot_lon_min < bbox[0][0]) or (plot_lon_min > bbox[1][0]):\n",
    "            print(f'ERROR: Longitude must be between {bbox[0][0]} and {bbox[1][0]}.')\n",
    "            plot_lon_min = float(input('Write value of minimum longitude (again): '))\n",
    "\n",
    "        # Define maximum longitude\n",
    "        plot_lon_max = float(input('Write value of maximum longitude: '))\n",
    "        while (plot_lon_max < bbox[0][0]) or (plot_lon_max > bbox[1][0]) or (plot_lon_max <= plot_lon_min):\n",
    "            print(f'ERROR: Longitude must be between {bbox[0][0]} and {bbox[1][0]} and be higher than the minimum {plot_lon_min}.')\n",
    "            plot_lon_max = float(input('Write value of maximum longitude (again): '))\n",
    "\n",
    "        # Define minimum latitude\n",
    "        plot_lat_min = float(input('Write value of minimum latitude: '))\n",
    "        while (plot_lat_min < bbox[0][1]) or (plot_lat_min > bbox[1][1]):\n",
    "            print(f'ERROR: Latitude must be between {bbox[0][1]} and {bbox[1][1]}.')\n",
    "            plot_lat_min = float(input('Write value of minimum latitude (again): '))\n",
    "\n",
    "        # Define maximum latitude\n",
    "        plot_lat_max = float(input('Write value of maximum latitude: '))\n",
    "        while (plot_lat_max < bbox[0][1]) or (plot_lat_max > bbox[1][1]) or (plot_lat_max <= plot_lat_min):\n",
    "            print(f'ERROR: Latitude must be between {bbox[0][1]} and {bbox[1][1]} and be higher than the minimum {plot_lat_min}.')\n",
    "            plot_lat_max = float(input('Write value of maximum latitude (again): '))\n",
    "\n",
    "        # Define plot bbox\n",
    "        plot_bbox = ((plot_lon_min, plot_lat_min), (plot_lon_max, plot_lat_max))\n",
    "\n",
    "    print('The plots will be shown for the following spatial extent: ')\n",
    "    print(plot_bbox)\n",
    "    \n",
    "    return plot_bbox"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def colorbar_range(range_type, merge, array, *args):\n",
    "\n",
    "    \"\"\" Define colorbar range\n",
    "\n",
    "        Args:\n",
    "            range_type (str): Range type for colorbar:\n",
    "            -  'Original': Show original values in range\n",
    "            -  'Positive': Show only positive values in range\n",
    "            -  'Equal': Show same scale in range\n",
    "            merge (xarray): Merge result for a specific time\n",
    "            array (xarray): Component for a specific time and model/sensor\n",
    "            *args: Include 'sensor_column' if range type is Equal\n",
    "\n",
    "        Returns:\n",
    "            vmin, vmax (float): Limits of color bar\n",
    "    \"\"\"\n",
    "\n",
    "    # The colorbar will show the original range\n",
    "    if range_type == 'Original':\n",
    "\n",
    "        vmin = np.nanmin(array)\n",
    "        vmax = np.nanmax(array)\n",
    "\n",
    "    # The colorbar will show the original range only with positive values\n",
    "    elif range_type == 'Positive':\n",
    "        \n",
    "        if np.nanmin(array) < 0:\n",
    "            vmin = 0\n",
    "        else:\n",
    "            vmin = np.nanmin(array)\n",
    "\n",
    "        vmax = np.nanmax(array)\n",
    "\n",
    "    # The colorbar will be in the same scale for both datasets\n",
    "    elif range_type == 'Equal':\n",
    "        \n",
    "        # Define arrays\n",
    "        array_1 = merge.model_column\n",
    "\n",
    "        if sensor_column in args:\n",
    "            array_2 = merge[sensor_column]\n",
    "\n",
    "        elif model_total_ds in args:\n",
    "            array_2 = model_total_ds.component.isel(step = step).sel(time = time)\n",
    "\n",
    "        # Define vmin\n",
    "        if np.nanmin(array_2) < np.nanmin(array_1):\n",
    "            vmin = np.nanmin(array_2)\n",
    "        else:\n",
    "            vmin = np.nanmin(array_1)\n",
    "\n",
    "        # Define vmax\n",
    "        if np.nanmax(array_2) < np.nanmax(array_1):\n",
    "            vmax = np.nanmax(array_1)\n",
    "        else:\n",
    "            vmax = np.nanmax(array_2)\n",
    "            \n",
    "    return vmin, vmax"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def visualize_pcolormesh(fig, axs, data_array, longitude, latitude, projection, color_scale, \n",
    "                         pad, long_name, units_name, vmin, vmax, set_global = True, lonmin = -180, \n",
    "                         lonmax = 180, latmin = -90, latmax = 90):\n",
    "    \n",
    "    \"\"\" Visualize two datasets side by side\n",
    "\n",
    "        Args:\n",
    "            fig: Figure\n",
    "            axs: Axes of figure\n",
    "            data_array (xarray): Variable values to plot - It must be 2-dimensional\n",
    "            longitude (arr): Longitudes within data_array\n",
    "            latitude (arr): Latitudes within data_array\n",
    "            projection: Geographical projection\n",
    "            color_scale (str): Color scale for the color bar\n",
    "            pad (float): Padding for the subtitles\n",
    "            long_name (str): Plot name\n",
    "            units_name (str): Component name and units\n",
    "            vmin, vmax (float): Limits of color bar\n",
    "            set_global: Extent setting\n",
    "            lonmin, lonmax, latmin, latmax (float): Limits of longitude and latitude values\n",
    "    \"\"\"\n",
    "\n",
    "    palette = copy(plt.get_cmap(color_scale))\n",
    "    palette.set_under(alpha = 0)\n",
    "    \n",
    "    im = axs.pcolormesh(\n",
    "                        longitude, latitude, data_array, \n",
    "                        cmap = palette, \n",
    "                        transform = projection,\n",
    "                        vmin = vmin,\n",
    "                        vmax = vmax,\n",
    "                        norm = colors.Normalize(vmin = 0, vmax = vmax),\n",
    "                        shading = 'auto'\n",
    "                        )\n",
    "                        \n",
    "    axs.add_feature(cfeature.BORDERS, edgecolor = 'black', linewidth = 1)\n",
    "    axs.add_feature(cfeature.COASTLINE, edgecolor = 'black', linewidth = 1)\n",
    "\n",
    "    if (projection == ccrs.PlateCarree()):\n",
    "        axs.set_extent([lonmin, lonmax, latmin, latmax], projection)\n",
    "        gl = axs.gridlines(draw_labels = True, linestyle = '--')\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.xformatter = LONGITUDE_FORMATTER\n",
    "        gl.yformatter = LATITUDE_FORMATTER\n",
    "        gl.xlabel_style = {'size': 16}\n",
    "        gl.ylabel_style = {'size': 16}\n",
    "\n",
    "    if (set_global):\n",
    "        axs.set_global()\n",
    "        axs.gridlines()\n",
    "\n",
    "    axs.set_title(long_name, fontsize = 18, pad = pad)\n",
    "    axs.tick_params(labelsize = 14)\n",
    "\n",
    "    cbr = fig.colorbar(im, ax = axs, extend = 'both', orientation = 'horizontal', fraction = 0.05, pad = 0.15)   \n",
    "    cbr.set_label(units_name, fontsize = 16)\n",
    "    cbr.ax.tick_params(labelsize = 14)\n",
    "    cbr.ax.xaxis.get_offset_text().set_fontsize(14)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def create_maps(merge, range_type, sensor, model, sensor_type, model_type, sensor_column, \n",
    "                projection, pad, units_name, plot_bbox):\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize = (20, 4), subplot_kw = {'projection': projection})\n",
    "    \n",
    "    # First plot - CAMS \n",
    "    array = merge.model_column\n",
    "    vmin, vmax = colorbar_range(range_type, merge, array, sensor_column)\n",
    "    long_name = model.upper() + ' (' + model_type + ')'\n",
    "    visualize_pcolormesh(\n",
    "                        fig = fig, axs = axs[0],\n",
    "                        data_array = array.fillna(-999),\n",
    "                        longitude = array.longitude,\n",
    "                        latitude = array.latitude,\n",
    "                        projection = projection,\n",
    "                        color_scale = 'coolwarm',\n",
    "                        pad = pad,\n",
    "                        long_name = long_name,\n",
    "                        units_name = units_name,\n",
    "                        vmin = vmin, \n",
    "                        vmax = vmax, \n",
    "                        set_global = False,\n",
    "                        lonmin = plot_bbox[0][0],\n",
    "                        lonmax = plot_bbox[1][0],\n",
    "                        latmin = plot_bbox[0][1],\n",
    "                        latmax = plot_bbox[1][1]\n",
    "                        )\n",
    "\n",
    "\n",
    "    # Second plot - TROPOMI, IASI or GOME-2\n",
    "    array = merge[sensor_column]\n",
    "    vmin, vmax = colorbar_range(range_type, merge, array, sensor_column)\n",
    "    long_name = sensor.upper() + ' (' + sensor_type + ')'\n",
    "    visualize_pcolormesh(\n",
    "                        fig = fig, axs = axs[1],\n",
    "                        data_array = array.fillna(-999),\n",
    "                        longitude = array.longitude,\n",
    "                        latitude = array.latitude,\n",
    "                        projection = projection,\n",
    "                        color_scale = 'coolwarm',\n",
    "                        pad = pad,\n",
    "                        long_name = long_name,\n",
    "                        units_name = units_name,\n",
    "                        vmin = vmin,  \n",
    "                        vmax = vmax, \n",
    "                        set_global = False,\n",
    "                        lonmin = plot_bbox[0][0],\n",
    "                        lonmax = plot_bbox[1][0],\n",
    "                        latmin = plot_bbox[0][1],\n",
    "                        latmax = plot_bbox[1][1]\n",
    "                        )\n",
    "\n",
    "    # Third plot - Differences\n",
    "    array = merge.difference\n",
    "    long_name = 'Differences plot'\n",
    "    visualize_pcolormesh(\n",
    "                        fig = fig, axs = axs[2],\n",
    "                        data_array = array.fillna(-999),\n",
    "                        longitude = array.longitude,\n",
    "                        latitude = array.latitude,\n",
    "                        projection = projection,\n",
    "                        color_scale = 'coolwarm',\n",
    "                        pad = pad,\n",
    "                        long_name = long_name,\n",
    "                        units_name = units_name,\n",
    "                        vmin = np.nanmin(array),  \n",
    "                        vmax = np.nanmax(array), \n",
    "                        set_global = False,\n",
    "                        lonmin = plot_bbox[0][0],\n",
    "                        lonmax = plot_bbox[1][0],\n",
    "                        latmin = plot_bbox[0][1],\n",
    "                        latmax = plot_bbox[1][1]\n",
    "                        )\n",
    "    \n",
    "    return fig"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def visualize_model_vs_sensor(model, sensor, component_nom, units, merge_table, plot_dates, plot_bbox, pad, y, \n",
    "                              model_type, sensor_type, range_type, sensor_column, distribution_type):\n",
    "\n",
    "    \"\"\" Plot model and sensor datasets in the study area for the selected dates, \n",
    "        along with a plot of the differences\n",
    "\n",
    "        Args:\n",
    "            model (str): Name of the model\n",
    "            sensor (str): Name of the sensor\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            units (str): Component units\n",
    "            merge_table (dataframe): Merge table with datasets column data and their difference\n",
    "            plot_dates (arr): Plot dates\n",
    "            plot_bbox (arr): Plot extent\n",
    "            pad (float): Padding for the subtitles\n",
    "            y (float): y-position of main title\n",
    "            model_type (str): Model type:\n",
    "            -  'Forecast'\n",
    "            -  'Reanalysis'\n",
    "            sensor_type (str): Sensor type ('NRT')\n",
    "            range_type (str): Range type for colorbar:\n",
    "            -  'Original': Show original values in range\n",
    "            -  'Positive': Show only positive values in range\n",
    "            -  'Equal': Show same scale in range\n",
    "    \"\"\"\n",
    "    \n",
    "    units_name = component_nom + ' (' + units + ')'\n",
    "    projection = ccrs.PlateCarree()\n",
    "\n",
    "    if distribution_type == 'aggregated':\n",
    "\n",
    "        merge = merge_table.to_xarray().mean(dim = 'time')\n",
    "        latitude = merge.latitude\n",
    "        longitude = merge.longitude\n",
    "        merge = merge.assign_coords(latitude = latitude, longitude = longitude)\n",
    "\n",
    "        fig = create_maps(merge, range_type, sensor, model, sensor_type, model_type, sensor_column, \n",
    "                          projection, pad, units_name, plot_bbox)\n",
    "\n",
    "        fig.suptitle(f'DISTRIBUTION OF {component_nom} (All times)',\n",
    "                     fontsize = 18, fontweight = 'bold', y = y)\n",
    "\n",
    "    if distribution_type == 'individual':\n",
    "\n",
    "        for time in plot_dates:\n",
    "\n",
    "            merge = merge_table.query('time == @time').to_xarray()\n",
    "            latitude = merge.sel(time = time).latitude\n",
    "            longitude = merge.sel(time = time).longitude\n",
    "            merge = merge.sel(time= time).assign_coords(latitude = latitude, longitude = longitude)\n",
    "\n",
    "            fig = create_maps(merge, range_type, sensor, model, sensor_type, model_type, sensor_column, \n",
    "                              projection, pad, units_name, plot_bbox)\n",
    "\n",
    "            if sensor == 'tropomi':\n",
    "                fig.suptitle(f'DISTRIBUTION OF {component_nom} (Est. time: {time})',\n",
    "                             fontsize = 18, fontweight = 'bold', y = y)\n",
    "            \n",
    "            elif sensor == 'iasi' or sensor == 'gome':\n",
    "                month = np.datetime64(time).astype('datetime64[M]')\n",
    "                fig.suptitle(f'DISTRIBUTION OF {component_nom} (Month: {month})',\n",
    "                             fontsize = 18, fontweight = 'bold', y = y)\n",
    "\n",
    "            plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def visualize_model_original_vs_calculated(model, component_nom, units, merge_table, model_total_ds, \n",
    "                                           plot_dates, plot_bbox, pad, y, model_type, range_type):\n",
    "\n",
    "    \"\"\" Plot model total columns from the original dataset and the calculated one \n",
    "        in the study area for the selected dates\n",
    "\n",
    "        Args:\n",
    "            model (str): Name of the model\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            units (str): Component units\n",
    "            merge_table (dataframe): Merge result\n",
    "            model_total_ds (xarray): CAMS total columns dataset in xarray format\n",
    "            plot_dates (arr): Plot dates\n",
    "            plot_bbox (arr): Plot extent\n",
    "            pad (float): Padding for the subtitles\n",
    "            y (float): y-position of main title\n",
    "            model_type (str): Model type:\n",
    "            -  'Forecast'\n",
    "            -  'Reanalysis'\n",
    "            range_type (str): Range type for colorbar:\n",
    "            -  'Original': Show original values in range\n",
    "            -  'Positive': Show only positive values in range\n",
    "            -  'Equal': Show same scale in range\n",
    "    \"\"\"\n",
    "\n",
    "    units_name = component_nom + ' (' + units + ')'\n",
    "    projection = ccrs.PlateCarree()\n",
    "\n",
    "    for time in plot_dates:\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize = (20, 5), subplot_kw = {'projection': projection})\n",
    "\n",
    "        merge = merge_table.query('time == @time').to_xarray()\n",
    "        latitude = merge.sel(time = time).latitude\n",
    "        longitude = merge.sel(time = time).longitude\n",
    "        merge = merge.sel(time= time).assign_coords(latitude = latitude, longitude = longitude)\n",
    "\n",
    "        step = 2\n",
    "\n",
    "        # First plot - CAMS calculated total columns\n",
    "        array = merge.model_column\n",
    "        vmin, vmax = colorbar_range(range_type, merge, array, model_total_ds, step, time)\n",
    "        long_name = 'CALCULATED TOTAL COLUMNS ' + model.upper() + ' (' + model_type + ')'\n",
    "        visualize_pcolormesh(\n",
    "                            fig = fig, axs = axs[0],\n",
    "                            data_array = array.fillna(-999),\n",
    "                            longitude = array.longitude,\n",
    "                            latitude = array.latitude,\n",
    "                            projection = projection,\n",
    "                            color_scale = 'coolwarm',\n",
    "                            pad = pad,\n",
    "                            long_name = long_name,\n",
    "                            units_name = units_name,\n",
    "                            vmin = vmin, \n",
    "                            vmax = vmax, \n",
    "                            set_global = False,\n",
    "                            lonmin = plot_bbox[0][0],\n",
    "                            lonmax = plot_bbox[1][0],\n",
    "                            latmin = plot_bbox[0][1],\n",
    "                            latmax = plot_bbox[1][1]\n",
    "                            )\n",
    "\n",
    "        # Second plot - CAMS original total columns\n",
    "        array = model_total_ds.component.isel(step = step).sel(time = time)\n",
    "        vmin, vmax = colorbar_range(range_type, merge, array, model_total_ds, step, time)\n",
    "        long_name = 'ORIGINAL TOTAL COLUMNS ' + model.upper() + ' (' + model_type + ')'\n",
    "        visualize_pcolormesh(\n",
    "                            fig = fig, axs = axs[1],\n",
    "                            data_array = array.fillna(-999),\n",
    "                            longitude = array.longitude,\n",
    "                            latitude = array.latitude,\n",
    "                            projection = projection,\n",
    "                            color_scale = 'coolwarm',\n",
    "                            pad = pad,\n",
    "                            long_name = long_name,\n",
    "                            units_name = units_name,\n",
    "                            vmin = vmin,\n",
    "                            vmax = vmax, \n",
    "                            set_global = False,\n",
    "                            lonmin = plot_bbox[0][0],\n",
    "                            lonmax = plot_bbox[1][0],\n",
    "                            latmin = plot_bbox[0][1],\n",
    "                            latmax = plot_bbox[1][1]\n",
    "                            )\n",
    "\n",
    "        fig.suptitle(f'DISTRIBUTION OF {component_nom} (Est. time: {time})',\n",
    "                    fontsize = 18, fontweight = 'bold', y = y)\n",
    "        plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def get_google_api():\n",
    "\n",
    "    \"\"\" Get Google API key for reverse geocoding (get country given the coordinates)\n",
    "        \n",
    "        Returns:\n",
    "            environ_keys[0]: Google API key\n",
    "    \"\"\"\n",
    "\n",
    "    # Open txt file with three lines:\n",
    "    # GOOGLE API KEY (first line), GOOGLE CLIENT ID (second line) and GOOGLE CLIENT SECRET (third line)\n",
    "    keys_file = open('data/keys.txt', 'r')\n",
    "    keys = keys_file.readlines()\n",
    "    environ_keys = [key.rstrip() for key in keys]\n",
    "\n",
    "    # Set environment variables in your system\n",
    "    os.environ['GOOGLE_API_KEY'] = environ_keys[0]\n",
    "    os.environ['GOOGLE_CLIENT'] = environ_keys[1]\n",
    "    os.environ['GOOGLE_CLIENT_SECRET'] = environ_keys[2]\n",
    "\n",
    "    return environ_keys[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def get_season(day):\n",
    "\n",
    "    \"\"\" Get season given the day\n",
    "\n",
    "        Args:\n",
    "            day (datetime): Date\n",
    "        \n",
    "        Returns:\n",
    "            season (str): Season of the year\n",
    "    \"\"\"\n",
    "\n",
    "    Y = 2000\n",
    "\n",
    "    seasons = [('Winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "               ('Spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "               ('Summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "               ('Autumn', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "               ('Winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "            \n",
    "    day = day.replace(year = Y)\n",
    "\n",
    "    season = next(season for season, (start, end) in seasons\n",
    "             if start <= day <= end)\n",
    "             \n",
    "    return season"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def linear_regression(X, Y, component_nom):\n",
    "\n",
    "    \"\"\" Fit a linear equation to scatter plot between X and Y and print results\n",
    "\n",
    "        Args:\n",
    "            X (array): Input sensor component values\n",
    "            Y (array): Input model component values\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "        \n",
    "        Returns:\n",
    "            fit_X (array): X in linear equation fit_Y = A * fit_X + B\n",
    "            fit_Y (array): Y in linear equation fit_Y = A * fit_X + B\n",
    "            score (float): Coefficient of determination\n",
    "            coefficient (float): A in linear equation fit_Y = A * fit_X + B\n",
    "            intercept (float): B in linear equation fit_Y = A * fit_X + B\n",
    "    \"\"\"\n",
    "\n",
    "    score = 'Unknown'\n",
    "    coefficient = 'Unknown'\n",
    "    intercept = 'Unknown'\n",
    "\n",
    "    reg = LinearRegression().fit(X, Y)\n",
    "    fit_X = np.linspace(np.nanmin(X), np.nanmax(X), 10)\n",
    "    fit_Y = fit_X * float(reg.coef_) + reg.intercept_\n",
    "    \n",
    "    score = reg.score(X, Y)\n",
    "    coefficient = reg.coef_[0][0]\n",
    "    intercept = reg.intercept_[0]\n",
    "\n",
    "    print(f'Fit equation: {component_nom}_model = {component_nom}_sensor * {float(reg.coef_):.2f} + ({float(reg.intercept_):.2E})')\n",
    "    print(f'Coefficient of determination (R2): {reg.score(X, Y):.2f}')\n",
    "\n",
    "    return fit_X, fit_Y, score, coefficient, intercept"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def scatter_plot_general_settings(component_nom, axs, units, lim_min, lim_max):\n",
    "\n",
    "    \"\"\" Set common settings for scatter plots\n",
    "\n",
    "        Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            plt (plot): Scatterplot\n",
    "            units (str): Component units\n",
    "            lim_min (float): Minimum value of component in scale\n",
    "            lim_max (float): Maximum value of component in scale\n",
    "    \"\"\"\n",
    "\n",
    "    # Scatter plot\n",
    "    axs[0].set_xlabel(f'Sensor {component_nom} ({units})', fontsize = 16)\n",
    "    axs[0].set_ylabel(f'Model {component_nom} ({units})', fontsize = 16)\n",
    "    axs[0].tick_params(labelsize = 14)\n",
    "    axs[0].set_xlim([lim_min, lim_max])\n",
    "    axs[0].set_ylim([lim_min, lim_max])\n",
    "\n",
    "    # Histograms\n",
    "    axs[1].set_xlabel(f'Sensor {component_nom} ({units})', fontsize = 16)\n",
    "    axs[2].set_xlabel(f'Model {component_nom} ({units})', fontsize = 16)\n",
    "    for i in range(1, 3):\n",
    "        axs[i].set_ylabel(f'Count', fontsize = 16)\n",
    "        axs[i].tick_params(labelsize = 14)\n",
    "        axs[i].set_xlim([lim_min, lim_max])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def scatter_plot(merge_table, component_nom, units, sensor_column, sensor, plot_dates, y, extent_definition, show_seasons, scatter_plot_type, *args):\n",
    "\n",
    "    \"\"\" Scatter plot between the model and sensor datasets in the study area for the selected dates (bbox or countries)\n",
    "\n",
    "        Args:\n",
    "            merge_table (dataframe): Merge result\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            units (str): Component units\n",
    "            sensor_column (str): Component column name in TROPOMI, IASI or GOME-2 database\n",
    "            sensor (str): Name of the sensor\n",
    "            plot_dates (arr): Plot dates\n",
    "            plot_bbox (arr): Plot extent\n",
    "            y (float): y-position of main title\n",
    "            extent_definition (str):\n",
    "            * 'country': Scatter plots for countries list\n",
    "            * 'bbox': Scatter plots for bbox coordinates\n",
    "            scatter_plot_type (str):\n",
    "            * 'aggregated': Aggregate plots by time, country or season\n",
    "            * 'individual': Individual plots per time, country or season\n",
    "            *args: Include 'plot_countries' or 'plot_bbox'\n",
    "    \"\"\"\n",
    "\n",
    "    sns.color_palette('colorblind', 10)\n",
    "\n",
    "    lim_min = min(np.nanmin(merge_table[sensor_column]), np.nanmin(merge_table['model_column']))\n",
    "    lim_max = max(np.nanmax(merge_table[sensor_column]), np.nanmax(merge_table['model_column']))\n",
    "\n",
    "    summary = []\n",
    "\n",
    "    merge = merge_table\n",
    "\n",
    "    if show_seasons == False:\n",
    "\n",
    "        if extent_definition == 'bbox':\n",
    "\n",
    "            if scatter_plot_type == 'aggregated':\n",
    "\n",
    "                # Prepare df\n",
    "                merge = merge.reset_index()\n",
    "                merge = merge[merge['time'].isin(plot_dates)]\n",
    "\n",
    "                if not merge.empty:\n",
    "                    \n",
    "                    fig, axs = plt.subplots(1, 3, figsize = (20, 5))\n",
    "\n",
    "                    # Linear regression\n",
    "                    X = merge[sensor_column].values.reshape(-1, 1) \n",
    "                    Y = merge['model_column'].values.reshape(-1, 1) \n",
    "                    fit_X, fit_Y, score, coefficient, intercept = linear_regression(X, Y, component_nom)\n",
    "                    axs[0].plot(fit_X, fit_Y, color = 'black')\n",
    "                    \n",
    "                    # Scatter plot and histograms\n",
    "                    sns.scatterplot(data = merge, x = sensor_column, y = 'model_column', hue = 'time', ax = axs[0])\n",
    "                    sns.histplot(data = merge, x = sensor_column, kde = True,  ax = axs[1])\n",
    "                    sns.histplot(data = merge, x = 'model_column', kde = True,  ax = axs[2])\n",
    "\n",
    "                    scatter_plot_general_settings(component_nom, axs, units, lim_min, lim_max)\n",
    "                    fig.suptitle(f'{component_nom} (All times)', fontsize = 18, fontweight = 'bold', y = y)\n",
    "\n",
    "                    # Update summary\n",
    "                    summary.append({'Period': plot_dates, 'Location': plot_bbox, \n",
    "                                    'Score': score, 'Coefficient': coefficient, \n",
    "                                    'Intercept': intercept})\n",
    "\n",
    "            elif scatter_plot_type == 'individual':\n",
    "                \n",
    "                for time in plot_dates:\n",
    "                    \n",
    "                    # Prepare df\n",
    "                    merge_time = merge.query('time == @time and longitude >= @plot_bbox[0][0] and longitude <= @plot_bbox[1][0] and latitude >= @plot_bbox[0][1] and latitude <= @plot_bbox[1][1]')\n",
    "                    \n",
    "                    if not merge_time.empty:\n",
    "                        \n",
    "                        fig, axs = plt.subplots(1, 3, figsize = (20, 5))\n",
    "\n",
    "                        # Scatter plot and histograms\n",
    "                        sns.scatterplot(data = merge_time, x = sensor_column, y = 'model_column', ax = axs[0])\n",
    "                        sns.histplot(data = merge_time, x = sensor_column, kde = True,  ax = axs[1])\n",
    "                        sns.histplot(data = merge_time, x = 'model_column', kde = True,  ax = axs[2])\n",
    "\n",
    "                        scatter_plot_general_settings(component_nom, axs, units, lim_min, lim_max)\n",
    "                        \n",
    "                        if sensor == 'tropomi':\n",
    "                            fig.suptitle(f'{component_nom} (Est. time: {time})', fontsize = 18, fontweight = 'bold', y = y)\n",
    "                            \n",
    "                        elif sensor == 'iasi' or sensor == 'gome':\n",
    "                            month = np.datetime64(time).astype('datetime64[M]')\n",
    "                            fig.suptitle(f'{component_nom} (Month: {month})', fontsize = 18, fontweight = 'bold', y = y)\n",
    "\n",
    "                        # Linear regression\n",
    "                        X = merge_time[sensor_column].values.reshape(-1, 1) \n",
    "                        Y = merge_time['model_column'].values.reshape(-1, 1) \n",
    "                        fit_X, fit_Y, score, coefficient, intercept = linear_regression(X, Y, component_nom)\n",
    "                        axs[0].plot(fit_X, fit_Y, color = 'black')\n",
    "                        plt.show()\n",
    "\n",
    "                        # Update summary\n",
    "                        summary.append({'Period': time, 'Location': plot_bbox, \n",
    "                                        'Score': score, 'Coefficient': coefficient, \n",
    "                                        'Intercept': intercept})\n",
    "\n",
    "        elif extent_definition == 'country':\n",
    "            \n",
    "            # Prepare df\n",
    "            merge = merge.reset_index()\n",
    "            merge = merge[merge['time'].isin(plot_dates)]\n",
    "\n",
    "            # Read Google API key for reverse geocoding (get country by coordinates)\n",
    "            google_api_key = get_google_api()\n",
    "\n",
    "            # Reverse geocoding\n",
    "            merge['Country'] = merge.apply(lambda row: geocoder.google([row['latitude'], row['longitude']], \n",
    "                                            method='reverse', key = google_api_key).country_long, axis = 1)\n",
    "\n",
    "            # Find data for the countries in search list\n",
    "            merge = merge[merge['Country'].isin(plot_countries)]\n",
    "            available_countries = np.unique(merge['Country'])\n",
    "\n",
    "            if scatter_plot_type == 'aggregated':\n",
    "\n",
    "                if not merge.empty:\n",
    "                    \n",
    "                    fig, axs = plt.subplots(1, 3, figsize = (20, 5))\n",
    "\n",
    "                    # Linear regression\n",
    "                    X = merge[sensor_column].values.reshape(-1, 1) \n",
    "                    Y = merge['model_column'].values.reshape(-1, 1) \n",
    "                    fit_X, fit_Y, score, coefficient, intercept = linear_regression(X, Y, component_nom)\n",
    "                    axs[0].plot(fit_X, fit_Y, color = 'black')\n",
    "\n",
    "                    # Scatter plot and histograms\n",
    "                    sns.scatterplot(data = merge, x = sensor_column, y = 'model_column', hue = 'Country', ax = axs[0])\n",
    "                    sns.histplot(data = merge, x = sensor_column, kde = True,  ax = axs[1])\n",
    "                    sns.histplot(data = merge, x = 'model_column', kde = True,  ax = axs[2])\n",
    "\n",
    "                    scatter_plot_general_settings(component_nom, axs, units, lim_min, lim_max)\n",
    "                    fig.suptitle(f'{component_nom} (All countries)', fontsize = 18, fontweight = 'bold', y = y)\n",
    "\n",
    "                    # Update summary\n",
    "                    summary.append({'Period': plot_dates, 'Location': available_countries, \n",
    "                                    'Score': score, 'Coefficient': coefficient, \n",
    "                                    'Intercept': intercept})\n",
    "\n",
    "            elif scatter_plot_type == 'individual':\n",
    "\n",
    "                for plot_country in plot_countries:\n",
    "\n",
    "                    merge_country = merge[merge['Country'] == plot_country]\n",
    "\n",
    "                    if not merge_country.empty:\n",
    "                        \n",
    "                        fig, axs = plt.subplots(1, 3, figsize = (20, 5))\n",
    "\n",
    "                        # Linear regression\n",
    "                        X = merge_country[sensor_column].values.reshape(-1, 1) \n",
    "                        Y = merge_country['model_column'].values.reshape(-1, 1) \n",
    "                        fit_X, fit_Y, score, coefficient, intercept = linear_regression(X, Y, component_nom)\n",
    "                        axs[0].plot(fit_X, fit_Y, color = 'black')\n",
    "\n",
    "                        # Update summary\n",
    "                        summary.append({'Period': plot_dates, 'Location': plot_country, \n",
    "                                        'Score': score, 'Coefficient': coefficient, \n",
    "                                        'Intercept': intercept})\n",
    "\n",
    "                        # Scatter plot and histograms\n",
    "                        sns.scatterplot(data = merge_country, x = sensor_column, y = 'model_column', ax = axs[0])\n",
    "                        sns.histplot(data = merge_country, x = sensor_column, kde = True,  ax = axs[1])\n",
    "                        sns.histplot(data = merge_country, x = 'model_column', kde = True,  ax = axs[2])\n",
    "\n",
    "                        scatter_plot_general_settings(component_nom, axs, units, lim_min, lim_max)\n",
    "                        fig.suptitle(f'{component_nom} ({plot_country})', fontsize = 18, fontweight = 'bold', y = y)\n",
    "                        plt.show()\n",
    "\n",
    "            else:\n",
    "                print('ERROR: scatter_plot_type is wrongly defined. The options are ''aggregated'' and ''individual''.')\n",
    "                raise KeyboardInterrupt()\n",
    "\n",
    "        else:\n",
    "            print('ERROR: extent_definition is wrongly defined. The options are ''bbox'' and ''country''.')\n",
    "            raise KeyboardInterrupt()\n",
    "                \n",
    "    elif show_seasons == True:\n",
    "        \n",
    "        if show_seasons == True and extent_definition == 'country':\n",
    "            print('ERROR: Set up show_seasons to False in order to show the scatter plots by countries.')\n",
    "            raise KeyboardInterrupt()\n",
    "\n",
    "        plot_seasons = ['Winter', 'Spring', 'Summer', 'Autumn']\n",
    "\n",
    "        # Prepare df\n",
    "        merge = merge.reset_index()\n",
    "        merge = merge[merge['time'].isin(plot_dates)]\n",
    "\n",
    "        # Find data for the seasons in list\n",
    "        merge['Season'] = merge.apply(lambda row: get_season(row['time']), axis = 1)\n",
    "        available_seasons = np.unique(merge['Season'])\n",
    "\n",
    "        if scatter_plot_type == 'aggregated':\n",
    "\n",
    "            if not merge.empty:\n",
    "                \n",
    "                fig, axs = plt.subplots(1, 3, figsize = (20, 5))\n",
    "\n",
    "                # Linear regression\n",
    "                X = merge[sensor_column].values.reshape(-1, 1) \n",
    "                Y = merge['model_column'].values.reshape(-1, 1) \n",
    "                fit_X, fit_Y, score, coefficient, intercept = linear_regression(X, Y, component_nom)\n",
    "                axs[0].plot(fit_X, fit_Y, color = 'black')\n",
    "\n",
    "                # Scatter plot and histograms\n",
    "                sns.scatterplot(data = merge, x = sensor_column, y = 'model_column', hue = 'Season', ax = axs[0])\n",
    "                sns.histplot(data = merge, x = sensor_column, kde = True, ax = axs[1])\n",
    "                sns.histplot(data = merge, x = 'model_column', kde = True, ax = axs[2])\n",
    "\n",
    "                scatter_plot_general_settings(component_nom, axs, units, lim_min, lim_max)\n",
    "                fig.suptitle(f'{component_nom} (All seasons)', fontsize = 18, fontweight = 'bold', y = y)\n",
    "                plt.show()\n",
    "\n",
    "                # Update summary\n",
    "                summary.append({'Period': available_seasons, 'Location': plot_bbox, \n",
    "                                'Score': score, 'Coefficient': coefficient, \n",
    "                                'Intercept': intercept})\n",
    "\n",
    "        elif scatter_plot_type == 'individual':\n",
    "\n",
    "            for plot_season in plot_seasons:\n",
    "                \n",
    "                # Prepare df\n",
    "                merge_season = merge[merge['Season'] == plot_season]\n",
    "                \n",
    "                if not merge_season.empty:\n",
    "                    \n",
    "                    fig, axs = plt.subplots(1, 3, figsize = (20, 5))\n",
    "\n",
    "                    # Linear regression\n",
    "                    X = merge_season[sensor_column].values.reshape(-1, 1) \n",
    "                    Y = merge_season['model_column'].values.reshape(-1, 1) \n",
    "                    fit_X, fit_Y, score, coefficient, intercept = linear_regression(X, Y, component_nom)\n",
    "                    axs[0].plot(fit_X, fit_Y, color = 'black')\n",
    "\n",
    "                    # Update summary\n",
    "                    summary.append({'Period': plot_season, 'Location':  plot_bbox, \n",
    "                                    'Score': score, 'Coefficient': coefficient, \n",
    "                                    'Intercept': intercept})\n",
    "\n",
    "                    # Scatter plot and histograms\n",
    "                    sns.scatterplot(data = merge_season, x = sensor_column, y = 'model_column', ax = axs[0])\n",
    "                    sns.histplot(data = merge_season, x = sensor_column, kde = True, ax = axs[1])\n",
    "                    sns.histplot(data = merge_season, x = 'model_column', kde = True, ax = axs[2])\n",
    "\n",
    "                    fig.suptitle(f'{component_nom} ({plot_season})', fontsize = 18, fontweight = 'bold', y = y)\n",
    "                    scatter_plot_general_settings(component_nom, axs, units, lim_min, lim_max)\n",
    "                    plt.show()\n",
    "\n",
    "        else:\n",
    "            print('ERROR: scatter_plot_type is wrongly defined. The options are ''aggregated'' and ''individual''.')\n",
    "            raise KeyboardInterrupt()\n",
    "\n",
    "    else:\n",
    "        print('ERROR: show_seasons is wrongly defined. The options are True and False.')\n",
    "        raise KeyboardInterrupt()\n",
    "    \n",
    "    summary = pd.DataFrame(summary)\n",
    "\n",
    "    return summary"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def retrieve_coords(merge_table, coords_search, component_nom, sensor_column, sensor, model, plot_dates, units):\n",
    "\n",
    "    \"\"\" Get component data for the closest coordinates to the list of search coordinates and plot them along time\n",
    "\n",
    "        Args:\n",
    "            merge_table (dataframe): Merge result\n",
    "            coords_search (list): List of search coordinates\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor_column (str): Component column name in TROPOMI, IASI or GOME-2 database\n",
    "            sensor (str): Name of the sensor\n",
    "            model (str): Name of the model\n",
    "            plot_dates (arr): Plot dates\n",
    "            units (str): Component units\n",
    "\n",
    "        Returns:\n",
    "            retrieval_table_all (dataframe): Dataframe with results from search\n",
    "    \"\"\"\n",
    "    \n",
    "    retrieval_table_all = pd.DataFrame()\n",
    "    for i in range(0, len(coords_search)):\n",
    "\n",
    "        for time in plot_dates:\n",
    "\n",
    "            # List of available points per time\n",
    "            retrieval_table = merge_table.query('time == @time').reset_index()\n",
    "            available_points = list([(x, y) for x, y in zip(retrieval_table['latitude'], retrieval_table['longitude'])])\n",
    "            \n",
    "            # Get closest pair to coordinates in search list\n",
    "            lat_found = closest_point(coords_search[i], available_points)[0]\n",
    "            lon_found = closest_point(coords_search[i], available_points)[1]\n",
    "            retrieval_table = merge_table.query('latitude == @lat_found and longitude == @lon_found and time == @time')\n",
    "\n",
    "            retrieval_table = retrieval_table.reset_index()\n",
    "            retrieval_table['lat_search'] = coords_search[i][0]\n",
    "            retrieval_table['lon_search'] = coords_search[i][1]\n",
    "        \n",
    "            # Append retrieval table to previous coordinates\n",
    "            retrieval_table_all = retrieval_table_all.append(retrieval_table)\n",
    "        \n",
    "        table_length = len(retrieval_table_all[(retrieval_table_all['latitude'] == lat_found) & \n",
    "                                            (retrieval_table_all['longitude'] == lon_found) &\n",
    "                                            (retrieval_table_all['lat_search'] == coords_search[i][0]) &\n",
    "                                            (retrieval_table_all['lon_search'] == coords_search[i][1])])\n",
    "\n",
    "        # Plot variations in time\n",
    "        if table_length > 1:\n",
    "        \n",
    "            fig, ax = plt.subplots(figsize = (30, 5))\n",
    "\n",
    "            retrieval_table_time = retrieval_table_all[(retrieval_table_all['latitude'] == lat_found) & \n",
    "                                                       (retrieval_table_all['longitude'] == lon_found)]\n",
    "            plt1 = ax.plot(retrieval_table_time['time'], retrieval_table_time[sensor_column], color = 'red', label = sensor.upper())\n",
    "            plt2 = ax.plot(retrieval_table_time['time'], retrieval_table_time['model_column'], color = 'black', label = model.upper())\n",
    "\n",
    "            ax.legend(loc='center left', bbox_to_anchor = (1, 0.5), prop = {'size': 25})\n",
    "\n",
    "            if sensor == 'tropomi':\n",
    "                ax.set_xlabel('Estimated time', fontsize = 25)\n",
    "                \n",
    "            elif sensor == 'iasi' or sensor == 'gome':\n",
    "                ax.set_xlabel('Month', fontsize = 25)\n",
    "\n",
    "            ax.tick_params(labelsize = 22)\n",
    "            ax.set_ylabel(f'{component_nom} ({units})', fontsize = 25)\n",
    "            ax.set_title(f'{component_nom} at latitude {lat_found} and longitude {lon_found}', \n",
    "                        fontsize = 25, fontweight = 'bold', y = 1.05)\n",
    "        \n",
    "    retrieval_table_all = retrieval_table_all.set_index(['lat_search', \n",
    "                                                        'lon_search', \n",
    "                                                        'latitude', \n",
    "                                                        'longitude', \n",
    "                                                        'time'])\n",
    "\n",
    "    return retrieval_table_all"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('env-new': venv)"
  },
  "interpreter": {
   "hash": "84d6139589c0d952b978fb9437b8e11e4e03996aa73ed56a307e4c0ad5e273d4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}