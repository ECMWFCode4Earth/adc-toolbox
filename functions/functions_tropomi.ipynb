{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TROPOMI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_L3_download(date, component_nom):\n",
    "\n",
    "    \"\"\" Query and download the TROPOMI L3 dataset from Sentinel API\n",
    "\n",
    "         Args:\n",
    "            date (str): Query date\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "   \"\"\"\n",
    "\n",
    "    year = date.split('-')[0]\n",
    "    month = date.split('-')[1]\n",
    "    \n",
    "    TROPOMI_product_path = os.path.join('/', '/'.join(\n",
    "                           os.getcwd().split('/')[1:3]), 'adc-toolbox', \n",
    "                           os.path.relpath('data/tropomi/' + component_nom + '/L3/' + year + '-' + month))\n",
    "    os.makedirs(TROPOMI_product_path, exist_ok = True) \n",
    "    product_name = 'TROPOMI_L3_NO2_COLUMN_' + year + month + '.asc.gz'\n",
    "    file_name = TROPOMI_product_path + '/' + product_name\n",
    "\n",
    "    path = ('https://d1qb6yzwaaq4he.cloudfront.net/tropomi/' + component_nom.lower() + '/' + year +\n",
    "            '/' + month + '/' + component_nom.lower() + '_' + year + month + '.asc.gz')\n",
    "    subprocess.run(['wget', '-q', '-nc', path, '-O', TROPOMI_product_path + '/' + product_name])\n",
    "    \n",
    "    if os.stat(file_name).st_size == 0:  \n",
    "        os.remove(file_name) \n",
    "        print(product_name, 'is not available.')\n",
    "\n",
    "    else:\n",
    "        print(product_name, 'was downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_L3_read(component_nom, dates, lat_res = 0.125, lon_res = 0.125):\n",
    "\n",
    "    \"\"\" Read TROPOMI L3 dataset as xarray dataset object\n",
    "\n",
    "        Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            dates (list): Available dates\n",
    "\n",
    "        Returns:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "   \"\"\"\n",
    "\n",
    "    sensor_ds = []\n",
    "\n",
    "    for date in dates:\n",
    "\n",
    "        year = date.split('-')[0]\n",
    "        month = date.split('-')[1]\n",
    "        time = dt.datetime(int(year), int(month), 1)\n",
    "\n",
    "        TROPOMI_product_path = os.path.join('/', '/'.join(\n",
    "                            os.getcwd().split('/')[1:3]), 'adc-toolbox', \n",
    "                            os.path.relpath('data/tropomi/' + component_nom + '/L3/' + year + '-' + month))\n",
    "        product_name = 'TROPOMI_L3_NO2_COLUMN_' + year + month + '.asc.gz'\n",
    "        \n",
    "        sensor_df_time = []\n",
    "\n",
    "        # Reconstruct file\n",
    "        with gzip.open(TROPOMI_product_path + '/' + product_name, 'rt', encoding='utf-8') as f:\n",
    "            \n",
    "            i = 0    \n",
    "            lon = -179.9375\n",
    "\n",
    "            for line in f:    \n",
    "                \n",
    "                if i > 3:\n",
    "\n",
    "                    if 'lat' in line:\n",
    "                        lat = float(line.replace('lat=  ', ''))\n",
    "                        lon = -179.9375\n",
    "\n",
    "                    else: \n",
    "\n",
    "                        line = line.replace('\\n', '')\n",
    "\n",
    "                        for value in [line[i:i+4] for i in range(0, len(line), 4)]:\n",
    "                            \n",
    "                            if value == '-999':\n",
    "                                value = np.nan\n",
    "                                \n",
    "                            else:\n",
    "                                value = float(value.replace(' ', ''))\n",
    "                                value = value*10**13\n",
    "                             \n",
    "                            sensor_df_time.append({'time': time, \n",
    "                                                   'latitude': lat, \n",
    "                                                   'longitude': lon, \n",
    "                                                   'sensor_column': value})\n",
    "                            lon += 0.125\n",
    "                            \n",
    "                i += 1\n",
    "                \n",
    "        sensor_df_time = pd.DataFrame(sensor_df_time)\n",
    "        sensor_df_time = sensor_df_time.set_index(['time', 'latitude', 'longitude'])\n",
    "        sensor_df_time = sensor_df_time[~sensor_df_time.index.duplicated()]\n",
    "\n",
    "        # Change resolution\n",
    "        sensor_ds_time = sensor_df_time.to_xarray()\n",
    "        sensor_ds_time = regrid(sensor_ds_time, lat_res, lon_res) \n",
    "\n",
    "        sensor_ds.append(sensor_ds_time)\n",
    "            \n",
    "    sensor_ds = xr.concat(sensor_ds, dim = 'time')\n",
    "    sensor_ds['sensor_column'] = sensor_ds['sensor_column'].assign_attrs({'units': 'molec cm-2'})\n",
    "\n",
    "    return sensor_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_L2_download(input_type, bbox, date, product_type, component_nom):\n",
    "\n",
    "   \"\"\" Query and download the TROPOMI L2 dataset from Sentinel API\n",
    "\n",
    "         Args:\n",
    "            input_type (str): Search type (Manual or Query)\n",
    "            bbox (arr): Query bounding box\n",
    "            date (str): Query date\n",
    "            product_type (str): Query product type\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "\n",
    "        Returns:\n",
    "            product_name (str): Product name of TROPOMI product within 5phub\n",
    "   \"\"\"\n",
    "\n",
    "   user = 's5pguest' \n",
    "   password = 's5pguest' \n",
    "   api = SentinelAPI(user, password, 'https://s5phub.copernicus.eu/dhus/')\n",
    "\n",
    "   if input_type == 'Manual':\n",
    "\n",
    "      file_name = input('Write file name: ')\n",
    "      product_name = input('Write product name:')\n",
    "\n",
    "   elif input_type == 'Query':\n",
    "      \n",
    "      print('WARNING: The maximum number of items that can be shown is 5.')\n",
    "      print('You can see all the results at https://s5phub.copernicus.eu/dhus/.')\n",
    "\n",
    "      poly = geojson.Polygon([[(bbox[0][0], bbox[0][1]), (bbox[0][0], bbox[1][1]), \n",
    "                               (bbox[1][0], bbox[1][1]), (bbox[1][0], bbox[0][1]), \n",
    "                               (bbox[0][0], bbox[0][1])]])\n",
    "\n",
    "      products = api.query(area = geojson_to_wkt(poly),\n",
    "                           area_relation = 'Contains',\n",
    "                           producttype = product_type,\n",
    "                           processinglevel = 'L2',\n",
    "                           platformname = 'Sentinel-5 Precursor',\n",
    "                           instrumentname = 'TROPOspheric Monitoring Instrument',\n",
    "                           processingmode = 'Near real time',\n",
    "                           date = date,\n",
    "                           limit = 5)\n",
    "\n",
    "      items = list(products.items())\n",
    "      \n",
    "      if items:\n",
    "         for i in range(0, len(items)):\n",
    "               print('Number ', i, '-', items[i][1]['title'], sep = '')\n",
    "\n",
    "      else: \n",
    "         print('There are no results for the processing mode NRT. The search in the offline archives will start.')\n",
    "         products = api.query(area = geojson_to_wkt(poly),\n",
    "                              area_relation = 'Contains',\n",
    "                              producttype = product_type,\n",
    "                              processinglevel = 'L2',\n",
    "                              platformname = 'Sentinel-5 Precursor',\n",
    "                              instrumentname = 'TROPOspheric Monitoring Instrument',\n",
    "                              processingmode = 'Offline',\n",
    "                              date = date,\n",
    "                              limit = 5)\n",
    "\n",
    "         items = list(products.items())\n",
    "\n",
    "         if items:\n",
    "            for i in range(0, len(items)):\n",
    "               print('Number ', i, '-', items[i][1]['title'], sep = '')\n",
    "\n",
    "         else: \n",
    "            print('There are no results in the offline archives. The code will be interrupted.')\n",
    "            raise KeyboardInterrupt\n",
    "            \n",
    "      file_int = input('Select number or press Enter if you want to select the first result: ') or 0\n",
    "      file_name = items[int(file_int)][0]\n",
    "      product_name = items[int(file_int)][1]['title'] + '.nc'\n",
    "\n",
    "   print('SELECTED')\n",
    "   print('File name:', file_name)\n",
    "   print('Product name:', product_name)\n",
    "   \n",
    "   if os.path.isfile(os.path.join('/', '/'.join(os.getcwd().split('/')[1:3]), 'adc-toolbox', os.path.relpath('data/tropomi' + '/' + \n",
    "                     component_nom + '/L2/' + date[0].split('T')[0] + '/' + product_name))):\n",
    "      print('The file exists, it will not be downloaded again.')\n",
    "\n",
    "   else:\n",
    "      print('The file does not exist, it will be downloaded.')\n",
    "      print(f'Downloading {product_name}...')\n",
    "      api.download(file_name, directory_path = os.path.join('/', '/'.join(\n",
    "                                               os.getcwd().split('/')[1:3]), 'adc-toolbox', \n",
    "                                               os.path.relpath('data/tropomi/' + component_nom + '/L2/' + date[0].split('T')[0])))\n",
    "\n",
    "   return product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_L2_read(component_nom, sensor_column, dates):\n",
    "\n",
    "    \"\"\" Read TROPOMI L2 dataset as xarray dataset object\n",
    "\n",
    "        Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor_column (str): Name of sensor column in downloaded dataset\n",
    "            dates (list): Available dates\n",
    "\n",
    "        Returns:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "            support_input_ds (xarray): TROPOMI dataset that contains support input data in xarray format\n",
    "            support_details_ds (xarray): TROPOMI dataset that contains support details data in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    sensor_ds_all = []\n",
    "    support_input_ds_all = []\n",
    "    support_details_ds_all = []\n",
    "\n",
    "    for date in dates:\n",
    "\n",
    "        path = os.path.join('/', '/'.join(\n",
    "               os.getcwd().split('/')[1:3]), 'adc-toolbox', \n",
    "               os.path.relpath('data/tropomi/' + component_nom + '/L2/' + date[0].split('T')[0]))\n",
    "        product_names = [file for file in os.listdir(path) if file.endswith('.nc')]\n",
    "        \n",
    "        for product_name in product_names:\n",
    "\n",
    "            sensor_ds = xr.open_dataset(path + '/' + product_name, group = 'PRODUCT')\n",
    "            sensor_ds = sensor_ds.rename({sensor_column: 'sensor_column'})\n",
    "            \n",
    "            support_input_ds = xr.open_dataset(path + '/' + product_name, \n",
    "                                               group = 'PRODUCT/SUPPORT_DATA/INPUT_DATA')\n",
    "\n",
    "            support_input_ds = support_input_ds.assign(ground_pixel = sensor_ds.ground_pixel)\n",
    "            support_input_ds = support_input_ds.assign(scanline = sensor_ds.scanline)\n",
    "            support_input_ds = support_input_ds.assign(time = sensor_ds.time)\n",
    "            support_input_ds = support_input_ds.set_coords(['ground_pixel', 'scanline', 'time'])\n",
    "\n",
    "            support_details_ds = xr.open_dataset(path + '/' + product_name, \n",
    "                                                 group = 'PRODUCT/SUPPORT_DATA/DETAILED_RESULTS')\n",
    "\n",
    "            support_details_ds = support_details_ds.assign(ground_pixel = sensor_ds.ground_pixel)\n",
    "            support_details_ds = support_details_ds.assign(scanline = sensor_ds.scanline)\n",
    "            support_details_ds = support_details_ds.assign(time = sensor_ds.time)\n",
    "            support_details_ds = support_details_ds.set_coords(['ground_pixel', 'scanline', 'time'])\n",
    "\n",
    "            if component_nom == 'CO':\n",
    "                    \n",
    "                # Transform heights into levels\n",
    "                data = {'Layer': np.arange(1, 51)[::-1], 'Height': sensor_ds.layer}\n",
    "                dataframe = pd.DataFrame(data)\n",
    "                \n",
    "                for i in range(0, 50):\n",
    "\n",
    "                    sensor_ds['layer'] = xr.where(sensor_ds.layer == dataframe['Height'].iloc[i], \n",
    "                                                  int(dataframe['Layer'].iloc[i]), sensor_ds['layer'])\n",
    "\n",
    "            sensor_ds_all.append(sensor_ds)\n",
    "            support_input_ds_all.append(support_input_ds)\n",
    "            support_details_ds_all.append(support_details_ds)\n",
    "\n",
    "    sensor_ds = xr.concat(sensor_ds_all, dim = 'time')\n",
    "    support_input_ds = xr.concat(support_input_ds_all, dim = 'time')\n",
    "    support_details_ds = xr.concat(support_details_ds_all, dim = 'time')\n",
    "\n",
    "    return sensor_ds, support_input_ds, support_details_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_pressure(sensor_ds, component_nom, support_input_ds, support_details_ds):\n",
    "\n",
    "    \"\"\" Calculate level pressures for TROPOMI dataset\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            support_input_ds (xarray): TROPOMI dataset that contains support input data in xarray format\n",
    "            support_details_ds (xarray): TROPOMI dataset that contains support details data in xarray format\n",
    "            \n",
    "        Returns:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if component_nom == 'NO2':\n",
    "        \n",
    "        print('The level pressures will be calculated.')\n",
    "\n",
    "        # Calculate pressure as p = ap + b * ps (Units: ap(Pa) + b(none) * ps(Pa) -> To Pa)\n",
    "        pressure_upper_bound = (sensor_ds.tm5_constant_a.sel(vertices = 1) + \n",
    "                                sensor_ds.tm5_constant_b.sel(vertices = 1) * support_input_ds.surface_pressure)\n",
    "\n",
    "        pressure_lower_bound = (sensor_ds.tm5_constant_a.sel(vertices = 0) + \n",
    "                                sensor_ds.tm5_constant_b.sel(vertices = 0) * support_input_ds.surface_pressure)\n",
    "\n",
    "        sensor_ds = sensor_ds.assign(pressure = (pressure_upper_bound + pressure_lower_bound) / 2)\n",
    "    \n",
    "    elif component_nom == 'CO':\n",
    "\n",
    "        print('The level pressures will be retrieved.')\n",
    "\n",
    "        # Pressure is at lower bound!\n",
    "        pressure_lower = support_details_ds.pressure_levels\n",
    "        sensor_ds = sensor_ds.assign(pressure = pressure_lower)\n",
    "\n",
    "    elif component_nom == 'SO2':\n",
    "        \n",
    "        print('The level pressures will be calculated.')\n",
    "        \n",
    "        # Unknown bound, half?\n",
    "        pressure = (support_input_ds.tm5_constant_a + \n",
    "                    support_input_ds.tm5_constant_b * support_input_ds.surface_pressure)\n",
    "        sensor_ds = sensor_ds.assign(pressure = pressure)\n",
    "    \n",
    "    elif component_nom == 'O3':\n",
    "\n",
    "        print('The level pressures will be retrieved.')\n",
    "\n",
    "        # Unknown bound, half?\n",
    "        pressure = support_details_ds.pressure_grid\n",
    "        sensor_ds = sensor_ds.assign(pressure = pressure)\n",
    "\n",
    "    else:\n",
    "        print('This dataset does not contain data to retrieve or calculate the level pressures.')\n",
    "\n",
    "    return sensor_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_column_kernel(sensor_ds, component_nom, support_details_ds):\n",
    "\n",
    "    \"\"\" Calculate column kernels for TROPOMI dataset\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            support_details_ds (xarray): TROPOMI dataset that contains support details data in xarray format\n",
    "\n",
    "        Returns:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if component_nom == 'NO2':\n",
    "\n",
    "        print('The column kernels will be calculated.')\n",
    "\n",
    "        column_kernel = xr.where(sensor_ds.layer > sensor_ds.tm5_tropopause_layer_index, 0, \n",
    "                                 sensor_ds.averaging_kernel * (sensor_ds.air_mass_factor_total / \n",
    "                                 sensor_ds.air_mass_factor_troposphere))\n",
    "        sensor_ds = sensor_ds.assign(column_kernel = column_kernel)\n",
    "\n",
    "    elif component_nom == 'CO':\n",
    "        \n",
    "        print('The column kernels will be calculated.')\n",
    "\n",
    "        column_kernel = support_details_ds.column_averaging_kernel\n",
    "        sensor_ds = sensor_ds.assign(column_kernel = column_kernel)\n",
    "    \n",
    "    elif component_nom == 'SO2':\n",
    "        \n",
    "        print('The column kernels will be calculated.')\n",
    "        \n",
    "        \"\"\"\n",
    "        height_options = [1, 7, 15]\n",
    "        height = input('Input height (in km) to calculate the column kernels with accuracy (1, 7 or 15): ')\n",
    "\n",
    "        while int(height) not in height_options:\n",
    "            print('ERROR: Enter a valid height number. The options are 1, 7 or 15 km.')\n",
    "            height = input('Input height (in km): ')\n",
    "\n",
    "        air_mass_factor_total = support_details_ds['sulfurdioxide_total_air_mass_factor_' + height + 'km']\n",
    "        column_kernel = xr.where(sensor_ds.layer > support_input_ds.tm5_tropopause_layer_index, 0, \n",
    "                                 support_details_ds.averaging_kernel * (air_mass_factor_total / \n",
    "                                 sensor_ds.air_mass_factor_troposphere))\n",
    "        \"\"\"\n",
    "        \n",
    "        column_kernel = support_details_ds.averaging_kernel\n",
    "        sensor_ds = sensor_ds.assign(column_kernel = column_kernel)\n",
    "    \n",
    "    elif component_nom == 'O3':\n",
    "\n",
    "        print('The column kernels will be calculated.')\n",
    "        \n",
    "        column_kernel = support_details_ds.averaging_kernel\n",
    "        sensor_ds = sensor_ds.assign(column_kernel = column_kernel)\n",
    "\n",
    "    else:\n",
    "        print('The dataset does not contain data to retrieve or calculate the column averaging kernels.')\n",
    "\n",
    "    return sensor_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_apriori_profile(sensor_ds, component_nom, component, support_details_ds):\n",
    "\n",
    "    \"\"\" Retrieve apriori profile if it exists and add to xarray dataset.\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            component (str): Component name\n",
    "            support_details_ds (xarray): TROPOMI dataset that contains support details data in xarray format\n",
    "        \n",
    "        Returns:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if component_nom == 'SO2':\n",
    "        apriori_profile = 'sulfurdioxide_profile_apriori'\n",
    "\n",
    "    else:\n",
    "        apriori_profile = component.replace('_', '') + '_profile_apriori'\n",
    "    \n",
    "    if apriori_profile in list(support_details_ds.keys()):\n",
    "        apriori_profile = support_details_ds[apriori_profile]\n",
    "        sensor_ds = sensor_ds.assign(apriori_profile = apriori_profile)\n",
    "        print('The apriori profiles will be retrieved.')\n",
    "\n",
    "    else:\n",
    "        print('The dataset does not contain any apriori profile.')\n",
    "    \n",
    "    return sensor_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_lookup_table(sensor_ds, component_nom):\n",
    "\n",
    "    \"\"\" Create file with the original corresponding coordinates to each scanline and ground pixel in TROPOMI dataset\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "\n",
    "        Returns:\n",
    "            lookup_table (dataframe): TROPOMI coordinates equivalence table\n",
    "    \"\"\"\n",
    "\n",
    "    # Dims and vars to drop\n",
    "    if component_nom == 'NO2':\n",
    "        dims_to_drop = ['polynomial_exponents', 'vertices', 'intensity_offset_polynomial_exponents', 'corner', 'layer']\n",
    "        vars_to_drop = ['time_utc', 'qa_value', 'sensor_column', 'nitrogendioxide_tropospheric_column_precision', \n",
    "                        'nitrogendioxide_tropospheric_column_precision_kernel', 'air_mass_factor_troposphere', \n",
    "                        'air_mass_factor_total', 'tm5_tropopause_layer_index']\n",
    "\n",
    "    elif component_nom == 'O3':\n",
    "        dims_to_drop = ['corner', 'layer', 'level']\n",
    "        vars_to_drop = ['time_utc', 'qa_value', 'sensor_column', 'ozone_total_vertical_column_precision']\n",
    "\n",
    "    elif component_nom == 'CO':\n",
    "        dims_to_drop = ['corner', 'layer']\n",
    "        vars_to_drop = ['time_utc', 'qa_value', 'sensor_column', 'carbonmonoxide_total_column_precision',\n",
    "                        'carbonmonoxide_total_column_corrected']\n",
    "\n",
    "    elif component_nom == 'SO2':\n",
    "        dims_to_drop = ['corner', 'layer']\n",
    "        vars_to_drop = ['time_utc', 'qa_value', 'sensor_column', 'sulfurdioxide_total_vertical_column_precision']\n",
    "\n",
    "    elif component_nom == 'HCHO':\n",
    "        dims_to_drop = ['corner', 'layer']\n",
    "        vars_to_drop = ['formaldehyde_tropospheric_vertical_column_precision']\n",
    "\n",
    "    # Create lookup table\n",
    "    lookup_table = sensor_ds.drop_dims(dims_to_drop).drop_vars(vars_to_drop).to_dataframe().reset_index()\n",
    "\n",
    "    return lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_subset(sensor_ds_time, bbox, component_nom):\n",
    "\n",
    "    \"\"\" Read file with the corresponding coordinates to each scanline and ground pixel in TROPOMI dataset.\n",
    "        Subset dataset into desired bounding box.\n",
    "\n",
    "        Args:\n",
    "            sensor_ds_time (xarray): TROPOMI dataset in xarray format per time\n",
    "            bbox (arr): Query bounding box\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "    \n",
    "        Returns:\n",
    "            sensor_ds_time (xarray): TROPOMI dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    # Read lookup table\n",
    "    lookup_table = TROPOMI_lookup_table(sensor_ds_time, component_nom)\n",
    "    \n",
    "    # Set limits\n",
    "    lookup_table = lookup_table[(lookup_table['latitude'] >= bbox[0][1]) & \n",
    "                                (lookup_table['latitude'] <= bbox[1][1])]\n",
    "    lookup_table = lookup_table[(lookup_table['longitude'] >= bbox[0][0]) & \n",
    "                                (lookup_table['longitude'] <= bbox[1][0])]\n",
    "    \n",
    "    if lookup_table.empty:\n",
    "        \n",
    "        print('ERROR: The subset could not be made. Try for another TROPOMI dataset. The code will be interrupted.')\n",
    "        raise KeyboardInterrupt\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Get scanline and ground pixel coordinates\n",
    "        scanline_coords = np.unique(lookup_table['scanline'].values).tolist()\n",
    "        ground_pixel_coords = np.unique(lookup_table['ground_pixel'].values).tolist()\n",
    "\n",
    "        # Set limits\n",
    "        sensor_ds_time = sensor_ds_time.sel(scanline = scanline_coords, ground_pixel = ground_pixel_coords)\n",
    "\n",
    "    return sensor_ds_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_apply_kernels(match_df, model_ds_time, sensor_ds_time, component_nom):\n",
    "\n",
    "    \"\"\" Apply averaging kernels: Find the nearest neighbours in the observation space \n",
    "        (in latitude and longitudes) and interpolate values in pressure\n",
    "\n",
    "        Args:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "            model_ds_time (xarray): Model levels dataset in xarray format per time\n",
    "            sensor_ds_time (xarray): TROPOMI dataset in xarray format per time\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            \n",
    "        Returns:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "    \"\"\"\n",
    "\n",
    "    print('WARNING: The application of averaging kernels will take some time.')\n",
    "    \n",
    "    # Read new coordinates (after subset)\n",
    "    lookup_table = TROPOMI_lookup_table(sensor_ds_time, component_nom)\n",
    "\n",
    "    # Set the layer coordinate as index\n",
    "    match_df = match_df.set_index('layer', append = True)\n",
    "\n",
    "    # Create index that includes CAMS pressure levels for all the locations in TROPOMI\n",
    "    new_array = np.concatenate([np.arange(1, 137) * 1000, sensor_ds_time.layer.values])\n",
    "    new_index = pd.MultiIndex.from_product([match_df.index.levels[0], \n",
    "                                            match_df.index.levels[1],\n",
    "                                            match_df.index.levels[2],\n",
    "                                            new_array\n",
    "                                            ],\n",
    "                                            names = ['scanline', 'ground_pixel', 'time', 'layer'])\n",
    "    \n",
    "    # Append original and new indexes and reindex dataframe\n",
    "    match_df = match_df[~match_df.index.duplicated()]\n",
    "    match_df = match_df.reindex(match_df.index.append(new_index))\n",
    "    \n",
    "    # Sort and reset index\n",
    "    match_df = match_df.sort_index()\n",
    "    match_df = match_df.reset_index()\n",
    "\n",
    "    # Find latitudes in CAMS rows with scanlines and ground pixels\n",
    "    match_df['latitude'] = match_df.apply(lambda row: float(lookup_table[\n",
    "                                                           (lookup_table['scanline'] == row['scanline']) & \n",
    "                                                           (lookup_table['ground_pixel'] == row['ground_pixel'])]['latitude'])\n",
    "                                                           if pd.isnull(row['latitude']) \n",
    "                                                           else row['latitude'], \n",
    "                                                           axis = 1)\n",
    "                                                            \n",
    "    # Find longitudes in CAMS rows with scanlines and ground pixels\n",
    "    match_df['longitude'] = match_df.apply(lambda row: float(lookup_table[\n",
    "                                                            (lookup_table['scanline'] == row['scanline']) & \n",
    "                                                            (lookup_table['ground_pixel'] == row['ground_pixel'])]['longitude'])\n",
    "                                                            if pd.isnull(row['longitude']) \n",
    "                                                            else row['longitude'], \n",
    "                                                            axis = 1)\n",
    "\n",
    "    # Get unique timestep\n",
    "    sensor_times = sensor_ds_time.delta_time.isel(scanline = 0).values\n",
    "    model_times = model_ds_time.valid_time.values\n",
    "    unique_step = int(np.unique(nearest_neighbour(model_times, sensor_times)))\n",
    "    unique_time = model_ds_time.component.isel(step = unique_step).step.values.astype('timedelta64[h]')\n",
    "\n",
    "    # Get CAMS model partial columns above each level at closest TROPOMI locations (nearest neighbours)\n",
    "    match_df['model_partial_column_above'] = match_df.apply(lambda row: model_ds_time.component.sel(\n",
    "                                                                        step = unique_time,\n",
    "                                                                        hybrid = row['layer'] / 1000, \n",
    "                                                                        latitude = row['latitude'], \n",
    "                                                                        longitude = row['longitude'], \n",
    "                                                                        method = 'nearest').values \n",
    "                                                                        if pd.isnull(row['sensor_column']) \n",
    "                                                                        else math.nan,\n",
    "                                                                        axis = 1)\n",
    "\n",
    "    # Get CAMS model level pressures\n",
    "    match_df['pressure'] = match_df.apply(lambda row: model_ds_time.pressure.sel(\n",
    "                                                      step = unique_time,\n",
    "                                                      hybrid = row['layer'] / 1000, \n",
    "                                                      latitude = row['latitude'], \n",
    "                                                      longitude = row['longitude'], \n",
    "                                                      method = 'nearest').values \n",
    "                                                      if pd.isnull(row['pressure']) \n",
    "                                                      else row['pressure'],\n",
    "                                                      axis = 1)\n",
    "\n",
    "    # Transform 1D-array data to float\n",
    "    match_df['model_partial_column_above'] = match_df['model_partial_column_above'].apply(lambda x: float(x))\n",
    "    match_df['pressure'] = match_df['pressure'].apply(lambda x: float(x))\n",
    "\n",
    "    # Set multiindex again and sort for interpolation\n",
    "    match_df = match_df.reset_index()\n",
    "    match_df = match_df.set_index(['time', 'ground_pixel', 'scanline', 'pressure'])\n",
    "    match_df = match_df.sort_values(['time', 'ground_pixel','scanline', 'pressure'], \n",
    "                                    ascending = [True, True, True, False])\n",
    "\n",
    "    # Interpolate partial columns onto the TM5 pressure levels.\n",
    "    match_df = match_df[~match_df.index.duplicated()]\n",
    "    match_df['model_partial_column_above'] = match_df['model_partial_column_above'].interpolate()\n",
    "\n",
    "    # Drop unnecessary values\n",
    "    match_df = match_df.reset_index()\n",
    "    match_df = match_df.set_index(['time', 'ground_pixel', 'scanline', 'layer'])\n",
    "    match_df = match_df.drop(np.arange(1, 137) * 1000, level = 'layer')     \n",
    "    \n",
    "    # Calculate CAMS partial columns for each TM5 layer (as difference of the interpolated values)\n",
    "    match_df['model_column'] = match_df['model_partial_column_above'] - match_df['model_partial_column_above'].shift(-1)\n",
    "    match_df = match_df.reset_index()\n",
    "    match_df.loc[match_df['layer'] == 33, ['model_column']] = match_df['model_partial_column_above']\n",
    "    match_df = match_df.set_index(['time', 'ground_pixel', 'scanline', 'layer'])\n",
    "\n",
    "    # Calculate values to generate CAMS column to sum in the next step\n",
    "    if 'apriori_profile' in match_df.columns:\n",
    "        match_df['model_column'] = match_df.apply(lambda row: row['apriori_profile'] +\n",
    "                                                              row['column_kernel'] * row['model_column']  -\n",
    "                                                              row['column_kernel'] * row['apriori_profile'], \n",
    "                                                              axis = 1)\n",
    "    \n",
    "    else:\n",
    "        match_df['model_column'] = match_df.apply(lambda row: row['model_column'] * \n",
    "                                                              row['column_kernel'], \n",
    "                                                              axis = 1)\n",
    "\n",
    "    return match_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84d6139589c0d952b978fb9437b8e11e4e03996aa73ed56a307e4c0ad5e273d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env-new': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
