{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TROPOMI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_download(input_type, bbox, date, product_type, processing_mode, component_nom):\n",
    "\n",
    "   \"\"\" Query and download the TROPOMI dataset from Sentinel API\n",
    "\n",
    "         Args:\n",
    "            input_type (str): Search type (Manual or Query)\n",
    "            bbox (arr): Query bounding box\n",
    "            date (list or tuple): Query date\n",
    "            product_type (str): Query product type\n",
    "            processing_mode (str): Query processing mode (Offline, Near real time, Reprocessing)\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "\n",
    "        Returns:\n",
    "            product_name (str): Product name of TROPOMI product within 5phub\n",
    "   \"\"\"\n",
    "\n",
    "   user = 's5pguest' \n",
    "   password = 's5pguest' \n",
    "   api = SentinelAPI(user, password, 'https://s5phub.copernicus.eu/dhus/')\n",
    "\n",
    "   if input_type == 'Manual':\n",
    "\n",
    "      file_name = input('Write file name: ')\n",
    "      product_name = input('Write product name:')\n",
    "\n",
    "   elif input_type == 'Query':\n",
    "      \n",
    "      print('WARNING: The maximum number of items that can be shown is 5.')\n",
    "      print('You can see all the results at https://s5phub.copernicus.eu/dhus/.')\n",
    "\n",
    "      poly = geojson.Polygon([[(bbox[0][0], bbox[0][1]), (bbox[0][0], bbox[1][1]), \n",
    "                               (bbox[1][0], bbox[1][1]), (bbox[1][0], bbox[0][1]), \n",
    "                               (bbox[0][0], bbox[0][1])]])\n",
    "\n",
    "      products = api.query(area = geojson_to_wkt(poly),\n",
    "                           area_relation = 'Contains',\n",
    "                           producttype = product_type,\n",
    "                           processinglevel = 'L2',\n",
    "                           platformname = 'Sentinel-5 Precursor',\n",
    "                           instrumentname = 'TROPOspheric Monitoring Instrument',\n",
    "                           processingmode = processing_mode,\n",
    "                           date = date,\n",
    "                           limit = 5)\n",
    "\n",
    "      items = list(products.items())\n",
    "      \n",
    "      if not items: \n",
    "         print('There are no results. The code will be interrupted.')\n",
    "         raise KeyboardInterrupt\n",
    "       \n",
    "      else:\n",
    "         for i in range(0, len(items)):\n",
    "            print('Number ', i, '-', items[i][1]['title'], sep = '')\n",
    "\n",
    "      file_int = input('Select number or press Enter if you want to select the first result: ') or 0\n",
    "      file_name = items[int(file_int)][0]\n",
    "      product_name = items[int(file_int)][1]['title'] + '.nc'\n",
    "\n",
    "   print('SELECTED')\n",
    "   print('File name:', file_name)\n",
    "   print('Product name:', product_name)\n",
    "   \n",
    "   if os.path.isfile(os.path.join(os.path.abspath(''), 'data/tropomi' + '/' + \n",
    "                     component_nom + '/' + date[0].split('T')[0] + '/' + product_name)):\n",
    "      print('The file exists, it will not be downloaded again.')\n",
    "\n",
    "   else:\n",
    "      print('The file does not exist, it will be downloaded.')\n",
    "      print(f'Downloading {product_name}...')\n",
    "      api.download(file_name, directory_path = 'data/tropomi/' + component_nom + '/' + date[0].split('T')[0])\n",
    "\n",
    "   return product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_read(dates, component_nom, sensor_column):\n",
    "\n",
    "    \"\"\" Read TROPOMI dataset as xarray dataset object\n",
    "\n",
    "        Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor_column (str): Name of sensor column in downloaded dataset\n",
    "\n",
    "        Returns:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "            support_input_ds (xarray): TROPOMI dataset that contains support input data in xarray format\n",
    "            support_details_ds (xarray): TROPOMI dataset that contains support details data in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    sensor_ds_all = []\n",
    "    support_input_ds_all = []\n",
    "    support_details_ds_all = []\n",
    "\n",
    "    for date in dates:\n",
    "\n",
    "        path = 'data/tropomi/' + component_nom + '/' + date[0].split('T')[0]\n",
    "        product_names = [file for file in os.listdir(path) if file.endswith('.nc')]\n",
    "        \n",
    "        for product_name in product_names:\n",
    "\n",
    "            sensor_ds = xr.open_dataset(path + '/' + product_name, group = 'PRODUCT')\n",
    "            sensor_ds = sensor_ds.rename({sensor_column: 'sensor_column'})\n",
    "            \n",
    "            support_input_ds = xr.open_dataset(path + '/' + product_name, \n",
    "                                               group = 'PRODUCT/SUPPORT_DATA/INPUT_DATA')\n",
    "\n",
    "            support_input_ds = support_input_ds.assign(ground_pixel = sensor_ds.ground_pixel)\n",
    "            support_input_ds = support_input_ds.assign(scanline = sensor_ds.scanline)\n",
    "            support_input_ds = support_input_ds.assign(time = sensor_ds.time)\n",
    "            support_input_ds = support_input_ds.set_coords(['ground_pixel', 'scanline', 'time'])\n",
    "\n",
    "            support_details_ds = xr.open_dataset(path + '/' + product_name, \n",
    "                                                 group = 'PRODUCT/SUPPORT_DATA/DETAILED_RESULTS')\n",
    "\n",
    "            support_details_ds = support_details_ds.assign(ground_pixel = sensor_ds.ground_pixel)\n",
    "            support_details_ds = support_details_ds.assign(scanline = sensor_ds.scanline)\n",
    "            support_details_ds = support_details_ds.assign(time = sensor_ds.time)\n",
    "            support_details_ds = support_details_ds.set_coords(['ground_pixel', 'scanline', 'time'])\n",
    "\n",
    "            if component_nom == 'CO':\n",
    "                    \n",
    "                # Transform heights into levels\n",
    "                data = {'Layer': np.arange(1, 51)[::-1], 'Height': sensor_ds.layer}\n",
    "                dataframe = pd.DataFrame(data)\n",
    "                \n",
    "                for i in range(0, 50):\n",
    "\n",
    "                    sensor_ds['layer'] = xr.where(sensor_ds.layer == dataframe['Height'].iloc[i], \n",
    "                                                  int(dataframe['Layer'].iloc[i]), sensor_ds['layer'])\n",
    "\n",
    "            sensor_ds_all.append(sensor_ds)\n",
    "            support_input_ds_all.append(support_input_ds)\n",
    "            support_details_ds_all.append(support_details_ds)\n",
    "\n",
    "    sensor_ds = xr.concat(sensor_ds_all, dim = 'time')\n",
    "    support_input_ds = xr.concat(support_input_ds_all, dim = 'time')\n",
    "    support_details_ds = xr.concat(support_details_ds_all, dim = 'time')\n",
    "\n",
    "    return sensor_ds, support_input_ds, support_details_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_pressure(sensor_ds, component_nom, support_input_ds, support_details_ds):\n",
    "\n",
    "    \"\"\" Calculate level pressures for TROPOMI dataset\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            support_input_ds (xarray): TROPOMI dataset that contains support input data in xarray format\n",
    "            support_details_ds (xarray): TROPOMI dataset that contains support details data in xarray format\n",
    "            \n",
    "        Returns:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if component_nom == 'NO2':\n",
    "        \n",
    "        print('The layers pressures will be calculated (lower and upper bounds).')\n",
    "\n",
    "        # Calculate pressure as p = ap + b * ps (Units: ap(Pa) + b(none) * ps(Pa) -> To Pa)\n",
    "        pressure = (sensor_ds.tm5_constant_a + sensor_ds.tm5_constant_b * support_input_ds.surface_pressure)\n",
    "        sensor_ds = sensor_ds.assign(pressure = pressure)\n",
    "    \n",
    "    elif component_nom == 'CO':\n",
    "\n",
    "        print('The layers pressures will be retrieved (lower bound).')\n",
    "\n",
    "        # Pressure is at lower bound!\n",
    "        pressure_lower = support_details_ds.pressure_levels\n",
    "        sensor_ds = sensor_ds.assign(pressure = pressure_lower)\n",
    "\n",
    "    elif component_nom == 'SO2':\n",
    "        \n",
    "        print('The layers pressures will be calculated (unknown bound, half?).')\n",
    "        \n",
    "        pressure = (support_input_ds.tm5_constant_a + support_input_ds.tm5_constant_b * support_input_ds.surface_pressure)\n",
    "        sensor_ds = sensor_ds.assign(pressure = pressure)\n",
    "    \n",
    "    elif component_nom == 'O3':\n",
    "\n",
    "        print('The layers pressures will be retrieved (unknown bound, half?).')\n",
    "        pressure = support_details_ds.pressure_grid\n",
    "        sensor_ds = sensor_ds.assign(pressure = pressure)\n",
    "\n",
    "    else:\n",
    "        print('This dataset does not contain data to calculate the layer pressures.')\n",
    "\n",
    "    return sensor_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_column_kernel(sensor_ds, component_nom, support_details_ds):\n",
    "\n",
    "    \"\"\" Calculate column kernels for TROPOMI dataset\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            support_details_ds (xarray): TROPOMI dataset that contains support details data in xarray format\n",
    "\n",
    "        Returns:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if component_nom == 'NO2':\n",
    "\n",
    "        column_kernel = xr.where(sensor_ds.layer > sensor_ds.tm5_tropopause_layer_index, 0, \n",
    "                                 sensor_ds.averaging_kernel * (sensor_ds.air_mass_factor_total / \n",
    "                                 sensor_ds.air_mass_factor_troposphere))\n",
    "        sensor_ds = sensor_ds.assign(column_kernel = column_kernel)\n",
    "\n",
    "    elif component_nom == 'CO':\n",
    "\n",
    "        column_kernel = support_details_ds.column_averaging_kernel\n",
    "        sensor_ds = sensor_ds.assign(column_kernel = column_kernel)\n",
    "    \n",
    "    elif component_nom == 'SO2':\n",
    "        \n",
    "        \"\"\"\n",
    "        height_options = [1, 7, 15]\n",
    "        height = input('Input height (in km) to calculate the column kernels with accuracy: ')\n",
    "\n",
    "        while int(height) not in height_options:\n",
    "            print('ERROR: Enter a valid height number. The options are 1, 7 or 15 km.')\n",
    "            height = input('Input height (in km): ')\n",
    "        \"\"\"\n",
    "\n",
    "        column_kernel = support_details_ds.averaging_kernel\n",
    "        sensor_ds = sensor_ds.assign(column_kernel = column_kernel)\n",
    "    \n",
    "    elif component_nom == 'O3':\n",
    "\n",
    "        column_kernel = support_details_ds.averaging_kernel\n",
    "        sensor_ds = sensor_ds.assign(column_kernel = column_kernel)\n",
    "\n",
    "    else:\n",
    "        print('The dataset does not contain information to retrieve or calculate the column averaging kernels.')\n",
    "\n",
    "    return sensor_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_apriori_profile(sensor_ds, component, support_details_ds):\n",
    "\n",
    "    \"\"\" Retrieve apriori profile if it exists and add to xarray dataset.\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "            component (str): Component name\n",
    "            support_details_ds (xarray): TROPOMI dataset that contains support details data in xarray format\n",
    "        \n",
    "        Returns:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    apriori_profile = component.replace('_', '') + '_profile_apriori'\n",
    "\n",
    "    if apriori_profile in list(support_details_ds.keys()):\n",
    "        apriori_profile = support_details_ds[apriori_profile]\n",
    "        sensor_ds = sensor_ds.assign(apriori_profile = apriori_profile)\n",
    "\n",
    "    else:\n",
    "        print('The dataset does not contain any apriori profile.')\n",
    "    \n",
    "    return sensor_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_original_coords(sensor_ds, component_nom, time):\n",
    "\n",
    "    \"\"\" Create file with the original corresponding coordinates to each scanline and ground pixel in TROPOMI dataset\n",
    "\n",
    "        Args:\n",
    "            sensor_ds (xarray): TROPOMI dataset in xarray format\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            time (timestamp): Start datetime for each period\n",
    "    \"\"\"\n",
    "\n",
    "    # Create dataframe with scanlines and ground pixels\n",
    "    sensor_coords_df = []\n",
    "    sensor_coords_df = pd.DataFrame(list(product(sensor_ds.ground_pixel.values, sensor_ds.scanline.values)), \n",
    "                            columns = ['ground_pixel', 'scanline'])\n",
    "\n",
    "    # Find corresponding latitudes and longitudes                          \n",
    "    for index, row in sensor_coords_df.iterrows():\n",
    "        sensor_coords_df.loc[index,'latitude'] = sensor_ds.latitude.sel(\n",
    "                                                scanline = sensor_coords_df['scanline'].loc[index], \n",
    "                                                ground_pixel = sensor_coords_df['ground_pixel'].loc[index],\n",
    "                                                method = None).values\n",
    "                                            \n",
    "        sensor_coords_df.loc[index,'longitude'] = sensor_ds.longitude.sel(\n",
    "                                                scanline = sensor_coords_df['scanline'].loc[index], \n",
    "                                                ground_pixel = sensor_coords_df['ground_pixel'].loc[index],\n",
    "                                                method = None).values\n",
    "\n",
    "    # Save as csv\n",
    "    time_str = str(time).split('T')[0]\n",
    "    sensor_coords_df.to_csv('data/tropomi/' + component_nom + '/' + time_str + '/' + \n",
    "                            component_nom + '-' + time_str + '-coords.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_subset(sensor_ds_time, bbox, time, sensor, component_nom):\n",
    "\n",
    "    \"\"\" Read file with the corresponding coordinates to each scanline and ground pixel in TROPOMI dataset.\n",
    "        Subset dataset into desired bounding box.\n",
    "\n",
    "        Args:\n",
    "            sensor_ds_time (xarray): TROPOMI dataset in xarray format per time\n",
    "            bbox (arr): Query bounding box\n",
    "            time (timestamp): Start datetime for each period\n",
    "            sensor (str): Name of the sensor\n",
    "    \n",
    "        Returns:\n",
    "            sensor_ds_time (xarray): TROPOMI dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    time_str = str(time).split('T')[0]\n",
    "    if os.path.isfile(os.path.join(os.path.abspath(''), 'data/tropomi/' + component_nom + '/' \n",
    "                      + time_str + '/' + component_nom + '-' + time_str + '-coords.csv')):\n",
    "        pass\n",
    "\n",
    "    else: \n",
    "        print('WARNING: Subsetting TROPOMI sensor data will take some time.')\n",
    "        TROPOMI_original_coords(sensor_ds_time, component_nom, time)\n",
    "        \n",
    "    # Read csv\n",
    "    sensor_coords_df = pd.read_csv('data/tropomi/' + component_nom + '/' + time_str + '/' + \n",
    "                                   component_nom + '-' + time_str + '-coords.csv')\n",
    "    \n",
    "    # Set limits\n",
    "    sensor_coords_df = sensor_coords_df[(sensor_coords_df['latitude'] >= bbox[0][1]) & \n",
    "                                        (sensor_coords_df['latitude'] <= bbox[1][1])]\n",
    "    sensor_coords_df = sensor_coords_df[(sensor_coords_df['longitude'] >= bbox[0][0]) & \n",
    "                                        (sensor_coords_df['longitude'] <= bbox[1][0])]\n",
    "    \n",
    "    if sensor_coords_df.empty:\n",
    "        \n",
    "        print('ERROR: The subset could not be made. Try for another TROPOMI dataset. The code will be interrupted.')\n",
    "        raise KeyboardInterrupt\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Get scanline and ground pixel coordinates\n",
    "        scanline_coords = np.unique(sensor_coords_df['scanline'].values).tolist()\n",
    "        ground_pixel_coords = np.unique(sensor_coords_df['ground_pixel'].values).tolist()\n",
    "\n",
    "        # Set limits\n",
    "        sensor_ds_time = sensor_ds_time.sel(scanline = scanline_coords, ground_pixel = ground_pixel_coords)\n",
    "\n",
    "    return sensor_ds_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_subset_coords(sensor_ds_time):\n",
    "\n",
    "    \"\"\" Create file with the subset corresponding coordinates to each scanline and ground pixel in TROPOMI dataset\n",
    "\n",
    "        Args:\n",
    "            sensor_ds_time (xarray): TROPOMI dataset in xarray format per time\n",
    "        \n",
    "        Returns:\n",
    "            TROPOMI_subset_coords_df (dataframe): Dataframe with subset coordinates\n",
    "    \"\"\"\n",
    "\n",
    "    # Create dataframe with scanlines and ground pixels\n",
    "    TROPOMI_subset_coords_df = []\n",
    "    TROPOMI_subset_coords_df = pd.DataFrame(list(product(sensor_ds_time.ground_pixel.values, \n",
    "                                                         sensor_ds_time.scanline.values)), \n",
    "                                            columns = ['ground_pixel', 'scanline'])\n",
    "\n",
    "    # Find corresponding latitudes and longitudes                          \n",
    "    for index, row in TROPOMI_subset_coords_df.iterrows():\n",
    "        \n",
    "        TROPOMI_subset_coords_df.loc[index,'latitude'] = sensor_ds_time.latitude.sel(\n",
    "                                                         scanline = TROPOMI_subset_coords_df['scanline'].loc[index], \n",
    "                                                         ground_pixel = TROPOMI_subset_coords_df['ground_pixel'].loc[index],\n",
    "                                                         method = None).values\n",
    "                                                    \n",
    "        TROPOMI_subset_coords_df.loc[index,'longitude'] = sensor_ds_time.longitude.sel(\n",
    "                                                          scanline = TROPOMI_subset_coords_df['scanline'].loc[index], \n",
    "                                                          ground_pixel = TROPOMI_subset_coords_df['ground_pixel'].loc[index],\n",
    "                                                          method = None).values\n",
    "\n",
    "    return TROPOMI_subset_coords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TROPOMI_apply_avg_kernels(kernels_method, match_df, model_ds_time, sensor_ds_time, model_levels_df):\n",
    "\n",
    "    \"\"\" Apply averaging kernels by using two methods:\n",
    "        * Nearest neighbours: Find the nearest neighbours in the observation space (in pressures, latitude and longitudes)\n",
    "        * Interpolation: Find the nearest neighbours in the observation space (in latitude and longitudes) and \n",
    "                         interpolate values in pressure\n",
    "\n",
    "        Args:\n",
    "            kernels_method (str): Method to apply averaging kernels to model space:\n",
    "            * Nearest neighbours: Find nearest neighbours horizontally and vertically\n",
    "            * Interpolation: Find nearest neighbours horizontally and interpolate vertically\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "            model_ds_time (xarray): Model levels dataset in xarray format per time\n",
    "            sensor_ds_time (xarray): TROPOMI dataset in xarray format per time\n",
    "            model_levels_df (dataframe): Table with 137 CAMS levels data\n",
    "        \n",
    "        Returns:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "    \"\"\"\n",
    "\n",
    "    print('WARNING: The application of averaging kernels will take some time.')\n",
    "\n",
    "    if kernels_method == 'Nearest neighbours':\n",
    "        \n",
    "        match_df = avg_kernels_nearest_neighbours(match_df, model_ds_time, model_levels_df)\n",
    "\n",
    "    elif kernels_method == 'Interpolation':\n",
    "           \n",
    "        match_df, _ = avg_kernels_vertical_interpolation(match_df, model_ds_time, sensor_ds_time, \n",
    "                                                         sensor_column, model_levels_df)\n",
    "        \n",
    "        \"\"\"\n",
    "        answer = input('Do you want to see the vertical interpolation for one location? Yes or No:')\n",
    "        \n",
    "        if answer == 'Yes':\n",
    "            scanline_value = input('Show interpolation for one scanline: ')\n",
    "            ground_pixel_value = input('Show interpolation for one ground_pixel: ')\n",
    "            visualize_interpolation(match_df_visualize, scanline_value, ground_pixel_value, model_levels_df, component_nom)\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "        \"\"\"\n",
    "    \n",
    "    # Calculate values to generate CAMS column to sum in the next step\n",
    "    if 'apriori_profile' in match_df.columns:\n",
    "        match_df['model_column'] = match_df.apply(lambda row: row['apriori_profile'] +\n",
    "                                                              row['column_kernel'] * row['model_component']  -\n",
    "                                                              row['column_kernel'] * row['apriori_profile'], \n",
    "                                                              axis = 1)\n",
    "    \n",
    "    else:\n",
    "        match_df['model_column'] = match_df.apply(lambda row: row['column_kernel'] * row['model_component'], \n",
    "                                                              axis = 1)\n",
    "\n",
    "    return match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_kernels_nearest_neighbours(match_df, model_ds_time, model_levels_df):\n",
    "\n",
    "    \"\"\" Nearest neighbours method: Find the nearest neighbours in the observation space (in pressures, latitude and longitudes)\n",
    "\n",
    "        Args:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "            model_ds_time (xarray): Model levels dataset in xarray format per time\n",
    "            model_levels_df (dataframe): Table with 137 CAMS levels data\n",
    "        \n",
    "        Returns:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "    \"\"\"\n",
    "    \n",
    "    model_pressures = model_levels_df['ph [Pa]'].to_numpy()\n",
    "    model_times = model_ds_time.valid_time.data\n",
    "\n",
    "    match_df['lay_index'] = match_df.apply(lambda row: nearest_neighbour(model_pressures, row['pressure']), axis = 1)\n",
    "    match_df['step_index'] = match_df.apply(lambda row: nearest_neighbour(model_times, row['delta_time']), axis = 1)\n",
    "    match_df['model_time'] = match_df.apply(lambda row: model_ds_time.valid_time[row['step_index']].values, axis = 1)\n",
    "\n",
    "    match_df['model_component'] = match_df.apply(lambda row: model_ds_time.component.sel( \n",
    "                                                            latitude = row['latitude'], \n",
    "                                                            longitude = row['longitude'], \n",
    "                                                            method = 'nearest').isel(hybrid = int(row['lay_index']), \n",
    "                                                            step = int(row['step_index'])).values, \n",
    "                                                            axis = 1)\n",
    "    \n",
    "    return match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_kernels_vertical_interpolation(match_df, model_ds_time, sensor_ds_time, sensor_column, model_levels_df):\n",
    "\n",
    "    \"\"\" Interpolation: Find the nearest neighbours in the observation space (in latitude and longitudes) and \n",
    "        interpolate values in pressure\n",
    "\n",
    "        Args:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "            model_ds_time (xarray): Model levels dataset in xarray format per time\n",
    "            sensor_ds_time (xarray): TROPOMI dataset in xarray format per time\n",
    "            sensor_column (str): Name of sensor column in downloaded dataset\n",
    "            model_levels_df (dataframe): Table with 137 CAMS levels data\n",
    "        \n",
    "        Returns:\n",
    "            match_df (dataframe): Dataframe used to apply averaging kernels\n",
    "            match_df_visualize (dataframe): Dataframe used to apply averaging kernels with interpolated values\n",
    "    \"\"\"\n",
    "    \n",
    "    sensor_coords_df = TROPOMI_subset_coords(sensor_ds_time)\n",
    "\n",
    "    match_df = match_df.set_index('pressure', append = True)\n",
    "\n",
    "    # Create index that includes CAMS pressure levels for all the locations in TROPOMI\n",
    "    new_index = pd.MultiIndex.from_product([match_df.index.levels[0], \n",
    "                                            match_df.index.levels[1],\n",
    "                                            match_df.index.levels[2],\n",
    "                                            model_levels_df['ph [Pa]'].to_numpy()],\n",
    "                                            names = ['scanline', 'ground_pixel', 'time', 'pressure'])\n",
    "    \n",
    "    # Append original and new indexes and reindex dataframe\n",
    "    match_df = match_df[~match_df.index.duplicated()]\n",
    "    match_df = match_df.reindex(match_df.index.append(new_index))\n",
    "    \n",
    "    # Sort and reset index\n",
    "    match_df = match_df.sort_index()\n",
    "    match_df = match_df.reset_index()\n",
    "\n",
    "    # Find latitudes in CAMS rows with scanlines and ground pixels\n",
    "    match_df['latitude'] = match_df.apply(lambda row: float(sensor_coords_df[\n",
    "                                                            (sensor_coords_df['scanline'] == row['scanline']) & \n",
    "                                                            (sensor_coords_df['ground_pixel'] == row['ground_pixel'])]['latitude'])\n",
    "                                                            if pd.isnull(row['latitude']) else row['latitude'], \n",
    "                                                            axis = 1)\n",
    "                                                            \n",
    "    # Find longitudes in CAMS rows with scanlines and ground pixels\n",
    "    match_df['longitude'] = match_df.apply(lambda row: float(sensor_coords_df[\n",
    "                                                            (sensor_coords_df['scanline'] == row['scanline']) & \n",
    "                                                            (sensor_coords_df['ground_pixel'] == row['ground_pixel'])]['longitude'])\n",
    "                                                            if pd.isnull(row['longitude']) else row['longitude'], \n",
    "                                                            axis = 1)\n",
    "                                                            \n",
    "    # Find hybrids in CAMS rows from 137 models table\n",
    "    match_df['hybrid'] = match_df.apply(lambda row: nearest_neighbour(model_levels_df['ph [Pa]'].to_numpy(), row['pressure']) + 1\n",
    "                                                    if pd.isnull(row['sensor_column']) else math.nan, \n",
    "                                                    axis = 1)\n",
    "\n",
    "    # Get unique timestep\n",
    "    sensor_times = sensor_ds_time.delta_time.isel(scanline = 0).values\n",
    "    model_times = model_ds_time.valid_time.values\n",
    "    unique_step = int(np.unique(nearest_neighbour(model_times, sensor_times)))\n",
    "    unique_time = model_ds_time.component.isel(step = unique_step).step.values.astype('timedelta64[h]')\n",
    "\n",
    "    # Get CAMS component data at nearby TROPOMI locations (nearest neighbours)\n",
    "    # Do it only for CAMS rows\n",
    "    match_df['model_component'] = match_df.apply(lambda row: model_ds_time.component.sel(\n",
    "                                                            hybrid = row['hybrid'], \n",
    "                                                            latitude = row['latitude'], \n",
    "                                                            longitude = row['longitude'], \n",
    "                                                            step = unique_time, method = 'nearest').values \n",
    "                                                            if pd.isnull(row['sensor_column']) else math.nan,\n",
    "                                                            axis = 1)\n",
    "\n",
    "    # Transform 1D-array data to float\n",
    "    match_df['model_component'] = match_df['model_component'].apply(lambda x: float(x))\n",
    "\n",
    "    # Set multiindex again and sort\n",
    "    match_df = match_df.set_index(['time', 'pressure', 'scanline', 'ground_pixel'])\n",
    "    match_df = match_df.sort_values(['time', 'ground_pixel','scanline', 'pressure'], \n",
    "                                    ascending = [True, True, True, False])\n",
    "\n",
    "    # Interpolation\n",
    "    match_df['model_component'] = match_df['model_component'].interpolate()\n",
    "\n",
    "    # Show vertical interpolation for one location\n",
    "    match_df_visualize = match_df\n",
    "\n",
    "    # Drop unnecessary values\n",
    "    match_df = match_df.drop(model_levels_df['ph [Pa]'].to_numpy(), level = 'pressure')\n",
    "    \n",
    "    model_times = model_ds_time.valid_time.data\n",
    "    match_df['step_index'] = match_df.apply(lambda row: nearest_neighbour(model_times, row['delta_time']), axis = 1)\n",
    "\n",
    "    # Reset pressure index\n",
    "    match_df = match_df.reset_index('pressure')\n",
    "\n",
    "    return match_df, match_df_visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_interpolation(match_df_visualize, scanline_value, ground_pixel_value, model_levels_df, component_nom):\n",
    "\n",
    "    \"\"\" Visualize interpolated partial columns of the model for a specific location given a scanline and ground pixel\n",
    "\n",
    "        Args:\n",
    "            match_df_visualize (dataframe): Dataframe used to apply averaging kernels with interpolated values\n",
    "            scanline_value (int): Specific location scanline\n",
    "            ground_pixel_value (int): Specific location ground pixel\n",
    "            model_levels_df (dataframe): Table with 137 CAMS levels data\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "    \"\"\"\n",
    "\n",
    "    units = component_nom + ' (' + model_ds.component.units + ')'\n",
    "\n",
    "    # Query to get data for one location\n",
    "    small = match_df.query('scanline == @scanline_value and ground_pixel == @ground_pixel_value')\n",
    "\n",
    "    # Get pressure data\n",
    "    all_pressures = small.index.get_level_values(1).to_numpy()\n",
    "    model_pressures = model_levels_df['ph [Pa]'].to_numpy()\n",
    "\n",
    "    # Show in black original values and in red the interpolated pressures\n",
    "    diff_colors = np.where(np.isin(all_pressures, model_pressures), 'black', \n",
    "                           np.where(~np.isin(all_pressures, model_pressures), 'red', 'yellow'))\n",
    "\n",
    "    # Show component vs. pressures\n",
    "    plt.scatter(small['model_component'], all_pressures, c = diff_colors, s = 10)\n",
    "\n",
    "    # Revert yaxis to have surface pressure on the bottom\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    ax.set_xlabel(units, fontsize = 18)\n",
    "    ax.set_ylabel('Pressure (Pa)', fontsize = 18)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84d6139589c0d952b978fb9437b8e11e4e03996aa73ed56a307e4c0ad5e273d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env-new': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
