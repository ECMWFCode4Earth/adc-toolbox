{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOME-2 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GOME_L3_version(component_nom, year, month):\n",
    "\n",
    "    \"\"\" Get version of L3 GOME-2 dataset for each component nomenclature\n",
    "\n",
    "         Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            year (str): Year of dataset\n",
    "            month (str): Month of dataset\n",
    "\n",
    "        Returns:\n",
    "            version (str): GOME-2 dataset version\n",
    "    \"\"\"\n",
    "    \n",
    "    year = int(year)\n",
    "    month = int(month)\n",
    "    \n",
    "    if component_nom == 'NO2':\n",
    "        version = 'v1'\n",
    "\n",
    "    return version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GOME_L3_download(component_nom, date, satellite):\n",
    "\n",
    "    \"\"\" Download L3 GOME-2 datasets\n",
    "\n",
    "        Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            date (str): Query date\n",
    "            satellites (list): List with A, B and/or C referring to METOP series\n",
    "\n",
    "        Returns:\n",
    "            product_name (str): Product name of GOME-2 product\n",
    "    \"\"\"\n",
    "    \n",
    "    year = date.split('-')[0]\n",
    "    month = date.split('-')[1]\n",
    "    version = GOME_L3_version(component_nom, year, month)\n",
    "\n",
    "    output_path = 'data/gome/' + component_nom + '/monthly/' + year + '-' + month\n",
    "    os.makedirs(output_path, exist_ok = True) \n",
    "\n",
    "    product_name = ''.join(['GOME_', component_nom, '_Global_', year, month, '_METOP' + satellite + '_DLR_', version, '.nc'])\n",
    "    path = 'ftp://acsaf.eoc.dlr.de/gome2' + satellite.lower() + '/level3/' + component_nom + '/' + year + '/' + product_name\n",
    "   \n",
    "    file_name = output_path + '/' + product_name\n",
    "    subprocess.run(['wget', '-q', '-nc', path, '-O', file_name])\n",
    "\n",
    "    if os.stat(file_name).st_size == 0:  \n",
    "        os.remove(file_name) \n",
    "        print(product_name, 'is not available.')\n",
    "        \n",
    "    else:\n",
    "        print(product_name, 'was downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GOME_L3_read(component_nom, sensor_column, dates, lat_res = 0.25, lon_res = 0.25):\n",
    "\n",
    "    \"\"\" Read L3 GOME-2 datasets as xarray dataset object and assign time\n",
    "\n",
    "         Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor_column (str): Name of sensor column in downloaded dataset\n",
    "            dates (list): Available dates\n",
    "            lat_res (float): Spatial resolution for latitude\n",
    "            lon_res (float): Spatial resolution for longitude\n",
    "\n",
    "        Returns:\n",
    "            sensor_ds (xarray): GOME-2 dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if lat_res < 0.25 or lon_res < 0.25:\n",
    "        print('To show the original data, the resolution must equal to 1x1ยบ.')\n",
    "        print('To show aggregated data, the resolution must be superior to 1x1ยบ.')\n",
    "        raise KeyboardInterrupt()\n",
    "\n",
    "    sensor_ds_all = []\n",
    "\n",
    "    for date in dates:\n",
    "\n",
    "        year = date.split('-')[0]\n",
    "        month = date.split('-')[1]\n",
    "\n",
    "        sensor_ds_ABC = []\n",
    "\n",
    "        # Combine data from METOP-A, METOP-B and METOP-C\n",
    "        path = 'data/gome/' + component_nom + '/monthly/' + year + '-' + month\n",
    "        product_names = [file for file in os.listdir(path)]\n",
    "        \n",
    "        for product_name in product_names:\n",
    "            \n",
    "            sensor_ds_sat = xr.open_dataset(path + '/' + product_name)\n",
    "            sensor_ds_int_sat = xr.open_dataset(path + '/' + product_name, group = 'PRODUCT')\n",
    "            sensor_ds_sat[sensor_column] = sensor_ds_int_sat[sensor_column]\n",
    "            unit = sensor_ds_sat[sensor_column].units\n",
    "            sensor_ds_ABC.append(sensor_ds_sat)\n",
    "\n",
    "        sensor_ds_ABC = xr.concat(sensor_ds_ABC, dim = 'latitude')\n",
    "\n",
    "        # Regrid onto a custom defined regular grid\n",
    "        lat_bins = np.arange(-90, 90 + lat_res/2, lat_res)\n",
    "        lon_bins = np.arange(-180, 180 + lon_res/2, lon_res)\n",
    "        \n",
    "        lat_center = np.arange(-90 + lat_res/2, 90, lat_res)\n",
    "        lon_center = np.arange(-180 + lon_res/2, 180, lon_res)\n",
    "\n",
    "        sensor_ds_ABC_gridded_int = sensor_ds_ABC.groupby_bins('latitude', lat_bins, labels = lat_center).mean()\n",
    "        sensor_ds_ABC_gridded = sensor_ds_ABC_gridded_int.groupby_bins('longitude', lon_bins, labels = lon_center).mean()\n",
    "        sensor_ds_ABC_gridded = sensor_ds_ABC_gridded.rename({'latitude_bins': 'latitude', 'longitude_bins': 'longitude'})\n",
    "\n",
    "        # Add time\n",
    "        time_str = dt.datetime(int(year), int(month), 1)\n",
    "        sensor_ds_ABC_gridded = sensor_ds_ABC_gridded.assign_coords({'time': time_str}).expand_dims(dim = ['time'])\n",
    "\n",
    "        # Add units as attribute\n",
    "        sensor_ds_ABC_gridded.attrs['units'] = unit\n",
    "\n",
    "        sensor_ds_all.append(sensor_ds_ABC_gridded)\n",
    "        \n",
    "    sensor_ds = xr.concat(sensor_ds_all, dim = 'time')\n",
    "    sensor_ds = sensor_ds.rename({sensor_column: 'sensor_column'})\n",
    "    \n",
    "    return sensor_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GOME_L2_download(component_nom, date, satellite):\n",
    "\n",
    "    \"\"\" Download L2 GOME-2 datasets\n",
    "\n",
    "         Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            date (str): Query date\n",
    "            satellites (list): List with A, B and/or C referring to METOP series\n",
    "    \"\"\"\n",
    "    \n",
    "    output_path = 'data/gome/' + component_nom + '/' + date + '/' + satellite\n",
    "    os.makedirs(output_path, exist_ok = True) \n",
    "\n",
    "    # Get year, month and day from date\n",
    "    year = date.split('-')[0]\n",
    "    month = date.split('-')[1]\n",
    "    day = date.split('-')[2]\n",
    "\n",
    "    # Save index.html with available offline products through FTP for specific date\n",
    "    date_path = 'ftp://acsaf.eoc.dlr.de/gome2' + satellite.lower() + '/offline/' + year + '/' + month + '/' + day + '/'\n",
    "    date_url = 'data/gome/' + component_nom + '/' + 'index.html'\n",
    "    subprocess.run(['wget', '-q', '-O', date_url, '-i', date_path])\n",
    "\n",
    "    # Download all files for date and satellite\n",
    "    if os.stat('data/gome/' + component_nom + '/' + 'index.html').st_size != 0:  \n",
    "            \n",
    "        # Read index.html and get content within pre tabs\n",
    "        html_text = open('data/gome/' + component_nom + '/' + 'index.html', 'r')\n",
    "        items_int = bs4.BeautifulSoup(html_text, 'lxml').pre.get_text().splitlines()[1:]\n",
    "        items = [item_int.split('File        ', 1)[1].split('  (', 1)[0] for item_int in items_int]\n",
    "\n",
    "        for product_name in items:\n",
    "            \n",
    "            file_name = output_path + '/' + product_name\n",
    "            path = 'ftp://acsaf.eoc.dlr.de/gome2' + satellite.lower() + '/offline/' + year + '/' + month + '/' + day + '/' + product_name\n",
    "            subprocess.run(['wget', '-q', '-nc', path, '-O', file_name])\n",
    "\n",
    "            if os.stat(file_name).st_size == 0:  \n",
    "                os.remove(file_name) \n",
    "                print(product_name, 'is not available.')\n",
    "                \n",
    "            else:\n",
    "                print(product_name, 'was downloaded.')\n",
    "    else:\n",
    "        print(f'The datasets for {date} and METOP-{satellite} are not available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GOME_L2_read(component_nom, sensor_column, dates, satellites, lat_res = 0.25, lon_res = 0.25):\n",
    "\n",
    "    \"\"\" Read L2 GOME-2 datasets as xarray dataset object and assign time\n",
    "\n",
    "         Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor_column (str): Name of sensor column in downloaded dataset\n",
    "            dates (list): Available dates\n",
    "            satellites (list): List with A, B and/or C referring to METOP series\n",
    "            lat_res (float): Spatial resolution for latitude\n",
    "            lon_res (float): Spatial resolution for longitude\n",
    "            \n",
    "        Returns:\n",
    "            sensor_ds (xarray): GOME-2 dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if lat_res < 0.25 or lon_res < 0.25:\n",
    "        print('To show the original data, the resolution must equal to 1x1ยบ.')\n",
    "        print('To show aggregated data, the resolution must be superior to 1x1ยบ.')\n",
    "        raise KeyboardInterrupt()\n",
    "\n",
    "    sensor_ds_all = []\n",
    "\n",
    "    # Concatenate all the products for different dates\n",
    "    for date in dates:\n",
    "\n",
    "        year = date.split('-')[0]\n",
    "        month = date.split('-')[1]\n",
    "        day = date.split('-')[2]\n",
    "        \n",
    "        sensor_ds_ABC = []\n",
    "\n",
    "        # Concatenate all the products for METOP-A, B and C\n",
    "        for satellite in os.listdir('data/gome/' + component_nom + '/' + date):\n",
    "\n",
    "            sensor_ds_sat_daily = []\n",
    "            path = 'data/gome/' + component_nom + '/' + date + '/' + satellite\n",
    "            product_names = [file for file in os.listdir(path)]\n",
    "            \n",
    "            # Concatenate all the products for different delta times\n",
    "            for product_name in product_names:\n",
    "\n",
    "                f = h5py.File(path + '/' + product_name, 'r')\n",
    "                f['TOTAL_COLUMNS/' + component_nom]\n",
    "\n",
    "                latitude = f['GEOLOCATION/LatitudeCentre']\n",
    "                longitude = f['GEOLOCATION/LongitudeCentre']\n",
    "\n",
    "                # Get component for one delta time \n",
    "                sensor_ds_sat_time = xr.DataArray(\n",
    "                                                f['TOTAL_COLUMNS/' + component_nom],\n",
    "                                                dims = ('ground_pixel'),\n",
    "                                                coords = {\n",
    "                                                    'latitude': ('ground_pixel', latitude[:]),\n",
    "                                                    'longitude': ('ground_pixel', longitude[:])\n",
    "                                                },\n",
    "                                                name = component_nom\n",
    "                )\n",
    "                \n",
    "                # Get delta time from product name and add it as a variable\n",
    "                delta_time_str_int = product_name.split(date.replace('-', ''), 1)[1].split('_', 1)[0]\n",
    "                delta_time_str = [delta_time_str_int[i:i+2] for i in range(0, len(delta_time_str_int), 2)]\n",
    "                delta_time_hour = delta_time_str[0]\n",
    "                delta_time_minute = delta_time_str[1]\n",
    "                delta_time_second = delta_time_str[2]\n",
    "            \n",
    "                delta_time = dt.datetime(int(year), int(month), int(day), \n",
    "                                                                int(delta_time_hour), int(delta_time_minute), \n",
    "                                                                int(delta_time_second))\n",
    "\n",
    "                sensor_ds_delta_time = xr.DataArray(np.repeat(delta_time, len(sensor_ds_sat_time.ground_pixel)),\n",
    "                                                    dims = ('ground_pixel'),\n",
    "                                                    coords = {\n",
    "                                                        'latitude': ('ground_pixel', latitude[:]),\n",
    "                                                        'longitude': ('ground_pixel', longitude[:])\n",
    "                                                    },\n",
    "                                                    name = 'delta_time'\n",
    "                )\n",
    "\n",
    "                # Merge both variables (component and delta time)\n",
    "                sensor_ds_sat_time = xr.merge([sensor_ds_sat_time, sensor_ds_delta_time])\n",
    "                sensor_ds_sat_daily.append(sensor_ds_sat_time)\n",
    "            \n",
    "            sensor_ds_sat_daily = xr.concat(sensor_ds_sat_daily, dim = 'ground_pixel')\n",
    "            \n",
    "        sensor_ds_ABC = xr.concat([sensor_ds_sat_daily], dim = 'ground_pixel')\n",
    "\n",
    "        sensor_ds_ABC = sensor_ds_ABC.assign_coords(longitude = (((sensor_ds_ABC.longitude + 180) % 360) - 180))\n",
    "\n",
    "        y = sensor_ds_ABC.latitude.data\n",
    "        x = sensor_ds_ABC.longitude.data\n",
    "        z = sensor_ds_ABC[component_nom].data\n",
    "\n",
    "        zi, yi, xi = np.histogram2d(y, x, bins = (180, 360), weights = z, normed = False)\n",
    "        counts, _, _ = np.histogram2d(y, x, bins = (180, 360))\n",
    "        zi = zi / counts\n",
    "        \n",
    "        sensor_ds_ABC_gridded = xr.DataArray(\n",
    "                                            zi,\n",
    "                                            dims = ['latitude', 'longitude'],\n",
    "                                            coords = {\n",
    "                                                'latitude': (['latitude'], yi[:-1]),\n",
    "                                                'longitude': (['longitude'], xi[:-1])\n",
    "                                            },\n",
    "                                            name = 'sensor_column'\n",
    "        )\n",
    "\n",
    "        # Regrid onto a custom defined regular grid\n",
    "        lat_bins = np.arange(-90, 90 + lat_res/2, lat_res)\n",
    "        lon_bins = np.arange(-180, 180 + lon_res/2, lon_res)\n",
    "        \n",
    "        lat_center = np.arange(-90 + lat_res/2, 90, lat_res)\n",
    "        lon_center = np.arange(-180 + lon_res/2, 180, lon_res)\n",
    "\n",
    "        sensor_ds_ABC_gridded_int = sensor_ds_ABC_gridded.groupby_bins('latitude', lat_bins, labels = lat_center).mean()\n",
    "        sensor_ds_ABC_gridded = sensor_ds_ABC_gridded_int.groupby_bins('longitude', lon_bins, labels = lon_center).mean()\n",
    "        sensor_ds_ABC_gridded = sensor_ds_ABC_gridded.rename({'latitude_bins': 'latitude', 'longitude_bins': 'longitude'})\n",
    "\n",
    "        # Get datafame with delta time (non-gridded)\n",
    "        delta_time_df = pd.DataFrame()\n",
    "        delta_time_df['ground_pixel'] = sensor_ds_ABC.ground_pixel\n",
    "        delta_time_df['latitude'] = delta_time_df.apply(lambda row: sensor_ds_ABC.sel(ground_pixel = row['ground_pixel']).latitude.values, axis = 1)\n",
    "        delta_time_df['longitude'] = delta_time_df.apply(lambda row: sensor_ds_ABC.sel(ground_pixel = row['ground_pixel']).longitude.values, axis = 1)\n",
    "        delta_time_df['delta_time'] = delta_time_df.apply(lambda row: sensor_ds_ABC.sel(ground_pixel = row['ground_pixel']).delta_time.values, axis = 1)\n",
    "        \n",
    "        # Round latitude and longitude to 0 decimals\n",
    "        delta_time_df_rounded = delta_time_df\n",
    "        delta_time_df_rounded['latitude_rounded'] = [round(value.item(0)) for value in delta_time_df_rounded['latitude'].values]\n",
    "        delta_time_df_rounded['longitude_rounded'] = [round(value.item(0)) for value in delta_time_df_rounded['longitude'].values]\n",
    "        delta_time_df_rounded\n",
    "\n",
    "        # Get datafame without delta time (gridded)\n",
    "        delta_time_df_gridded = sensor_ds_ABC_gridded.to_dataframe()\n",
    "        delta_time_df_gridded = delta_time_df_gridded.reset_index()\n",
    "\n",
    "        # Round latitude and longitude to 0 decimals\n",
    "        delta_time_df_gridded_rounded = delta_time_df_gridded\n",
    "        delta_time_df_gridded_rounded['latitude_rounded'] = round(delta_time_df_gridded_rounded['latitude'])\n",
    "        delta_time_df_gridded_rounded['longitude_rounded'] = round(delta_time_df_gridded_rounded['longitude'])\n",
    "\n",
    "        # Order dataframes before merge\n",
    "        delta_time_df_gridded_rounded = delta_time_df_gridded_rounded.sort_values(by = ['latitude_rounded', 'longitude_rounded'])\n",
    "        delta_time_df_rounded = delta_time_df_rounded.drop(columns = 'ground_pixel').sort_values(by = ['latitude_rounded', 'longitude_rounded'])\n",
    "        \n",
    "        # Merge and clean\n",
    "        final = pd.merge(delta_time_df_gridded_rounded, delta_time_df_rounded, \n",
    "                         on= ['latitude_rounded', 'longitude_rounded'], how = 'left')\n",
    "        final = final[~(final.delta_time.isnull() & final['sensor_column'].notnull())]\n",
    "        final = final.drop(columns = ['latitude_rounded', 'longitude_rounded', 'latitude_y', 'longitude_y'])\n",
    "        final = final.rename({'latitude_x': 'latitude', 'longitude_x': 'longitude'}, axis = 1)\n",
    "        final = final.set_index(['latitude', 'longitude'])\n",
    "        final = final[~final.index.duplicated()].to_xarray()\n",
    "        \n",
    "        # Assign day as time\n",
    "        time_str = dt.datetime(int(year), int(month), int(day))\n",
    "        final = final.assign_coords({'time': time_str}).expand_dims(dim = ['time'])\n",
    "\n",
    "        sensor_ds_all.append(final)\n",
    "\n",
    "    sensor_ds = xr.concat(sensor_ds_all, dim = 'time')\n",
    "   \n",
    "    return sensor_ds"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc2967d46b8688a8c6de8a18a3daae8ebe0b7dc5d18d27687b3fe01b2a6426f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env-new': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
