{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GOME-2 functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def GOME_L3_version(component_nom, year, month):\n",
    "\n",
    "    \"\"\" Get version of GOME-2 dataset for each component nomenclature\n",
    "\n",
    "         Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            year (str): Year of dataset\n",
    "            month (str): Month of dataset\n",
    "\n",
    "        Returns:\n",
    "            version (str): GOME-2 dataset version\n",
    "    \"\"\"\n",
    "    \n",
    "    year = int(year)\n",
    "    month = int(month)\n",
    "    \n",
    "    if component_nom == 'NO2':\n",
    "        version = 'v1'\n",
    "\n",
    "    return version"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def GOME_L3_download(component_nom, date, satellite):\n",
    "\n",
    "    \"\"\" Download L3 GOME-2 datasets\n",
    "\n",
    "         Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            date (str): Query year-month\n",
    "            satellites (list): List with A, B and/or C referring to METOP series\n",
    "\n",
    "        Returns:\n",
    "            product_name (str): Product name of GOME-2 product\n",
    "    \"\"\"\n",
    "\n",
    "    output_path = 'data/gome/' + component_nom + '/monthly/' + satellite\n",
    "    os.makedirs(output_path, exist_ok = True) \n",
    "\n",
    "    year = date.split('-')[0]\n",
    "    month = date.split('-')[1]\n",
    "    version = GOME_L3_version(component_nom, year, month)\n",
    "\n",
    "    product_name = ''.join(['GOME_', component_nom, '_Global_', year, month, '_METOP' + satellite + '_DLR_', version, '.nc'])\n",
    "    path = 'ftp://acsaf.eoc.dlr.de/gome2' + satellite.lower() + '/level3/' + component_nom + '/' + year + '/' + product_name\n",
    "    \n",
    "    url = output_path + '/' + product_name\n",
    "    subprocess.run(['wget', '-nc', path, '-O', url])\n",
    "\n",
    "    return product_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def GOME_L3_read(dates, component_nom, sensor_column, satellites):\n",
    "\n",
    "    \"\"\" Read L3 GOME-2 datasets as xarray dataset object and assign time\n",
    "\n",
    "         Args:\n",
    "            dates (list): Query year-month\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor_column (str): Name of sensor column in downloaded dataset\n",
    "            satellites (list): List with A, B and/or C referring to METOP series\n",
    "\n",
    "        Returns:\n",
    "            sensor_ds (xarray): GOME-2 dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    sensor_ds_all = []\n",
    "\n",
    "    for date in dates:\n",
    "        \n",
    "        year = date.split('-')[0]\n",
    "        month = date.split('-')[1]\n",
    "\n",
    "        sensor_ds_ABC = []\n",
    "\n",
    "        # Combine data from METOP-A, METOP-B and METOP-C\n",
    "        for satellite in satellites:\n",
    "        \n",
    "            path = 'data/gome/' + component_nom + '/monthly/' + satellite\n",
    "            product_names = [file for file in os.listdir(path)]\n",
    "            \n",
    "            for product_name in product_names:\n",
    "\n",
    "                sensor_ds_sat = xr.open_dataset(path + '/' + product_name)\n",
    "                sensor_ds_int_sat = xr.open_dataset(path + '/' + product_name, group = 'PRODUCT')\n",
    "                sensor_ds_sat[sensor_column] = sensor_ds_int_sat[sensor_column]\n",
    "\n",
    "                sensor_ds_ABC.append(sensor_ds_sat)\n",
    "\n",
    "        sensor_ds_ABC = xr.concat(sensor_ds_ABC, dim = 'latitude')\n",
    "        time_str = dt.datetime(int(year), int(month), 1)\n",
    "        sensor_ds_ABC = sensor_ds_ABC.assign_coords({'time': time_str}).expand_dims(dim = ['time'])\n",
    "        sensor_ds_all.append(sensor_ds_ABC)\n",
    "\n",
    "    sensor_ds = xr.merge(sensor_ds_all)\n",
    "        \n",
    "    return sensor_ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def GOME_L2_download(component_nom, date, satellite):\n",
    "\n",
    "    \"\"\" Download L2 GOME-2 datasets\n",
    "\n",
    "         Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            date (str): Query year-month\n",
    "            satellites (list): List with A, B and/or C referring to METOP series\n",
    "    \"\"\"\n",
    "\n",
    "    output_path = 'data/gome/' + component_nom + '/' + date + '/' + satellite\n",
    "    os.makedirs(output_path, exist_ok = True) \n",
    "\n",
    "    # Get year, month and day from date\n",
    "    year = date.split('-')[0]\n",
    "    month = date.split('-')[1]\n",
    "    day = date.split('-')[2]\n",
    "\n",
    "    # Save index.html with available offline products through FTP for specific date\n",
    "    date_path = 'ftp://acsaf.eoc.dlr.de/gome2' + satellite.lower() + '/offline/' + year + '/' + month + '/' + day + '/'\n",
    "    date_url = 'data/gome/' + component_nom + '/' + 'index.html'\n",
    "    subprocess.run(['wget', '-O', date_url, '-i', date_path])\n",
    "\n",
    "    # Read index.html and get content within pre tabs\n",
    "    html_text = open('data/gome/' + component_nom + '/' + 'index.html', 'r')\n",
    "    items_int = bs4.BeautifulSoup(html_text, 'lxml').pre.get_text().splitlines()[1:-1]\n",
    "    items = [item_int.split('File        ', 1)[1].split('  (', 1)[0] for item_int in items_int]\n",
    "\n",
    "    # Download all files for date and satellite\n",
    "    for product_name in items:\n",
    "        \n",
    "        url = output_path + '/' + product_name\n",
    "        path = 'ftp://acsaf.eoc.dlr.de/gome2' + satellite.lower() + '/offline/' + year + '/' + month + '/' + day + '/' + product_name\n",
    "        subprocess.run(['wget', '-nc', path, '-O', url])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def GOME_L2_read(dates, component_nom, sensor_column, satellites):\n",
    "\n",
    "    \"\"\" Read L2 GOME-2 datasets as xarray dataset object and assign time\n",
    "\n",
    "         Args:\n",
    "            dates (list): Query year-month\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor_column (str): Name of sensor column in downloaded dataset\n",
    "            satellites (list): List with A, B and/or C referring to METOP series\n",
    "            \n",
    "        Returns:\n",
    "            sensor_ds (xarray): GOME-2 dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    sensor_ds_all = []\n",
    "\n",
    "    # Concatenate all the products for different dates\n",
    "    for date in dates:\n",
    "\n",
    "        year = date.split('-')[0]\n",
    "        month = date.split('-')[1]\n",
    "        day = date.split('-')[2]\n",
    "        \n",
    "        sensor_ds_ABC = []\n",
    "\n",
    "        # Concatenate all the products for METOP-A, B and C\n",
    "        for satellite in satellites:\n",
    "\n",
    "            sensor_ds_sat_daily = []\n",
    "\n",
    "            path = 'data/gome/' + component_nom + '/' + date + '/' + satellite\n",
    "            product_names = [file for file in os.listdir(path)]\n",
    "            \n",
    "            # Concatenate all the products for different hours\n",
    "            for product_name in product_names:\n",
    "\n",
    "                f = h5py.File('data/gome/' + component_nom + '/' + date + '/' + satellite + '/' + product_name, 'r')\n",
    "                f['TOTAL_COLUMNS/' + component_nom]\n",
    "\n",
    "                latitude = f['GEOLOCATION/LatitudeCentre']\n",
    "                longitude = f['GEOLOCATION/LongitudeCentre']\n",
    "\n",
    "                sensor_ds_sat_time = xr.DataArray(\n",
    "                                                f['TOTAL_COLUMNS/' + component_nom],\n",
    "                                                dims = ('ground_pixel'),\n",
    "                                                coords = {\n",
    "                                                    'latitude': ('ground_pixel', latitude[:]),\n",
    "                                                    'longitude': ('ground_pixel', longitude[:])\n",
    "                                                },\n",
    "                                                name = component_nom\n",
    "                )\n",
    "\n",
    "                sensor_ds_sat_daily.append(sensor_ds_sat_time)\n",
    "            \n",
    "            sensor_ds_sat_daily = xr.concat(sensor_ds_sat_daily, dim = 'ground_pixel')\n",
    "        \n",
    "        sensor_ds_ABC = xr.concat(sensor_ds_sat_daily, dim = 'ground_pixel')\n",
    "\n",
    "        sensor_ds_ABC = sensor_ds_ABC.assign_coords(longitude = (((sensor_ds_ABC.longitude + 180) % 360) - 180))\n",
    "\n",
    "        y = sensor_ds_ABC.latitude.data\n",
    "        x = sensor_ds_ABC.longitude.data\n",
    "        z = sensor_ds_ABC.data\n",
    "\n",
    "        zi, yi, xi = np.histogram2d(y, x, bins = (180, 360), weights = z, normed = False)\n",
    "        counts, _, _ = np.histogram2d(y, x, bins = (180, 360))\n",
    "        zi = zi / counts\n",
    "        \n",
    "        sensor_ds_ABC_gridded = xr.DataArray(\n",
    "                                            zi,\n",
    "                                            dims = ['latitude', 'longitude'],\n",
    "                                            coords = {\n",
    "                                                'latitude': (['latitude'], yi[:-1]),\n",
    "                                                'longitude': (['longitude'], xi[:-1])\n",
    "                                            },\n",
    "                                            name = sensor_column\n",
    "        )\n",
    "        \n",
    "        time_str = dt.datetime(int(year), int(month), int(day))\n",
    "        sensor_ds_ABC_gridded = sensor_ds_ABC_gridded.assign_coords({'time': time_str}).expand_dims(dim = ['time'])\n",
    "        sensor_ds_ABC_gridded = sensor_ds_ABC_gridded.to_dataset()\n",
    "        sensor_ds_all.append(sensor_ds_ABC_gridded)\n",
    "\n",
    "    sensor_ds = xr.concat(sensor_ds_all, dim = 'time')\n",
    "   \n",
    "    return sensor_ds"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('env-new': venv)"
  },
  "interpreter": {
   "hash": "84d6139589c0d952b978fb9437b8e11e4e03996aa73ed56a307e4c0ad5e273d4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}