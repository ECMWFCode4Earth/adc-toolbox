{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOME-2 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GOME_L3_version_AC_SAF(component_nom, year, month):\n",
    "\n",
    "    \"\"\" Get version of L3 GOME-2 dataset for each component nomenclature (AC SAF)\n",
    "\n",
    "         Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            year (str): Year of dataset\n",
    "            month (str): Month of dataset\n",
    "\n",
    "        Returns:\n",
    "            version (str): GOME-2 dataset version\n",
    "    \"\"\"\n",
    "    \n",
    "    year = int(year)\n",
    "    month = int(month)\n",
    "    \n",
    "    if component_nom == 'NO2':\n",
    "        version = 'v1'\n",
    "\n",
    "    return version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GOME_L3_download_AC_SAF(component_nom, date, satellite):\n",
    "\n",
    "    \"\"\" Download L3 GOME-2 datasets (AC SAF)\n",
    "\n",
    "        Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            date (str): Query date\n",
    "            satellite (str): A, B and/or C referring to METOP series\n",
    "    \"\"\"\n",
    "    \n",
    "    year = date.split('-')[0]\n",
    "    month = date.split('-')[1]\n",
    "    version = GOME_L3_version_AC_SAF(component_nom, year, month)\n",
    "\n",
    "    GOME_product_path = os.path.join('/', '/'.join(\n",
    "                        os.getcwd().split('/')[1:3]), 'adc-toolbox', \n",
    "                        os.path.relpath('data/gome/' + component_nom + '/L3/' + year + '-' + month))\n",
    "    os.makedirs(GOME_product_path, exist_ok = True) \n",
    "\n",
    "    product_name = ''.join(['GOME_', component_nom, '_Global_', year, month, '_METOP' + satellite + '_DLR_', version, '.nc'])\n",
    "    path = 'ftp://acsaf.eoc.dlr.de/gome2' + satellite.lower() + '/level3/' + component_nom + '/' + year + '/' + product_name\n",
    "   \n",
    "    file_name = GOME_product_path + '/' + product_name\n",
    "    subprocess.run(['wget', '-q', '-nc', path, '-O', file_name])\n",
    "\n",
    "    if os.stat(file_name).st_size == 0:  \n",
    "        os.remove(file_name) \n",
    "        print(product_name, 'is not available.')\n",
    "        \n",
    "    else:\n",
    "        print(product_name, 'was downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GOME_L3_read_AC_SAF(component_nom, sensor_column, dates, lat_res = 0.25, lon_res = 0.25):\n",
    "\n",
    "    \"\"\" Read L3 GOME-2 datasets as xarray dataset object and assign time (AC SAF)\n",
    "\n",
    "         Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            sensor_column (str): Name of sensor column in downloaded dataset\n",
    "            dates (list): Available dates\n",
    "            lat_res (float): Spatial resolution for latitude\n",
    "            lon_res (float): Spatial resolution for longitude\n",
    "\n",
    "        Returns:\n",
    "            sensor_ds (xarray): GOME-2 dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if lat_res < 0.25 or lon_res < 0.25:\n",
    "        print('To show the original data, the resolution must equal to 1x1ยบ.')\n",
    "        print('To show aggregated data, the resolution must be superior to 1x1ยบ.')\n",
    "        raise KeyboardInterrupt()\n",
    "\n",
    "    sensor_ds_all = []\n",
    "\n",
    "    for date in dates:\n",
    "\n",
    "        year = date.split('-')[0]\n",
    "        month = date.split('-')[1]\n",
    "\n",
    "        sensor_ds_ABC = []\n",
    "\n",
    "        # Combine data from METOP-A, METOP-B and METOP-C\n",
    "        GOME_product_path = os.path.join('/', '/'.join(\n",
    "                            os.getcwd().split('/')[1:3]), 'adc-toolbox', \n",
    "                            os.path.relpath('data/gome/' + component_nom + '/L3/' + year + '-' + month))\n",
    "        product_names = [file for file in os.listdir(GOME_product_path)]\n",
    "        \n",
    "        for product_name in product_names:\n",
    "            \n",
    "            sensor_ds_sat = xr.open_dataset(GOME_product_path + '/' + product_name)\n",
    "            sensor_ds_int_sat = xr.open_dataset(GOME_product_path + '/' + product_name, group = 'PRODUCT')\n",
    "            sensor_ds_sat[sensor_column] = sensor_ds_int_sat[sensor_column]\n",
    "            unit = sensor_ds_sat[sensor_column].units\n",
    "            sensor_ds_ABC.append(sensor_ds_sat)\n",
    "\n",
    "        sensor_ds_ABC = xr.concat(sensor_ds_ABC, dim = 'latitude')\n",
    "\n",
    "        # Regrid onto a custom defined regular grid\n",
    "        sensor_ds_ABC_gridded = binning(sensor_ds_ABC, lat_res, lon_res) \n",
    "\n",
    "        # Add time\n",
    "        time_str = dt.datetime(int(year), int(month), 1)\n",
    "        sensor_ds_ABC_gridded = sensor_ds_ABC_gridded.assign_coords({'time': time_str}).expand_dims(dim = ['time'])\n",
    "\n",
    "        # Add units as attribute\n",
    "        sensor_ds_ABC_gridded.attrs['units'] = unit\n",
    "\n",
    "        sensor_ds_all.append(sensor_ds_ABC_gridded)\n",
    "        \n",
    "    sensor_ds = xr.concat(sensor_ds_all, dim = 'time')\n",
    "    sensor_ds = sensor_ds.rename({sensor_column: 'sensor_column'})\n",
    "    \n",
    "    return sensor_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GOME_L3_download_TEMIS(component_nom, date, satellite):\n",
    "\n",
    "    \"\"\" Download L3 GOME-2 datasets (TEMIS platform)\n",
    "\n",
    "         Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            date (str): Query date\n",
    "            satellite (str): A, B and/or C referring to METOP series\n",
    "    \"\"\"\n",
    "\n",
    "    year = date.split('-')[0]\n",
    "    month = date.split('-')[1]\n",
    "\n",
    "    if 'C' in satellites:\n",
    "        satellites.remove('C')\n",
    "\n",
    "    for satellite in satellites:\n",
    "\n",
    "        GOME_product_path = os.path.join('/', '/'.join(\n",
    "                                os.getcwd().split('/')[1:3]), 'adc-toolbox', \n",
    "                                os.path.relpath('data/gome/' + component_nom + '/L3/' + year + '-' + month))\n",
    "        os.makedirs(GOME_product_path, exist_ok = True) \n",
    "        product_name = 'GOME_L3_NO2_COLUMN_METOP_' + satellite + '_' + year + month + '.asc.zip'\n",
    "        file_name = GOME_product_path + '/' + product_name\n",
    "\n",
    "        if satellite == 'A':\n",
    "            path = ('https://d1qb6yzwaaq4he.cloudfront.net/airpollution/no2col/gome2_v2/' + year +\n",
    "                    '/' + month + '/' + component_nom.lower() + '_' + year + month + '.asc.zip')\n",
    "        elif satellite == 'B':\n",
    "            path = ('https://d1qb6yzwaaq4he.cloudfront.net/airpollution/no2col/gome2' + satellite.lower() + '/' + year +\n",
    "                    '/' + month + '/' + component_nom.lower() + '_' + year + month + '.asc.zip')\n",
    "\n",
    "        subprocess.run(['wget', '-q', '-nc', path, '-O', GOME_product_path + '/' + product_name])\n",
    "\n",
    "        if os.stat(file_name).st_size == 0:  \n",
    "            os.remove(file_name) \n",
    "            print(product_name, 'is not available.')\n",
    "\n",
    "        else:\n",
    "            print(product_name, 'was downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GOME_L3_read_TEMIS(component_nom, dates, lat_res = 0.25, lon_res = 0.25):\n",
    "\n",
    "    \"\"\" Read L3 GOME-2 datasets as xarray dataset object and assign time (TEMIS)\n",
    "\n",
    "         Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            dates (list): Available dates\n",
    "            lat_res (float): Spatial resolution for latitude\n",
    "            lon_res (float): Spatial resolution for longitude\n",
    "\n",
    "        Returns:\n",
    "            sensor_ds (xarray): GOME-2 dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    sensor_ds = []\n",
    "\n",
    "    for date in dates:\n",
    "\n",
    "        year = date.split('-')[0]\n",
    "        month = date.split('-')[1]\n",
    "        time = dt.datetime(int(year), int(month), 1)\n",
    "\n",
    "        GOME_product_path = os.path.join('/', '/'.join(\n",
    "                            os.getcwd().split('/')[1:3]), 'adc-toolbox', \n",
    "                            os.path.relpath('data/gome/' + component_nom + '/L3/' + year + '-' + month))\n",
    "        product_names = [file for file in os.listdir(GOME_product_path)]\n",
    "\n",
    "        sensor_df_AB = []\n",
    "\n",
    "        for product_name in product_names:\n",
    "\n",
    "            sensor_df_satellite = []\n",
    "\n",
    "            # Unzip and delete zip files\n",
    "            if product_name.endswith('.zip'):\n",
    "\n",
    "                zf = ZipFile(GOME_product_path + '/' + product_name, 'r')\n",
    "                zf.extractall(GOME_product_path)\n",
    "                zf.close()\n",
    "                os.rename(os.path.join(GOME_product_path, 'no2_' + year + month + '.asc'), \n",
    "                        os.path.join(GOME_product_path, product_name.replace('.zip', ''))) \n",
    "                os.remove(os.path.join(GOME_product_path, product_name))\n",
    "                \n",
    "            # Reconstruct file\n",
    "            with open(GOME_product_path + '/' + product_name.replace('.zip', ''), 'r') as f:\n",
    "                \n",
    "                i = 0    \n",
    "                lon = -179.875\n",
    "\n",
    "                for line in f:   \n",
    "\n",
    "                    if i > 3:\n",
    "\n",
    "                        if 'lat' in line:\n",
    "                            lat = float(line.replace('lat=  ', ''))\n",
    "                            lon = -179.875\n",
    "\n",
    "                        else: \n",
    "\n",
    "                            line = line.replace('\\n', '')\n",
    "\n",
    "                            for value in [line[i:i+4] for i in range(0, len(line), 4)]:\n",
    "                                \n",
    "                                if value == '-999':\n",
    "                                    value = np.nan\n",
    "                                    \n",
    "                                else:\n",
    "                                    value = float(value.replace(' ', ''))\n",
    "                                    value = value*10**13\n",
    "                                \n",
    "                                sensor_df_satellite.append({'time': time, \n",
    "                                                            'latitude': lat, \n",
    "                                                            'longitude': lon, \n",
    "                                                            'sensor_column': value})\n",
    "                                lon += 0.25\n",
    "                                \n",
    "                    i += 1\n",
    "                    \n",
    "            sensor_df_satellite = pd.DataFrame(sensor_df_satellite)\n",
    "            sensor_df_satellite = sensor_df_satellite.set_index(['time', 'latitude', 'longitude'])\n",
    "            sensor_df_satellite = sensor_df_satellite[~sensor_df_satellite.index.duplicated()]\n",
    "\n",
    "            sensor_df_AB.append(sensor_df_satellite)\n",
    "        \n",
    "        if len(sensor_df_AB) == 2:\n",
    "            sensor_df_AB = pd.merge(sensor_df_AB[0], sensor_df_AB[1], left_index = True, right_index = True, how = 'outer')\n",
    "\n",
    "        else:\n",
    "            sensor_df_AB = pd.concat([sensor_df_AB[0]])\n",
    "\n",
    "        # Mean of Metop-A and Metop-B data if both exist for a specific coordinate\n",
    "        sensor_df_AB = sensor_df_AB.mean(axis = 1).to_frame()\n",
    "        sensor_df_AB = sensor_df_AB.rename(columns = {0: 'sensor_column'}).sort_index()\n",
    "\n",
    "        # Regrid onto a custom defined regular grid\n",
    "        sensor_ds_time = sensor_df_AB.to_xarray()\n",
    "        sensor_ds_time_gridded = binning(sensor_ds_time, lat_res, lon_res) \n",
    "        \n",
    "        sensor_ds.append(sensor_ds_time_gridded)\n",
    "\n",
    "    sensor_ds = xr.concat(sensor_ds, dim = 'time')\n",
    "    sensor_ds['sensor_column'] = sensor_ds['sensor_column'].assign_attrs({'units': 'molec cm-2'})\n",
    "\n",
    "    return sensor_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GOME_L2_download(component_nom, date, satellite):\n",
    "\n",
    "    \"\"\" Download L2 GOME-2 datasets\n",
    "\n",
    "         Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            date (str): Query date\n",
    "            satellite (str): A, B and/or C referring to METOP series\n",
    "    \"\"\"\n",
    "    \n",
    "    GOME_product_path = os.path.join('/', '/'.join(\n",
    "                        os.getcwd().split('/')[1:3]), 'adc-toolbox', \n",
    "                        os.path.relpath('data/gome/' + component_nom + '/L2/' + date + '/' + satellite))\n",
    "    os.makedirs(GOME_product_path, exist_ok = True) \n",
    "\n",
    "    # Get year, month and day from date\n",
    "    year = date.split('-')[0]\n",
    "    month = date.split('-')[1]\n",
    "    day = date.split('-')[2]\n",
    "\n",
    "    # Save index.html with available offline products through FTP for specific date\n",
    "    date_path = 'ftp://acsaf.eoc.dlr.de/gome2' + satellite.lower() + '/offline/' + year + '/' + month + '/' + day + '/'\n",
    "    index_file_path = os.path.join('/', '/'.join(\n",
    "                      os.getcwd().split('/')[1:3]), 'adc-toolbox', \n",
    "                      os.path.relpath('data/gome/' + component_nom + '/' + 'index.html'))\n",
    "    subprocess.run(['wget', '-q', '-O', index_file_path, '-i', date_path])\n",
    "\n",
    "    # Download all files for date and satellite\n",
    "    if os.stat(index_file_path).st_size != 0:  \n",
    "            \n",
    "        # Read index.html and get content within pre tabs\n",
    "        html_text = open(index_file_path, 'r')\n",
    "        items_int = bs4.BeautifulSoup(html_text, 'lxml').pre.get_text().splitlines()[1:]\n",
    "        GOME_product_names = [item_int.split('File        ', 1)[1].split('  (', 1)[0] for item_int in items_int]\n",
    "\n",
    "        for product_name in GOME_product_names:\n",
    "            \n",
    "            file_name = GOME_product_path + '/' + product_name\n",
    "            path = 'ftp://acsaf.eoc.dlr.de/gome2' + satellite.lower() + '/offline/' + year + '/' + month + '/' + day + '/' + product_name\n",
    "            subprocess.run(['wget', '-q', '-nc', path, '-O', file_name])\n",
    "\n",
    "            if os.stat(file_name).st_size == 0:  \n",
    "                os.remove(file_name) \n",
    "                print(product_name, 'is not available.')\n",
    "                \n",
    "            else:\n",
    "                print(product_name, 'was downloaded.')\n",
    "\n",
    "    else:\n",
    "        print(f'The datasets for {date} and METOP-{satellite} are not available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GOME_L2_read(component_nom, dates, lat_res = 0.25, lon_res = 0.25):\n",
    "\n",
    "    \"\"\" Read L2 GOME-2 datasets as xarray dataset object and assign time\n",
    "\n",
    "         Args:\n",
    "            component_nom (str): Component chemical nomenclature\n",
    "            dates (list): Available dates\n",
    "            lat_res (float): Spatial resolution for latitude\n",
    "            lon_res (float): Spatial resolution for longitude\n",
    "            \n",
    "        Returns:\n",
    "            sensor_ds (xarray): GOME-2 dataset in xarray format\n",
    "    \"\"\"\n",
    "\n",
    "    if lat_res < 0.25 or lon_res < 0.25:\n",
    "        print('To show the original data, the resolution must equal to 1x1ยบ.')\n",
    "        print('To show aggregated data, the resolution must be superior to 1x1ยบ.')\n",
    "        raise KeyboardInterrupt()\n",
    "\n",
    "    sensor_ds_all = []\n",
    "\n",
    "    # Concatenate all the products for different dates\n",
    "    for date in dates:\n",
    "\n",
    "        year = date.split('-')[0]\n",
    "        month = date.split('-')[1]\n",
    "        day = date.split('-')[2]\n",
    "        \n",
    "        sensor_ds_ABC = []\n",
    "\n",
    "        GOME_product_path = os.path.join('/', '/'.join(\n",
    "                            os.getcwd().split('/')[1:3]), 'adc-toolbox', \n",
    "                            os.path.relpath('data/gome/' + component_nom + '/L2/' + date))\n",
    "         \n",
    "        # Concatenate all the products for METOP-A, B and C\n",
    "        for satellite in os.listdir(GOME_product_path):\n",
    "\n",
    "            sensor_ds_sat_daily = []\n",
    "            GOME_product_names = [file for file in os.listdir(GOME_product_path + '/' + satellite)]\n",
    "            \n",
    "            # Concatenate all the products for different delta times\n",
    "            for product_name in GOME_product_names:\n",
    "\n",
    "                f = h5py.File(GOME_product_path + '/' + satellite + '/' + product_name, 'r')\n",
    "                f['TOTAL_COLUMNS/' + component_nom]\n",
    "\n",
    "                latitude = f['GEOLOCATION/LatitudeCentre']\n",
    "                longitude = f['GEOLOCATION/LongitudeCentre']\n",
    "\n",
    "                # Get component for one delta time \n",
    "                sensor_ds_sat_time = xr.DataArray(\n",
    "                                                  f['TOTAL_COLUMNS/' + component_nom],\n",
    "                                                  dims = ('ground_pixel'),\n",
    "                                                  coords = {\n",
    "                                                            'latitude': ('ground_pixel', latitude[:]),\n",
    "                                                            'longitude': ('ground_pixel', longitude[:])\n",
    "                                                  },\n",
    "                                                  name = component_nom\n",
    "                )\n",
    "                \n",
    "                # Get delta time from product name and add it as a variable\n",
    "                delta_time_str_int = product_name.split(date.replace('-', ''), 1)[1].split('_', 1)[0]\n",
    "                delta_time_str = [delta_time_str_int[i:i+2] for i in range(0, len(delta_time_str_int), 2)]      \n",
    "                delta_time = dt.datetime(int(year), int(month), int(day), \n",
    "                                         int(delta_time_str[0]), int(delta_time_str[1]), \n",
    "                                         int(delta_time_str[2]))\n",
    "\n",
    "                sensor_ds_delta_time = xr.DataArray(np.repeat(delta_time, len(sensor_ds_sat_time.ground_pixel)),\n",
    "                                                    dims = ('ground_pixel'),\n",
    "                                                    coords = {\n",
    "                                                              'latitude': ('ground_pixel', latitude[:]),\n",
    "                                                              'longitude': ('ground_pixel', longitude[:])\n",
    "                                                    },\n",
    "                                                    name = 'delta_time'\n",
    "                )\n",
    "\n",
    "                # Merge both variables (component and delta time)\n",
    "                sensor_ds_sat_time = xr.merge([sensor_ds_sat_time, sensor_ds_delta_time])\n",
    "                sensor_ds_sat_daily.append(sensor_ds_sat_time)\n",
    "            \n",
    "            sensor_ds_sat_daily = xr.concat(sensor_ds_sat_daily, dim = 'ground_pixel')\n",
    "            \n",
    "        sensor_ds_ABC = xr.concat([sensor_ds_sat_daily], dim = 'ground_pixel')\n",
    "\n",
    "        sensor_ds_ABC = sensor_ds_ABC.assign_coords(longitude = (((sensor_ds_ABC.longitude + 180) % 360) - 180))\n",
    "\n",
    "        y = sensor_ds_ABC.latitude.data\n",
    "        x = sensor_ds_ABC.longitude.data\n",
    "        z = sensor_ds_ABC[component_nom].data\n",
    "\n",
    "        zi, yi, xi = np.histogram2d(y, x, bins = (180, 360), weights = z, normed = False)\n",
    "        counts, _, _ = np.histogram2d(y, x, bins = (180, 360))\n",
    "        zi = zi / counts\n",
    "        \n",
    "        sensor_ds_ABC_gridded = xr.DataArray(\n",
    "                                             zi,\n",
    "                                             dims = ['latitude', 'longitude'],\n",
    "                                             coords = {\n",
    "                                                       'latitude': (['latitude'], yi[:-1]),\n",
    "                                                       'longitude': (['longitude'], xi[:-1])\n",
    "                                             },\n",
    "                                             name = 'sensor_column'\n",
    "        )\n",
    "\n",
    "        # Regrid onto a custom defined regular grid\n",
    "        sensor_ds_ABC_gridded = binning(sensor_ds_ABC_gridded, lat_res, lon_res) \n",
    "        \n",
    "        # Get datafame with delta time (non-gridded)\n",
    "        delta_time_df = pd.DataFrame()\n",
    "        delta_time_df['ground_pixel'] = sensor_ds_ABC.ground_pixel\n",
    "        delta_time_df['latitude'] = delta_time_df.apply(lambda row: sensor_ds_ABC.sel(ground_pixel = row['ground_pixel']).latitude.values, axis = 1)\n",
    "        delta_time_df['longitude'] = delta_time_df.apply(lambda row: sensor_ds_ABC.sel(ground_pixel = row['ground_pixel']).longitude.values, axis = 1)\n",
    "        delta_time_df['delta_time'] = delta_time_df.apply(lambda row: sensor_ds_ABC.sel(ground_pixel = row['ground_pixel']).delta_time.values, axis = 1)\n",
    "        \n",
    "        # Round latitude and longitude to 0 decimals\n",
    "        delta_time_df_rounded = delta_time_df\n",
    "        delta_time_df_rounded['latitude_rounded'] = [round(value.item(0)) for value in delta_time_df_rounded['latitude'].values]\n",
    "        delta_time_df_rounded['longitude_rounded'] = [round(value.item(0)) for value in delta_time_df_rounded['longitude'].values]\n",
    "        delta_time_df_rounded\n",
    "\n",
    "        # Get datafame without delta time (gridded)\n",
    "        delta_time_df_gridded = sensor_ds_ABC_gridded.to_dataframe()\n",
    "        delta_time_df_gridded = delta_time_df_gridded.reset_index()\n",
    "\n",
    "        # Round latitude and longitude to 0 decimals\n",
    "        delta_time_df_gridded_rounded = delta_time_df_gridded\n",
    "        delta_time_df_gridded_rounded['latitude_rounded'] = round(delta_time_df_gridded_rounded['latitude'])\n",
    "        delta_time_df_gridded_rounded['longitude_rounded'] = round(delta_time_df_gridded_rounded['longitude'])\n",
    "\n",
    "        # Order dataframes before merge\n",
    "        delta_time_df_gridded_rounded = delta_time_df_gridded_rounded.sort_values(by = ['latitude_rounded', 'longitude_rounded'])\n",
    "        delta_time_df_rounded = delta_time_df_rounded.drop(columns = 'ground_pixel').sort_values(by = ['latitude_rounded', 'longitude_rounded'])\n",
    "        \n",
    "        # Merge and clean\n",
    "        final = pd.merge(delta_time_df_gridded_rounded, delta_time_df_rounded, \n",
    "                         on= ['latitude_rounded', 'longitude_rounded'], how = 'left')\n",
    "        final = final[~(final.delta_time.isnull() & final['sensor_column'].notnull())]\n",
    "        final = final.drop(columns = ['latitude_rounded', 'longitude_rounded', 'latitude_y', 'longitude_y'])\n",
    "        final = final.rename({'latitude_x': 'latitude', 'longitude_x': 'longitude'}, axis = 1)\n",
    "        final = final.set_index(['latitude', 'longitude'])\n",
    "        final = final[~final.index.duplicated()].to_xarray()\n",
    "        \n",
    "        # Assign day as time\n",
    "        time_str = dt.datetime(int(year), int(month), int(day))\n",
    "        final = final.assign_coords({'time': time_str}).expand_dims(dim = ['time'])\n",
    "\n",
    "        sensor_ds_all.append(final)\n",
    "\n",
    "    sensor_ds = xr.concat(sensor_ds_all, dim = 'time')\n",
    "   \n",
    "    return sensor_ds"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc2967d46b8688a8c6de8a18a3daae8ebe0b7dc5d18d27687b3fe01b2a6426f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env-new': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
